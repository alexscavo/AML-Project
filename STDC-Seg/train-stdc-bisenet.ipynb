{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11422827,"sourceType":"datasetVersion","datasetId":7153698},{"sourceId":11956975,"sourceType":"datasetVersion","datasetId":7419104}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, shutil\n\nsrc = \"/kaggle/input/stdc-repo/STDC-Seg\"\ndst = \"/kaggle/working/STDC-Seg\"\n\n# ensure the parent exists\nos.makedirs(os.path.dirname(dst), exist_ok=True)\n\n# copy the whole tree\nshutil.copytree(src, dst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T11:04:40.941841Z","iopub.execute_input":"2025-05-29T11:04:40.942148Z","iopub.status.idle":"2025-05-29T11:04:42.376206Z","shell.execute_reply.started":"2025-05-29T11:04:40.942117Z","shell.execute_reply":"2025-05-29T11:04:42.375504Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/STDC-Seg'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport os\nimport sys\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nsys.path.append('/kaggle/working/STDC-Seg')\n\nimport argparse\nimport logging\nimport time\nimport datetime\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom loveda import LoveDA\nfrom models.model_stages import BiSeNet\nfrom loss.loss import WeightedOhemCELoss, OhemCELoss\nfrom loss.detail_loss import DetailAggregateLoss\nfrom optimizer_loss import Optimizer\nimport torch.optim as optim\n# Configuration\ndef parse_args():\n    parser = argparse.ArgumentParser(description='STDC Segmentation Training')\n    parser.add_argument('--epochs', type=int, default=20, help='number of training epochs')\n    parser.add_argument('--batch_size', type=int, default=6, help='images per batch')\n    parser.add_argument('--n_workers_train', type=int, default=4)\n    parser.add_argument('--n_workers_val', type=int, default=0)\n    parser.add_argument('--cropsize', type=int, nargs=2, default=[1024, 512])\n    parser.add_argument('--randomscale', type=float, nargs='+',\n                        default=[0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0, 1.125, 1.25, 1.375, 1.5])\n    parser.add_argument('--backbone', type=str, default='STDCNet813')\n    parser.add_argument('--pretrain_path', type=str, default='/kaggle/working/STDC-Seg/pretrained_models/STDCNet813M_73.91.tar')\n    parser.add_argument('--ckpt', type=str, default=None)\n    parser.add_argument('--respath', type=str, default='/kaggle/working/output')\n    parser.add_argument('--use_conv_last', action='store_true')\n    parser.add_argument('--use_boundary_2', action='store_true')\n    parser.add_argument('--use_boundary_4', action='store_true')\n    parser.add_argument('--use_boundary_8', action='store_true')\n    parser.add_argument('--use_boundary_16', action='store_true')\n    return parser.parse_args(args=[] if '__file__' not in globals() else None)\n\n# Metrics\ndef compute_iou(pred, target, num_classes, ignore_index=255):\n    ious = []\n    pred = pred.view(-1)\n    target = target.view(-1)\n    for cls in range(num_classes):\n        mask = target == cls\n        if mask.sum().item() == 0:\n            ious.append(float('nan'))\n            continue\n        inter = ((pred == cls) & mask).sum().item()\n        union = ((pred == cls) | mask).sum().item()\n        ious.append(inter / union if union > 0 else float('nan'))\n    miou = np.nanmean(ious)\n    return ious, miou\n\n# Training loop\ndef train():\n    args = parse_args()\n    os.makedirs(args.respath, exist_ok=True)\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger()\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    n_classes = 7\n    ignore_idx = 255\n\n    # Dataset and DataLoader\n    ds_train = LoveDA('/kaggle/input/loveda-splits', cropsize=args.cropsize,\n                      mode='train', randomscale=tuple(args.randomscale), resolution=(512, 512))\n    dl_train = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True,\n                          num_workers=args.n_workers_train, pin_memory=True, drop_last=False)\n    ds_val = LoveDA('/kaggle/input/loveda-splits', mode='val', randomscale=tuple(args.randomscale), resolution=(512, 512))\n    dl_val = DataLoader(ds_val, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.n_workers_val, pin_memory=True, drop_last=False)\n\n    logger.info(f\"Train samples: {len(ds_train)}, Val samples: {len(ds_val)}\")\n\n    # Model\n    net = BiSeNet(backbone=args.backbone, n_classes=n_classes,\n                  pretrain_model=args.pretrain_path,\n                  use_boundary_2=args.use_boundary_2,\n                  use_boundary_4=args.use_boundary_4,\n                  use_boundary_8=args.use_boundary_8,\n                  use_boundary_16=args.use_boundary_16,\n                  use_conv_last=args.use_conv_last)\n    if args.ckpt:\n        net.load_state_dict(torch.load(args.ckpt, map_location='cpu'))\n    net = net.to(device)\n    net = nn.DataParallel(net)\n\n    # Losses and Optimizer\n    n_min = args.batch_size * args.cropsize[0] * args.cropsize[1] // 16\n    criteria = {\n        'p': WeightedOhemCELoss(0.7, n_min, 7, ignore_lb=ignore_idx),\n        '16': WeightedOhemCELoss(0.7, n_min, 7, ignore_lb=ignore_idx),\n        '32': WeightedOhemCELoss(0.7, n_min, 7, ignore_lb=ignore_idx)\n    }\n    boundary_loss = DetailAggregateLoss()\n    optimizer = Optimizer(model=net.module, loss=boundary_loss,\n                          lr0=1e-3, momentum=0.9, wd=5e-4,\n                          warmup_steps=1000, warmup_start_lr=1e-5,\n                          max_iter=len(dl_train)*args.epochs,\n                          power=0.9)\n\n    \n    \n    \n\n    # Epoch loop\n    best_miou = 0.0\n    for epoch in range(1, args.epochs + 1):\n        # -- Training --\n        net.train()\n        running_loss = 0.0\n        train_bar = tqdm(dl_train, desc=f\"Epoch {epoch}/{args.epochs} Training\", unit=\"batch\")\n        for imgs, lbs in train_bar:\n            imgs = imgs.to(device)\n            lbs = lbs.squeeze(1).to(device)\n\n            optimizer.zero_grad()\n            outputs = net(imgs)\n            out, out16, out32 = outputs[:3]\n\n            lp = criteria['p'](out, lbs)\n            l16 = criteria['16'](out16, lbs)\n            l32 = criteria['32'](out32, lbs)\n            lbce, ldice = 0.0, 0.0\n            if args.use_boundary_2 or args.use_boundary_4 or args.use_boundary_8 or args.use_boundary_16:\n                for det in outputs[3:]:\n                    bce, dice = boundary_loss(det, lbs)\n                    lbce += bce; ldice += dice\n\n            loss = lp + l16 + l32 + lbce + ldice\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n        avg_train_loss = running_loss / len(dl_train)\n        print(f\"Epoch {epoch} Training complete. Avg Loss: {avg_train_loss:.4f}\")\n        logger.info(f\"Epoch [{epoch}/{args.epochs}] Train Loss: {avg_train_loss:.4f}\")\n\n        # -- Validation --\n        net.eval()\n        running_val_loss = 0.0\n        intersection = torch.zeros(n_classes, dtype=torch.float64)\n        union        = torch.zeros(n_classes, dtype=torch.float64)\n        val_bar = tqdm(dl_val, desc=f\"Epoch {epoch}/{args.epochs} Validation\", unit=\"batch\")\n        with torch.no_grad():\n            for imgs, lbs in val_bar:\n                imgs = imgs.to(device)\n                lbs = lbs.squeeze(1).to(device)\n                outputs = net(imgs)\n                out = outputs[0]\n\n                # validation loss\n                lval = criteria['p'](out, lbs)\n                running_val_loss += lval.item()\n                val_bar.set_postfix(valloss=f\"{lval.item():.4f}\")\n\n                pred = torch.argmax(out, dim=1)\n                for cls in range(n_classes):\n                    mask = (lbs == cls)\n                    if mask.sum().item() == 0:\n                        continue\n                    inter = ((pred == cls) & mask).sum().item()\n                    uni   = ((pred == cls) | mask).sum().item()\n                    intersection[cls] += inter\n                    union[cls]        += uni\n\n        avg_val_loss = running_val_loss / len(dl_val)\n        print(f\"Epoch {epoch} Validation complete. Avg Loss: {avg_val_loss:.4f}\")\n        logger.info(f\"Epoch [{epoch}/{args.epochs}] Val Loss: {avg_val_loss:.4f}\")\n\n        ious = (intersection / union).tolist()\n        miou = float(torch.nanmean(intersection / union))\n        print(\"Per-class IoU:\")\n        for cls_idx, cls_iou in enumerate(ious):\n            print(f\"  Class {cls_idx}: {cls_iou:.4f}\")\n        print(f\"Mean IoU: {miou:.4f}\")\n\n        for cls_idx, cls_iou in enumerate(ious):\n            logger.info(f\"Class {cls_idx:>2} IoU: {cls_iou:.4f}\")\n        logger.info(f\"Mean IoU: {miou:.4f}\")\n\n        # Save\n        ckpt_name = f\"epoch{epoch:02d}_miou{miou:.4f}.pth\"\n        torch.save(net.module.state_dict(), os.path.join(args.respath, ckpt_name))\n        if miou > best_miou:\n            best_miou = miou\n            torch.save(net.module.state_dict(), os.path.join(args.respath, 'best_mIoU.pth'))\n\n    logger.info(\"Training complete\")\n\nif __name__ == '__main__':\n    train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T11:04:44.121351Z","iopub.execute_input":"2025-05-29T11:04:44.121655Z","iopub.status.idle":"2025-05-29T11:39:41.740883Z","shell.execute_reply.started":"2025-05-29T11:04:44.121633Z","shell.execute_reply":"2025-05-29T11:39:41.740189Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"use pretrain model /kaggle/working/STDC-Seg/pretrained_models/STDCNet813M_73.91.tar\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 Training: 100%|██████████| 193/193 [00:46<00:00,  4.15batch/s, loss=21.8889]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Training complete. Avg Loss: 27.6975\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 Validation: 100%|██████████| 166/166 [01:29<00:00,  1.87batch/s, valloss=8.0694] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Validation complete. Avg Loss: 9.7881\nPer-class IoU:\n  Class 0: 0.1040\n  Class 1: 0.3158\n  Class 2: 0.1210\n  Class 3: 0.2569\n  Class 4: 0.1200\n  Class 5: 0.0768\n  Class 6: 0.0257\nMean IoU: 0.1457\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 Training: 100%|██████████| 193/193 [00:40<00:00,  4.72batch/s, loss=27.5616]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Training complete. Avg Loss: 21.6751\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 Validation: 100%|██████████| 166/166 [01:04<00:00,  2.59batch/s, valloss=7.9411] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Validation complete. Avg Loss: 9.9730\nPer-class IoU:\n  Class 0: 0.1322\n  Class 1: 0.3897\n  Class 2: 0.2821\n  Class 3: 0.2955\n  Class 4: 0.1077\n  Class 5: 0.0811\n  Class 6: 0.3741\nMean IoU: 0.2375\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.83batch/s, loss=22.6214]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Training complete. Avg Loss: 17.6992\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=9.8664] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Validation complete. Avg Loss: 11.5656\nPer-class IoU:\n  Class 0: 0.1583\n  Class 1: 0.3766\n  Class 2: 0.2699\n  Class 3: 0.3365\n  Class 4: 0.1327\n  Class 5: 0.0784\n  Class 6: 0.4073\nMean IoU: 0.2514\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.89batch/s, loss=14.4742]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Training complete. Avg Loss: 15.5537\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.63batch/s, valloss=13.4657]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Validation complete. Avg Loss: 12.0635\nPer-class IoU:\n  Class 0: 0.2130\n  Class 1: 0.3127\n  Class 2: 0.3139\n  Class 3: 0.3709\n  Class 4: 0.1479\n  Class 5: 0.0865\n  Class 6: 0.4457\nMean IoU: 0.2701\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.91batch/s, loss=19.5182]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Training complete. Avg Loss: 15.5480\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.63batch/s, valloss=7.9275] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Validation complete. Avg Loss: 11.4511\nPer-class IoU:\n  Class 0: 0.3448\n  Class 1: 0.3507\n  Class 2: 0.2110\n  Class 3: 0.3563\n  Class 4: 0.1181\n  Class 5: 0.0903\n  Class 6: 0.3633\nMean IoU: 0.2621\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.88batch/s, loss=25.2022]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Training complete. Avg Loss: 15.5879\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=13.3801]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Validation complete. Avg Loss: 14.0007\nPer-class IoU:\n  Class 0: 0.1126\n  Class 1: 0.3362\n  Class 2: 0.2480\n  Class 3: 0.5015\n  Class 4: 0.1922\n  Class 5: 0.0843\n  Class 6: 0.3984\nMean IoU: 0.2676\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.92batch/s, loss=13.3293]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Training complete. Avg Loss: 13.9890\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.66batch/s, valloss=4.4157] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Validation complete. Avg Loss: 9.0180\nPer-class IoU:\n  Class 0: 0.2142\n  Class 1: 0.2613\n  Class 2: 0.3168\n  Class 3: 0.3220\n  Class 4: 0.1420\n  Class 5: 0.1026\n  Class 6: 0.4422\nMean IoU: 0.2573\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.85batch/s, loss=10.4569]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Training complete. Avg Loss: 12.7447\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.65batch/s, valloss=6.5751] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Validation complete. Avg Loss: 10.5087\nPer-class IoU:\n  Class 0: 0.5195\n  Class 1: 0.2242\n  Class 2: 0.3627\n  Class 3: 0.4932\n  Class 4: 0.1531\n  Class 5: 0.1629\n  Class 6: 0.3933\nMean IoU: 0.3299\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.86batch/s, loss=11.5342]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Training complete. Avg Loss: 11.7095\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=2.9561] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Validation complete. Avg Loss: 12.7916\nPer-class IoU:\n  Class 0: 0.5343\n  Class 1: 0.4062\n  Class 2: 0.3950\n  Class 3: 0.3080\n  Class 4: 0.1664\n  Class 5: 0.1203\n  Class 6: 0.4652\nMean IoU: 0.3422\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 Training: 100%|██████████| 193/193 [00:40<00:00,  4.81batch/s, loss=11.7035]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Training complete. Avg Loss: 11.0777\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.61batch/s, valloss=3.6728] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Validation complete. Avg Loss: 13.2460\nPer-class IoU:\n  Class 0: 0.5260\n  Class 1: 0.3695\n  Class 2: 0.3706\n  Class 3: 0.3556\n  Class 4: 0.2139\n  Class 5: 0.1465\n  Class 6: 0.4560\nMean IoU: 0.3483\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.90batch/s, loss=9.3982] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Training complete. Avg Loss: 10.5084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=4.6132] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Validation complete. Avg Loss: 15.9478\nPer-class IoU:\n  Class 0: 0.5378\n  Class 1: 0.4205\n  Class 2: 0.3007\n  Class 3: 0.3236\n  Class 4: 0.1898\n  Class 5: 0.1639\n  Class 6: 0.4576\nMean IoU: 0.3420\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.90batch/s, loss=9.3677] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Training complete. Avg Loss: 9.8825\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=4.1675] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Validation complete. Avg Loss: 18.8689\nPer-class IoU:\n  Class 0: 0.4837\n  Class 1: 0.4497\n  Class 2: 0.3620\n  Class 3: 0.2808\n  Class 4: 0.1775\n  Class 5: 0.1417\n  Class 6: 0.4414\nMean IoU: 0.3338\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.92batch/s, loss=9.0567] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Training complete. Avg Loss: 9.5637\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.66batch/s, valloss=5.3387] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Validation complete. Avg Loss: 17.7695\nPer-class IoU:\n  Class 0: 0.4945\n  Class 1: 0.3834\n  Class 2: 0.3791\n  Class 3: 0.3005\n  Class 4: 0.1618\n  Class 5: 0.1903\n  Class 6: 0.4547\nMean IoU: 0.3377\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.88batch/s, loss=11.5207]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Training complete. Avg Loss: 9.3384\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.65batch/s, valloss=5.2183] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Validation complete. Avg Loss: 21.5191\nPer-class IoU:\n  Class 0: 0.5352\n  Class 1: 0.4655\n  Class 2: 0.3430\n  Class 3: 0.2811\n  Class 4: 0.2211\n  Class 5: 0.0937\n  Class 6: 0.4475\nMean IoU: 0.3410\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.92batch/s, loss=9.1401] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Training complete. Avg Loss: 8.9203\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.63batch/s, valloss=6.6484] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Validation complete. Avg Loss: 21.4881\nPer-class IoU:\n  Class 0: 0.5324\n  Class 1: 0.4693\n  Class 2: 0.3309\n  Class 3: 0.3390\n  Class 4: 0.1617\n  Class 5: 0.1871\n  Class 6: 0.4310\nMean IoU: 0.3502\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 Training: 100%|██████████| 193/193 [00:40<00:00,  4.82batch/s, loss=9.4671] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Training complete. Avg Loss: 8.8081\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.62batch/s, valloss=7.1461] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Validation complete. Avg Loss: 28.3798\nPer-class IoU:\n  Class 0: 0.5357\n  Class 1: 0.3443\n  Class 2: 0.3455\n  Class 3: 0.2871\n  Class 4: 0.1316\n  Class 5: 0.1247\n  Class 6: 0.4485\nMean IoU: 0.3168\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.84batch/s, loss=8.2077] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Training complete. Avg Loss: 8.6263\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.65batch/s, valloss=6.0330] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Validation complete. Avg Loss: 24.0907\nPer-class IoU:\n  Class 0: 0.5440\n  Class 1: 0.4230\n  Class 2: 0.3346\n  Class 3: 0.3089\n  Class 4: 0.1685\n  Class 5: 0.1492\n  Class 6: 0.4508\nMean IoU: 0.3399\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.90batch/s, loss=8.6792] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Training complete. Avg Loss: 8.4582\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 Validation: 100%|██████████| 166/166 [01:02<00:00,  2.64batch/s, valloss=10.4303]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Validation complete. Avg Loss: 23.7006\nPer-class IoU:\n  Class 0: 0.5379\n  Class 1: 0.4203\n  Class 2: 0.3134\n  Class 3: 0.3579\n  Class 4: 0.1440\n  Class 5: 0.1431\n  Class 6: 0.4270\nMean IoU: 0.3348\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.90batch/s, loss=9.1082] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Training complete. Avg Loss: 8.2817\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.61batch/s, valloss=10.9586]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Validation complete. Avg Loss: 28.1996\nPer-class IoU:\n  Class 0: 0.5354\n  Class 1: 0.3817\n  Class 2: 0.2937\n  Class 3: 0.3050\n  Class 4: 0.1432\n  Class 5: 0.1367\n  Class 6: 0.4347\nMean IoU: 0.3186\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 Training: 100%|██████████| 193/193 [00:39<00:00,  4.92batch/s, loss=10.1442]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Training complete. Avg Loss: 8.1664\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 Validation: 100%|██████████| 166/166 [01:03<00:00,  2.63batch/s, valloss=10.6387]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Validation complete. Avg Loss: 27.4577\nPer-class IoU:\n  Class 0: 0.5401\n  Class 1: 0.4190\n  Class 2: 0.3360\n  Class 3: 0.3257\n  Class 4: 0.1456\n  Class 5: 0.1115\n  Class 6: 0.4359\nMean IoU: 0.3305\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}