{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montiamo il drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare di occupare troppa memoria, eliminiamo il dataset presente nella cartella di deeplab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r \"/content/drive/MyDrive/GitHub/DeepLab/project_datasets/LoveDA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**ATTENZIONE**: questa operazione elimina i file dal cestino di Google Drive. Verifica di non avere nulla che ti serva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.colab import auth\n",
    "\n",
    "# Authenticate\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Build the Drive API client\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "# Empty the trash\n",
    "drive_service.files().emptyTrash().execute()\n",
    "print(\"Google Drive Trash has been emptied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per scaricare lo zip del dataset LoveDA. Non usarlo se lo hai già scaricato. In ogni caso ho inserito un check che verifica la presenza o meno del file /content/drive/MyDrive/Datasets/LoveDA/train.zip. Se questo non è presente, allora parte il download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"/content/drive/MyDrive/Datasets/LoveDA/train.zip\"\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = '/content/drive/MyDrive/Datasets/LoveDA'\n",
    "train_zip = os.path.join(dataset_path, 'train.zip')\n",
    "val_zip = os.path.join(dataset_path, 'val.zip')\n",
    "\n",
    "# Function to unzip with a progress bar\n",
    "def unzip_with_progress(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        with tqdm(total=total_files, desc=f\"Extracting {os.path.basename(zip_path)}\") as pbar:\n",
    "            for file in zip_ref.infolist():\n",
    "                zip_ref.extract(file, extract_to)\n",
    "                pbar.update(1)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    url_train = \"https://zenodo.org/records/5706578/files/Train.zip?download=1\"\n",
    "    output_train = \"/content/drive/MyDrive/Datasets/LoveDA/train.zip\"  # Specify the path in your Google Drive\n",
    "\n",
    "    url_val = \"https://zenodo.org/records/5706578/files/Val.zip?download=1\"\n",
    "    output_val = \"/content/drive/MyDrive/Datasets/LoveDA/val.zip\"  # Specify the path in your Google Drive\n",
    "\n",
    "\n",
    "    response = requests.get(url_train, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "\n",
    "    with open(output_train, \"wb\") as file, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=\"Downloading\"\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            file.write(data)\n",
    "            progress_bar.update(len(data))\n",
    "\n",
    "    print(\"Download train completed!\")\n",
    "\n",
    "    response = requests.get(url_val, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "\n",
    "    with open(output_val, \"wb\") as file, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=\"Downloading\"\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            file.write(data)\n",
    "            progress_bar.update(len(data))\n",
    "\n",
    "    print(\"Download val completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una cartella in cui mettere il clone repository di github, qualora non sia già presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = \"/content/drive/MyDrive/GitHub/\"\n",
    "os.makedirs(destination_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poiché il repository è privato, è necessario fare il clone usando il tuo account github. Per farlo crea un token da github con i seguenti passaggi:\n",
    "\n",
    "\n",
    "1. Vai sul tuo account GitHub.\n",
    "2. Vai a **Settings** > **Developer settings** > **Personal access tokens** > Tokens (classic).\n",
    "3. Clicca **Generate new token**\n",
    "4. Imposta una data di scadenza del token e fisci tutte le autorizzazioni (spunta tutte le caselle proposte).\n",
    "5. Genera il token e salvalo da qualche parte, perché puoi vederlo solo una volta.\n",
    "\n",
    "Adesso inserisci il tuo username e il token nella casella di codice seguente per fare il clone\n",
    "\n",
    "Nota: anche qui viene fatto un check per cui il clone non viene eseguito il repository è già stato clonato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3946393136.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main\"\n",
    "if not os.path.exists(folder_path):\n",
    "  github_username = \"MontanaVincenzo\"  # Replace with your GitHub username\n",
    "  github_token = \"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\"  # Replace with your personal access token\n",
    "\n",
    "  # Repository URL and folder\n",
    "  repo_url = f\"https://{github_username}:{github_token}@github.com/alexscavo/AML-Project.git\"\n",
    "\n",
    "  !git clone {repo_url} {destination_path}\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per adattare la struttura del repository al codice proposto, creo la cartella */content/drive/MyDrive/GitHub/PIDNet-main/data/loveda*, poi unzippo dal drive i dataset di training e di evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/Train\"\n",
    "folder_path2 = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/train\"\n",
    "\n",
    "if (not os.path.exists(folder_path1)) and (not os.path.exists(folder_path2)):\n",
    "    new_folder = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda\"\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "    # Unzip train and validation datasets\n",
    "    unzip_with_progress(train_zip, '/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda')\n",
    "    unzip_with_progress(val_zip, '/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rinomio le cartelle Train ed Eval per adattare il percorso al codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/Train\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    # Define the old and new folder paths\n",
    "    old_folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/Train\"\n",
    "    new_folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/train\"\n",
    "\n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "\n",
    "    print(f\"Renamed folder from {old_folder_path} to {new_folder_path}\")\n",
    "\n",
    "folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/Val\"\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    # Define the old and new folder paths\n",
    "    old_folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/Val\"\n",
    "    new_folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda/val\"\n",
    "\n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "\n",
    "    print(f\"Renamed folder from {old_folder_path} to {new_folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardX\n",
    "!pip install yacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/create_loveda_list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RobotLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
