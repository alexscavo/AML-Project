{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:14.303612Z",
     "iopub.status.busy": "2025-05-24T10:32:14.303189Z",
     "iopub.status.idle": "2025-05-24T10:32:20.085158Z",
     "shell.execute_reply": "2025-05-24T10:32:20.084478Z",
     "shell.execute_reply.started": "2025-05-24T10:32:14.303588Z"
    },
    "id": "Pqh-LuR5inRH",
    "outputId": "c05502f6-b016-43bd-b554-1e4ea2614543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs) (6.0.2)\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (3.20.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install yacs\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.086468Z",
     "iopub.status.busy": "2025-05-24T10:32:20.086191Z",
     "iopub.status.idle": "2025-05-24T10:32:20.209807Z",
     "shell.execute_reply": "2025-05-24T10:32:20.208824Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.086439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Crea la cartella dove l'API Kaggle si aspetta il file\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "\n",
    "# Copia il file json dal dataset input nella cartella corretta\n",
    "shutil.copy('/kaggle/input/api-kaggle/kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "\n",
    "# Imposta i permessi giusti\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.211702Z",
     "iopub.status.busy": "2025-05-24T10:32:20.210988Z",
     "iopub.status.idle": "2025-05-24T10:32:20.216925Z",
     "shell.execute_reply": "2025-05-24T10:32:20.216353Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.211677Z"
    },
    "id": "9qCYBoYv1WQZ",
    "outputId": "bc9151bb-d1fa-4c35-f86d-7f2aaa284b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: /kaggle/working/data/loveda/train/\n",
      "Already exists: /kaggle/working/data/loveda/val/\n",
      "Already exists: /kaggle/working/data/list/loveda/rural\n",
      "Already exists: /kaggle/working/data/list/loveda/urban_rural\n",
      "Already exists: /kaggle/working/data/list/loveda/urban_urban\n",
      "Already exists: /kaggle/working/pretrained_models/imagenet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_kaggle_path = \"/kaggle/working/\"\n",
    "folder_names = [\n",
    "    'data/loveda/train/',\n",
    "    'data/loveda/val/',\n",
    "    'data/list/loveda/rural',\n",
    "    'data/list/loveda/urban_rural',\n",
    "    'data/list/loveda/urban_urban',\n",
    "    'pretrained_models/imagenet'\n",
    "]\n",
    "\n",
    "for relative_path in folder_names:\n",
    "    full_path = os.path.join(base_kaggle_path, relative_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "        print(f\"Created: {full_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {full_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.217887Z",
     "iopub.status.busy": "2025-05-24T10:32:20.217690Z",
     "iopub.status.idle": "2025-05-24T10:32:20.272608Z",
     "shell.execute_reply": "2025-05-24T10:32:20.271999Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.217871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped (already exists): /kaggle/working/data/loveda/train/Rural\n",
      "Skipped (already exists): /kaggle/working/data/loveda/train/Urban\n",
      "Skipped (already exists): /kaggle/working/data/loveda/val/Rural\n",
      "Skipped (already exists): /kaggle/working/data/loveda/val/Urban\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "list_src = [\n",
    "    '/kaggle/input/loveda-splits/Train/Train/Rural',\n",
    "    '/kaggle/input/loveda-splits/Train/Train/Urban',\n",
    "    '/kaggle/input/loveda-splits/Val/Val/Rural',\n",
    "    '/kaggle/input/loveda-splits/Val/Val/Urban'\n",
    "]\n",
    "\n",
    "list_dst = [\n",
    "    '/kaggle/working/data/loveda/train/Rural',\n",
    "    '/kaggle/working/data/loveda/train/Urban',\n",
    "    '/kaggle/working/data/loveda/val/Rural',\n",
    "    '/kaggle/working/data/loveda/val/Urban'\n",
    "]\n",
    "\n",
    "for src, dst in zip(list_src, list_dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copytree(src, dst)\n",
    "        print(f\"Copied: {src} → {dst}\")\n",
    "    else:\n",
    "        print(f\"Skipped (already exists): {dst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.273534Z",
     "iopub.status.busy": "2025-05-24T10:32:20.273298Z",
     "iopub.status.idle": "2025-05-24T10:32:20.298695Z",
     "shell.execute_reply": "2025-05-24T10:32:20.298185Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.273512Z"
    },
    "id": "x-_xpQCZcbRg",
    "outputId": "d91de478-c474-4944-ca0e-0b3a8de56f7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/configs/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "dst = '/kaggle/working/configs/'\n",
    "\n",
    "# Rimuove se esiste già\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "\n",
    "# Ora copia senza problemi\n",
    "shutil.copytree('/kaggle/input/configs-pidnet/configs', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.301202Z",
     "iopub.status.busy": "2025-05-24T10:32:20.300795Z",
     "iopub.status.idle": "2025-05-24T10:32:20.376051Z",
     "shell.execute_reply": "2025-05-24T10:32:20.375539Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.301186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Crea la directory se non esiste\n",
    "os.makedirs('/kaggle/working/pretrained_models/imagenet', exist_ok=True)\n",
    "\n",
    "# Ora copia il file\n",
    "shutil.copy('/kaggle/input/pidnet-pretrained/PIDNet_S_ImageNet.pth.tar', \n",
    "            '/kaggle/working/pretrained_models/imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.376825Z",
     "iopub.status.busy": "2025-05-24T10:32:20.376664Z",
     "iopub.status.idle": "2025-05-24T10:32:20.446898Z",
     "shell.execute_reply": "2025-05-24T10:32:20.446206Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.376812Z"
    },
    "id": "PDsG8UU9gU8e",
    "outputId": "5874c528-5f6c-4525-db46-52b965768d00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy('/kaggle/input/pidnet-pretrained/PIDNet_S_ImageNet.pth.tar', '/kaggle/working/pretrained_models/imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.448192Z",
     "iopub.status.busy": "2025-05-24T10:32:20.447869Z",
     "iopub.status.idle": "2025-05-24T10:32:20.453318Z",
     "shell.execute_reply": "2025-05-24T10:32:20.452550Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.448159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd '/kaggle/working'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LRO-dropYbt"
   },
   "source": [
    "# _init_paths.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.454224Z",
     "iopub.status.busy": "2025-05-24T10:32:20.454005Z",
     "iopub.status.idle": "2025-05-24T10:32:20.494948Z",
     "shell.execute_reply": "2025-05-24T10:32:20.494244Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.454209Z"
    },
    "id": "WDp6olwIbTw9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_lst_file(image_dir, label_dir, output_lst):\n",
    "    # List and sort files numerically\n",
    "    images = sorted(os.listdir(image_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    labels = sorted(os.listdir(label_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_lst), exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    with open(output_lst, 'w') as f:\n",
    "        for img, lbl in zip(images, labels):\n",
    "            # Generate full paths and normalize to use forward slashes\n",
    "            img_path = os.path.join(image_dir, img).replace(\"\\\\\", \"/\")\n",
    "            lbl_path = os.path.join(label_dir, lbl).replace(\"\\\\\", \"/\")\n",
    "            # Write formatted line with consistent spacing\n",
    "            f.write(f\"{img_path} {lbl_path}\\n\")\n",
    "\n",
    "# Paths to the LoveDA dataset directories\n",
    "urban_train_image_dir = \"data/loveda/train/Urban/images_png\"\n",
    "urban_train_label_dir = \"data/loveda/train/Urban/masks_png\"\n",
    "\n",
    "urban_test_image_dir = \"data/loveda/val/Urban/images_png\"\n",
    "urban_test_label_dir = \"data/loveda/val/Urban/masks_png\"\n",
    "\n",
    "rural_train_image_dir = \"data/loveda/train/Rural/images_png\"\n",
    "rural_train_label_dir = \"data/loveda/train/Rural/masks_png\"\n",
    "\n",
    "rural_test_image_dir = \"data/loveda/val/Rural/images_png\"\n",
    "rural_test_label_dir = \"data/loveda/val/Rural/masks_png\"\n",
    "\n",
    "\n",
    "\n",
    "# train on urban - test on urban\n",
    "train_lst_path = \"data/list/loveda/urban_urban/train.lst\"\n",
    "test_lst_path = \"data/list/loveda/urban_urban/val.lst\"\n",
    "\n",
    "# Create .lst files\n",
    "create_lst_file(urban_train_image_dir, urban_train_label_dir, train_lst_path)\n",
    "create_lst_file(urban_test_image_dir, urban_test_label_dir, test_lst_path)\n",
    "\n",
    "train_lst_path = \"data/list/loveda/urban_rural/train.lst\"\n",
    "target_lst_path = \"data/list/loveda/rural/train.lst\"\n",
    "test_lst_path = \"data/list/loveda/urban_rural/val.lst\"\n",
    "\n",
    "# Create .lst files\n",
    "create_lst_file(urban_train_image_dir, urban_train_label_dir, train_lst_path)\n",
    "create_lst_file(rural_train_image_dir, rural_train_label_dir, target_lst_path)\n",
    "create_lst_file(rural_test_image_dir, rural_test_label_dir, test_lst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.495879Z",
     "iopub.status.busy": "2025-05-24T10:32:20.495718Z",
     "iopub.status.idle": "2025-05-24T10:32:20.499987Z",
     "shell.execute_reply": "2025-05-24T10:32:20.499213Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.495866Z"
    },
    "id": "HZRc88q3pV0d"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft\n",
    "# Licensed under the MIT License.\n",
    "# Written by Ke Sun (sunk@mail.ustc.edu.cn)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj2x9u3_lEmk"
   },
   "source": [
    "# model_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:20.501048Z",
     "iopub.status.busy": "2025-05-24T10:32:20.500797Z",
     "iopub.status.idle": "2025-05-24T10:32:22.104472Z",
     "shell.execute_reply": "2025-05-24T10:32:22.103685Z",
     "shell.execute_reply.started": "2025-05-24T10:32:20.501027Z"
    },
    "id": "RkXp_Vq6k_FR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class segmenthead(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
    "        super(segmenthead, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
    "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(self.relu(self.bn1(x)))\n",
    "        out = self.conv2(self.relu(self.bn2(x)))\n",
    "\n",
    "        if self.scale_factor is not None:\n",
    "            height = x.shape[-2] * self.scale_factor\n",
    "            width = x.shape[-1] * self.scale_factor\n",
    "            out = F.interpolate(out,\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.process1 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process2 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process3 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process4 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        x_list = []\n",
    "\n",
    "        x_list.append(self.scale0(x))\n",
    "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
    "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
    "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
    "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
    "\n",
    "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "class PAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale_process = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        scale_list = []\n",
    "\n",
    "        x_ = self.scale0(x)\n",
    "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "\n",
    "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
    "\n",
    "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PagFM(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PagFM, self).__init__()\n",
    "        self.with_channel = with_channel\n",
    "        self.after_relu = after_relu\n",
    "        self.f_x = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        self.f_y = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        if with_channel:\n",
    "            self.up = nn.Sequential(\n",
    "                                    nn.Conv2d(mid_channels, in_channels,\n",
    "                                              kernel_size=1, bias=False),\n",
    "                                    BatchNorm(in_channels)\n",
    "                                   )\n",
    "        if after_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        input_size = x.size()\n",
    "        if self.after_relu:\n",
    "            y = self.relu(y)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        y_q = self.f_y(y)\n",
    "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x_k = self.f_x(x)\n",
    "\n",
    "        if self.with_channel:\n",
    "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
    "        else:\n",
    "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
    "\n",
    "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x = (1-sim_map)*x + sim_map*y\n",
    "\n",
    "        return x\n",
    "\n",
    "class Light_Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Light_Bag, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "\n",
    "class DDFMv2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DDFMv2, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "class Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Bag, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=3, padding=1, bias=False)\n",
    "                                )\n",
    "\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "        return self.conv(edge_att*p + (1-edge_att)*i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nct1QBaLlIY-"
   },
   "source": [
    "# pidnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:22.105556Z",
     "iopub.status.busy": "2025-05-24T10:32:22.105272Z",
     "iopub.status.idle": "2025-05-24T10:32:22.130563Z",
     "shell.execute_reply": "2025-05-24T10:32:22.129806Z",
     "shell.execute_reply.started": "2025-05-24T10:32:22.105540Z"
    },
    "id": "3jboQ25HlLp2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import logging\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class PIDNet(nn.Module):\n",
    "\n",
    "    def __init__(self, m=2, n=3, num_classes=19, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
    "        super(PIDNet, self).__init__()\n",
    "        self.augment = augment\n",
    "\n",
    "        # I Branch\n",
    "        self.conv1 =  nn.Sequential(\n",
    "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                      )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
    "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
    "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
    "\n",
    "        # P Branch\n",
    "        self.compression3 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "\n",
    "        self.compression4 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "        self.pag3 = PagFM(planes * 2, planes)\n",
    "        self.pag4 = PagFM(planes * 2, planes)\n",
    "\n",
    "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # D Branch\n",
    "        if m == 2:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
    "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
    "        else:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Bag(planes * 4, planes * 4)\n",
    "\n",
    "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # Prediction Head\n",
    "        if self.augment:\n",
    "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
    "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
    "\n",
    "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            if i == (blocks-1):\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
    "            else:\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        width_output = x.shape[-1] // 8\n",
    "        height_output = x.shape[-2] // 8\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(self.layer2(self.relu(x)))\n",
    "        x_ = self.layer3_(x)\n",
    "        x_d = self.layer3_d(x)\n",
    "\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x_ = self.pag3(x_, self.compression3(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff3(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_p = x_\n",
    "\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x_ = self.layer4_(self.relu(x_))\n",
    "        x_d = self.layer4_d(self.relu(x_d))\n",
    "\n",
    "        x_ = self.pag4(x_, self.compression4(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff4(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_d = x_d\n",
    "\n",
    "        x_ = self.layer5_(self.relu(x_))\n",
    "        x_d = self.layer5_d(self.relu(x_d))\n",
    "        x = F.interpolate(\n",
    "                        self.spp(self.layer5(x)),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
    "\n",
    "        if self.augment:\n",
    "            x_extra_p = self.seghead_p(temp_p)\n",
    "            x_extra_d = self.seghead_d(temp_d)\n",
    "            return [x_extra_p, x_, x_extra_d]\n",
    "        else:\n",
    "            return x_\n",
    "\n",
    "def get_seg_model(cfg, imgnet_pretrained):\n",
    "\n",
    "    if 's' in cfg.MODEL.NAME:\n",
    "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
    "    elif 'm' in cfg.MODEL.NAME:\n",
    "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=96, head_planes=128, augment=True)\n",
    "    else:\n",
    "        model = PIDNet(m=3, n=4, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=112, head_planes=256, augment=True)\n",
    "\n",
    "    if imgnet_pretrained:\n",
    "        pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
    "        model_dict.update(pretrained_state)\n",
    "        msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
    "        logging.info('Attention!!!')\n",
    "        logging.info(msg)\n",
    "        logging.info('Over!!!')\n",
    "        model.load_state_dict(model_dict, strict = False)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')\n",
    "        if 'state_dict' in pretrained_dict:\n",
    "            pretrained_dict = pretrained_dict['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "        msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "        logging.info('Attention!!!')\n",
    "        logging.info(msg)\n",
    "        logging.info('Over!!!')\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict, strict = False)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_pred_model(name, num_classes):\n",
    "\n",
    "    if 's' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
    "    elif 'm' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
    "    else:\n",
    "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL86sUi4ngtL"
   },
   "source": [
    "# base_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:22.131578Z",
     "iopub.status.busy": "2025-05-24T10:32:22.131344Z",
     "iopub.status.idle": "2025-05-24T10:32:23.066282Z",
     "shell.execute_reply": "2025-05-24T10:32:23.065577Z",
     "shell.execute_reply.started": "2025-05-24T10:32:22.131556Z"
    },
    "id": "yxhY6uIngb5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "y_k_size = 6\n",
    "x_k_size = 6\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 ignore_label=255,\n",
    "                 base_size=2048,\n",
    "                 crop_size=(1024, 1024),\n",
    "                 scale_factor=16,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]):\n",
    "\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.ignore_label = ignore_label\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        self.files = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def input_transform(self, image, city=False):\n",
    "        if city:\n",
    "            image = image.astype(np.float32)[:, :, ::-1]\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        image = image / 255.0\n",
    "        image -= self.mean\n",
    "        image /= self.std\n",
    "        return image\n",
    "\n",
    "    def label_transform(self, label):\n",
    "        return np.array(label).astype(np.uint8)\n",
    "\n",
    "    def pad_image(self, image, h, w, size, padvalue):\n",
    "        pad_h = max(size[0] - h, 0)\n",
    "        pad_w = max(size[1] - w, 0)\n",
    "\n",
    "        # Se non è necessario il padding, restituisci l'immagine originale\n",
    "        if pad_h == 0 and pad_w == 0:\n",
    "            return image\n",
    "\n",
    "        # Verifica il formato dell'immagine (deve essere H, W, C)\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        # Aggiungi il padding\n",
    "        pad_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=padvalue)\n",
    "\n",
    "        # Ripristina il formato originale (C, H, W) se necessario\n",
    "        if len(image.shape) == 3 and image.shape[2] <= 3:  # Se era in formato (C, H, W)\n",
    "            pad_image = np.transpose(pad_image, (2, 0, 1))  # Converti di nuovo in (C, H, W)\n",
    "\n",
    "        return pad_image\n",
    "\n",
    "    def rand_crop(self, image, label, edge):\n",
    "        # Verifica il formato dell'immagine\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Aggiungi padding se necessario\n",
    "        if h < self.crop_size[0] or w < self.crop_size[1]:\n",
    "            image = self.pad_image(image, h, w, self.crop_size, (0.0, 0.0, 0.0))\n",
    "            label = self.pad_image(label, h, w, self.crop_size, (self.ignore_label,))\n",
    "            edge = self.pad_image(edge, h, w, self.crop_size, (0.0,))\n",
    "\n",
    "        # Aggiorna le dimensioni dopo il padding\n",
    "        new_h, new_w = label.shape\n",
    "        if new_h < self.crop_size[0] or new_w < self.crop_size[1]:\n",
    "            raise ValueError(f\"Dimensioni insufficienti per il ritaglio: label={label.shape}, crop_size={self.crop_size}\")\n",
    "\n",
    "        # Calcola le coordinate per il ritaglio casuale\n",
    "        x = random.randint(0, new_w - self.crop_size[1])\n",
    "        y = random.randint(0, new_h - self.crop_size[0])\n",
    "\n",
    "        # Esegui il ritaglio\n",
    "        image = image[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        label = label[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        edge = edge[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "\n",
    "        #in questo modo l'iimagine è 512x512x3\n",
    "        #se volessi croppare quella regione\n",
    "        '''\n",
    "        # Estrai la regione da sfocare\n",
    "        cropped_region = image[y:y+crop_size[0], x:x+crop_size[1]]\n",
    "\n",
    "        # Applica il Gaussian Blur alla regione\n",
    "        blurred_region = cv2.GaussianBlur(cropped_region, (15, 15), 0)\n",
    "\n",
    "        # Sostituisci la regione originale con quella sfocata\n",
    "        augmented_image = image.copy()\n",
    "        augmented_image[y:y+crop_size[0], x:x+crop_size[1]] = blurred_region\n",
    "        '''\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "    def multi_scale_aug(self, image, label=None, edge=None,\n",
    "                        rand_scale=1, rand_crop=True):\n",
    "        long_size = int(self.base_size * rand_scale + 0.5)\n",
    "        h, w = image.shape[:2]\n",
    "        if h > w:\n",
    "            new_h = long_size\n",
    "            new_w = int(w * long_size / h + 0.5)\n",
    "        else:\n",
    "            new_w = long_size\n",
    "            new_h = int(h * long_size / w + 0.5)\n",
    "\n",
    "        image = cv2.resize(image, (new_w, new_h),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (new_w, new_h),\n",
    "                               interpolation=cv2.INTER_NEAREST)\n",
    "            if edge is not None:\n",
    "                edge = cv2.resize(edge, (new_w, new_h),\n",
    "                                   interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        if rand_crop:\n",
    "            image, label, edge = self.rand_crop(image, label, edge)\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def gen_sample(self, image, label, edge_pad=True, edge_size=4, city=False, transform=None, show=False):\n",
    "\n",
    "\n",
    "        if transform:\n",
    "            # Pass both image and mask\n",
    "            augmented = transform(image=image, mask=label)\n",
    "\n",
    "            if show:\n",
    "                show_images(image, augmented[\"image\"])\n",
    "\n",
    "            # Extract results\n",
    "            image = augmented['image']\n",
    "            label = augmented['mask']\n",
    "\n",
    "\n",
    "\n",
    "        #It' important keeping the edge generation after the data augmentation\n",
    "        edge = cv2.Canny(label, 0.1, 0.2)\n",
    "        kernel = np.ones((edge_size, edge_size), np.uint8)\n",
    "        if edge_pad:\n",
    "            edge = edge[y_k_size:-y_k_size, x_k_size:-x_k_size]\n",
    "            edge = np.pad(edge, ((y_k_size,y_k_size),(x_k_size,x_k_size)), mode='constant')\n",
    "        edge = (cv2.dilate(edge, kernel, iterations=1)>50)*1.0\n",
    "\n",
    "\n",
    "        #trasformazioni di input\n",
    "        image = self.input_transform(image, city=city) #Se city=True, converte l'immagine da RGB in BGR per opencv\n",
    "        label = self.label_transform(label) #converte la label in un array di interi\n",
    "        image = image.transpose((2, 0, 1)) #H,W,C -> C,H,W\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def inference(self, config, model, image):\n",
    "        size = image.size()\n",
    "        pred = model(image)\n",
    "\n",
    "        if config.MODEL.NUM_OUTPUTS > 1:\n",
    "            pred = pred[config.TEST.OUTPUT_INDEX]\n",
    "\n",
    "\n",
    "        pred = F.interpolate(\n",
    "            input=pred, size=size[-2:],\n",
    "            mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "        )\n",
    "\n",
    "\n",
    "        return pred.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwgVWGZaqIdl"
   },
   "source": [
    "# discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:23.067497Z",
     "iopub.status.busy": "2025-05-24T10:32:23.067107Z",
     "iopub.status.idle": "2025-05-24T10:32:23.073878Z",
     "shell.execute_reply": "2025-05-24T10:32:23.073140Z",
     "shell.execute_reply.started": "2025-05-24T10:32:23.067474Z"
    },
    "id": "GI5TiVbdqLuY"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "    #Discriminator based on GAN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FCDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, ndf = 64):\n",
    "        super(FCDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
    "        self.classifier = nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        #self.up_sample = nn.Upsample(scale_factor=32, mode='bilinear')\n",
    "        #self.sigmoid = nn.Sigmoid() #non uso sigmoid per la stabilità numerica a discapito di avere i logits e non le probabilità\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.classifier(x)\n",
    "        #x = self.up_sample(x)\n",
    "        #x = self.sigmoid(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOPrWJGJndSn"
   },
   "source": [
    "# loveda.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:23.074973Z",
     "iopub.status.busy": "2025-05-24T10:32:23.074739Z",
     "iopub.status.idle": "2025-05-24T10:32:24.221714Z",
     "shell.execute_reply": "2025-05-24T10:32:24.221194Z",
     "shell.execute_reply.started": "2025-05-24T10:32:23.074948Z"
    },
    "id": "FMHg7dVtgmKS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_images(image, blurred_image):\n",
    "    # Compute the absolute difference between the images\n",
    "    # Ensure both images are in the same format (H, W, C)\n",
    "    blurred_image = blurred_image.transpose(1, 2, 0)  # Change (C, H, W) to (H, W, C)\n",
    "\n",
    "    # Compute the absolute difference between the images\n",
    "    diff = np.abs(image - blurred_image)\n",
    "\n",
    "    # Plot the images and their difference side by side\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axs[0].imshow(image)  # Original image\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(blurred_image)  # Blurred image\n",
    "    axs[1].set_title(\"Blurred Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    axs[2].imshow(diff)  # Difference image\n",
    "    axs[2].set_title(\"Difference Image\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#classe per fare la data augmentation\n",
    "class DataAugmentation:\n",
    "    def __init__(self, config, dataset_instance):\n",
    "        self.enable = config[\"ENABLE\"]\n",
    "        self.probability = config[\"PROBABILITY\"]\n",
    "        self.techniques = config[\"TECHNIQUES\"]\n",
    "        self.dataset = dataset_instance  # Riferimento all'istanza del dataset\n",
    "\n",
    "    def apply(self, image, label, edge):\n",
    "\n",
    "        if not self.enable or random.random() > self.probability: #50% di probabilità di applicare la data augmentation\n",
    "            return image,label,edge #non faccio augmentation\n",
    "\n",
    "        if self.techniques.get(\"HORIZONTAL_FLIP\", False):\n",
    "            image,label,edge = self.horizontal_flip(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"GAUSSIAN_BLUR\", False):\n",
    "            image, label, edge = self.gaussian_blur(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"MULTIPLY\", False):\n",
    "            image, label, edge = self.multiply(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"RANDOM_BRIGHTNESS\", False):\n",
    "            image, label, edge = self.random_brightness(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"RANDOM_CROP\", False):\n",
    "            image, label, edge = self.random_crop(image, label, edge)\n",
    "\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "    def random_crop(self, image, label, edge):\n",
    "        return self.dataset.rand_crop(image, label, edge)  # Usa l'istanza del dataset\n",
    "\n",
    "\n",
    "\n",
    "    def horizontal_flip(self, image, label, edge):\n",
    "        # Inverti orizzontalmente immagine, label ed edge\n",
    "        flipped_image = image[:, :, ::-1]\n",
    "        flipped_label = label[:, ::-1]\n",
    "        flipped_edge = edge[:, ::-1]\n",
    "        return flipped_image, flipped_label, flipped_edge\n",
    "\n",
    "\n",
    "\n",
    "    def gaussian_blur(self, image, label, edge, kernel_size=5, show = False):\n",
    "        # Applica il Gaussian Blur solo all'immagine\n",
    "        transposed_image = image.transpose(1, 2, 0)  # From (C, H, W) to (H, W, C)\n",
    "\n",
    "        # Apply Gaussian blur\n",
    "        blurred_image = cv2.GaussianBlur(transposed_image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "        # If you want to return it to the PyTorch format (C, H, W)\n",
    "        blurred_image = blurred_image.transpose(2, 0, 1)  # From (H, W, C) to (C, H, W)\n",
    "\n",
    "        if show:\n",
    "            show_images(image, blurred_image)\n",
    "\n",
    "        return blurred_image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "    def multiply(self, image, label, edge, factor_range=(0.8, 1.2), show = False):\n",
    "        # Convert image to float32 to avoid overflow issues\n",
    "        factor = random.uniform(*factor_range)\n",
    "        image = image.astype(np.float32)  # Ensure safe multiplication\n",
    "\n",
    "        # Check if image is normalized (0-1), rescale before multiplication\n",
    "        if image.max() <= 1.0:\n",
    "            image *= 255.0  # Scale to 0-255 range before multiplication\n",
    "\n",
    "        multiplied_image = image * factor\n",
    "\n",
    "        if show:\n",
    "            show_images(image, multiplied_image)\n",
    "\n",
    "        return multiplied_image, label, edge\n",
    "\n",
    "    def random_brightness(self, image, label, edge, brightness_range=(-0.5, 0.5), show = False):\n",
    "        # Modify image brightness\n",
    "        brightness = np.float32(np.random.uniform(*brightness_range))\n",
    "        brightened_image = image + brightness  # Keep within [0,1]\n",
    "\n",
    "        if show:\n",
    "            show_images(image, brightened_image)\n",
    "        return brightened_image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "class LoveDA(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 list_path,\n",
    "                 num_classes=7,\n",
    "                 multi_scale=False,\n",
    "                 flip=False,\n",
    "                 ignore_label=0,\n",
    "                 base_size=1024,\n",
    "                 crop_size=(512, 512),\n",
    "                 scale_factor=16,\n",
    "                 enable_augmentation=False,\n",
    "                 augmentation_probability=0.5,\n",
    "                 horizontal_flip=False,\n",
    "                 gaussian_blur=False,\n",
    "                 multiply=False,\n",
    "                 random_brightness=False,\n",
    "                 random_crop=False,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225],\n",
    "                 bd_dilate_size=4,\n",
    "                 pseudo_label=False,\n",
    "                 transform=None):\n",
    "\n",
    "        # estende il base_dataset\n",
    "        super(LoveDA, self).__init__(ignore_label, base_size,\n",
    "                                     crop_size, scale_factor, mean, std)\n",
    "\n",
    "        self.root = root\n",
    "        self.list_path = list_path\n",
    "        self.num_classes = num_classes\n",
    "        self.multi_scale = multi_scale\n",
    "        self.flip = flip\n",
    "        self.ignore_label = ignore_label\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.enable_augmentation = enable_augmentation\n",
    "        self.augmentation_probability = augmentation_probability\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.gaussian_blur = gaussian_blur\n",
    "        self.multiply = multiply\n",
    "        self.random_brightness = random_brightness\n",
    "        self.random_crop = random_crop\n",
    "        self.bd_dilate_size = bd_dilate_size\n",
    "\n",
    "        self.img_list = [line.strip().split() for line in open(root + list_path)]\n",
    "        self.files = self.read_files()\n",
    "        self.color_list = [[0, 0, 0], [1, 1, 1], [2, 2, 2],\n",
    "                            [3, 3, 3], [4, 4, 4], [5, 5, 5], [6, 6, 6], [7, 7, 7]]\n",
    "        self.class_weights = torch.tensor([0.000000, 0.116411, 0.266041, 0.607794, 1.511413, 0.745507, 0.712438, 3.040396])\n",
    "        self.pseudo_label = pseudo_label\n",
    "        self.transform=transform\n",
    "\n",
    "    def read_files(self):\n",
    "        files = []\n",
    "\n",
    "        for item in self.img_list:\n",
    "            image_path, label_path = item\n",
    "            name = os.path.splitext(os.path.basename(label_path))[0]\n",
    "            files.append({\n",
    "                \"img\": image_path,\n",
    "                \"label\": label_path,\n",
    "                \"name\": name\n",
    "            })\n",
    "\n",
    "        return files\n",
    "\n",
    "    # da immagine a label\n",
    "    def color2label(self, color_map):\n",
    "        label = np.ones(color_map.shape[:2]) * self.ignore_label\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            label[(color_map == v).sum(2) == 3] = i\n",
    "\n",
    "        return label.astype(np.uint8)\n",
    "\n",
    "    def convert_label(self, label, inverse=False):\n",
    "        temp = label.copy()\n",
    "        if inverse:\n",
    "            for v, k in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        else:\n",
    "            for k, v in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        return label\n",
    "\n",
    "    # da label a immagine\n",
    "    def label2color(self, label):\n",
    "        color_map = np.zeros(label.shape + (3,))\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            color_map[label == i] = self.color_list[i]\n",
    "\n",
    "        return color_map.astype(np.uint8)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.files[index]\n",
    "        name = item[\"name\"]\n",
    "        image = cv2.imread(item[\"img\"], cv2.IMREAD_COLOR)\n",
    "\n",
    "        size = image.shape\n",
    "\n",
    "        label = cv2.imread(item[\"label\"], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "        #edge (H,W)\n",
    "        image, label, edge = self.gen_sample(image, label, edge_pad=False,\n",
    "                                             edge_size=self.bd_dilate_size, city=False, transform=self.transform, show=False) #image diventa (C,H,W)\n",
    "\n",
    "        return image.copy(), label.copy(), edge.copy(), np.array(size), name\n",
    "\n",
    "    def single_scale_inference(self, config, model, image):\n",
    "        pred = self.inference(config, model, image)\n",
    "        return pred\n",
    "\n",
    "    def save_pred(self, preds, sv_path, name):\n",
    "        preds = np.asarray(np.argmax(preds.cpu(), axis=1), dtype=np.uint8)\n",
    "        for i in range(preds.shape[0]):\n",
    "            pred = self.label2color(preds[i])\n",
    "            save_img = Image.fromarray(pred)\n",
    "            save_img.save(os.path.join(sv_path, name[i] + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWtVHwfinr5g"
   },
   "source": [
    "# criterion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:24.222723Z",
     "iopub.status.busy": "2025-05-24T10:32:24.222436Z",
     "iopub.status.idle": "2025-05-24T10:32:24.240094Z",
     "shell.execute_reply": "2025-05-24T10:32:24.239403Z",
     "shell.execute_reply.started": "2025-05-24T10:32:24.222707Z"
    },
    "id": "h1yOyy_NhYqb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from configs import config\n",
    "\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if config.MODEL.NUM_OUTPUTS == 1:\n",
    "            score = [score]\n",
    "\n",
    "        balance_weights = config.LOSS.BALANCE_WEIGHTS\n",
    "        sb_weights = config.LOSS.SB_WEIGHTS\n",
    "        if len(balance_weights) == len(score):\n",
    "            return sum([w * self._forward(x, target) for (w, x) in zip(balance_weights, score)])\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class OhemCrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, thres=0.7,\n",
    "                 min_kept=100000, weight=None):\n",
    "        super(OhemCrossEntropy, self).__init__()\n",
    "        self.thresh = thres\n",
    "        self.min_kept = max(1, min_kept)\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label,\n",
    "            reduction='none'\n",
    "        )\n",
    "\n",
    "    def _ce_forward(self, score, target):\n",
    "\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _ohem_forward(self, score, target, **kwargs):\n",
    "\n",
    "        pred = F.softmax(score, dim=1)\n",
    "        pixel_losses = self.criterion(score, target).contiguous().view(-1)\n",
    "        mask = target.contiguous().view(-1) != self.ignore_label\n",
    "\n",
    "        tmp_target = target.clone()\n",
    "        tmp_target[tmp_target == self.ignore_label] = 0\n",
    "        pred = pred.gather(1, tmp_target.unsqueeze(1))\n",
    "        pred, ind = pred.contiguous().view(-1,)[mask].contiguous().sort()\n",
    "        min_value = pred[min(self.min_kept, pred.numel() - 1)]\n",
    "        threshold = max(min_value, self.thresh)\n",
    "\n",
    "        pixel_losses = pixel_losses[mask][ind]\n",
    "        pixel_losses = pixel_losses[pred < threshold]\n",
    "        return pixel_losses.mean()\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if not (isinstance(score, list) or isinstance(score, tuple)):\n",
    "            score = [score]\n",
    "\n",
    "        balance_weights = config.LOSS.BALANCE_WEIGHTS\n",
    "        sb_weights = config.LOSS.SB_WEIGHTS\n",
    "        if len(balance_weights) == len(score):\n",
    "            functions = [self._ce_forward] * \\\n",
    "                (len(balance_weights) - 1) + [self._ohem_forward]\n",
    "            return sum([\n",
    "                w * func(x, target)\n",
    "                for (w, x, func) in zip(balance_weights, score, functions)\n",
    "            ])\n",
    "\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._ohem_forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "def weighted_bce(bd_pre, target):\n",
    "    n, c, h, w = bd_pre.size()\n",
    "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
    "    target_t = target.view(1, -1)\n",
    "\n",
    "    pos_index = (target_t == 1)\n",
    "    neg_index = (target_t == 0)\n",
    "\n",
    "    weight = torch.zeros_like(log_p)\n",
    "    pos_num = pos_index.sum()\n",
    "    neg_num = neg_index.sum()\n",
    "    sum_num = pos_num + neg_num\n",
    "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
    "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class BondaryLoss(nn.Module):\n",
    "    def __init__(self, coeff_bce = 20.0):\n",
    "        super(BondaryLoss, self).__init__()\n",
    "        self.coeff_bce = coeff_bce\n",
    "\n",
    "    def forward(self, bd_pre, bd_gt):\n",
    "\n",
    "        bce_loss = self.coeff_bce * weighted_bce(bd_pre, bd_gt)\n",
    "        loss = bce_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGSIbNfzoHXo"
   },
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:24.241161Z",
     "iopub.status.busy": "2025-05-24T10:32:24.240953Z",
     "iopub.status.idle": "2025-05-24T10:32:24.261672Z",
     "shell.execute_reply": "2025-05-24T10:32:24.261122Z",
     "shell.execute_reply.started": "2025-05-24T10:32:24.241137Z"
    },
    "id": "n8P5mZLNh-Ho"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from configs import default\n",
    "config = default._C.clone()\n",
    "update_config = default.update_config\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "\n",
    "  def __init__(self, model, sem_loss, bd_loss):\n",
    "    super(FullModel, self).__init__()\n",
    "    self.model = model\n",
    "    self.sem_loss = sem_loss\n",
    "    self.bd_loss = bd_loss\n",
    "\n",
    "  def pixel_acc(self, pred, label):\n",
    "    _, preds = torch.max(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc\n",
    "\n",
    "  def forward(self, inputs, labels, bd_gt, *args, **kwargs):\n",
    "\n",
    "    outputs = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "    h, w = labels.size(1), labels.size(2)\n",
    "    ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
    "    if ph != h or pw != w:\n",
    "        for i in range(len(outputs)):\n",
    "            outputs[i] = F.interpolate(outputs[i], size=(\n",
    "                h, w), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "\n",
    "    acc  = self.pixel_acc(outputs[-2], labels)\n",
    "    loss_s = self.sem_loss(outputs[:-1], labels)\n",
    "    loss_b = self.bd_loss(outputs[-1], bd_gt)\n",
    "\n",
    "    filler = torch.ones_like(labels) * config.TRAIN.IGNORE_LABEL\n",
    "    try:\n",
    "        bd_label = torch.where(torch.sigmoid(outputs[-1][:, 0, :, :]) > 0.8, labels, filler) # 0.7\n",
    "        loss_sb = self.sem_loss([outputs[-2]], bd_label)\n",
    "    except:\n",
    "        print(\"Error in loss computation\")\n",
    "        loss_sb = self.sem_loss([outputs[-2]], labels)\n",
    "    loss = loss_s + loss_b + loss_sb\n",
    "\n",
    "    return torch.unsqueeze(loss,0), outputs[:-1], acc, [loss_s, loss_b] #aoutputs[:-1] è una lista di tensori\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg\n",
    "\n",
    "def create_logger(cfg, cfg_name, phase='train'):\n",
    "    root_output_dir = Path(cfg.OUTPUT_DIR)\n",
    "\n",
    "    if (\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER\n",
    "        ):\n",
    "        folder_name = \"no_aug\"\n",
    "    else:\n",
    "        folder_name = \"aug\"\n",
    "\n",
    "    if cfg.TRAIN.DACS.ENABLE:\n",
    "        folder_name = \"dacs\"\n",
    "\n",
    "    if cfg.TRAIN.GAN.ENABLE:\n",
    "        folder_name = \"gan\"\n",
    "\n",
    "    if cfg.TRAIN.AUGMENTATION.ENABLE:\n",
    "        folder_name+= \"_hf\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP else \"\"\n",
    "        folder_name+= \"_gb\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR else \"\"\n",
    "        folder_name+= \"_rc\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP else \"\"\n",
    "        folder_name+= \"_cj\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER else \"\"\n",
    "        folder_name+= \"_gn\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE else \"\"\n",
    "\n",
    "    # set up logger\n",
    "    if not root_output_dir.exists():\n",
    "        print('=> creating {}'.format(root_output_dir))\n",
    "        root_output_dir.mkdir()\n",
    "\n",
    "    dataset = cfg.DATASET.DATASET\n",
    "    model = cfg.MODEL.NAME\n",
    "    cfg_name = os.path.basename(cfg_name).split('.')[0]\n",
    "\n",
    "    final_output_dir = root_output_dir / dataset / cfg_name / folder_name\n",
    "\n",
    "    print('=> creating {}'.format(final_output_dir))\n",
    "    final_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    time_str = time.strftime('%Y-%m-%d-%H-%M')\n",
    "    log_file = '{}_{}_{}.log'.format(cfg_name, time_str, phase)\n",
    "    final_log_file = final_output_dir / log_file\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=str(final_log_file),\n",
    "                        format=head)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    console = logging.StreamHandler()\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    tensorboard_log_dir = Path(cfg.LOG_DIR) / dataset / model / \\\n",
    "            (cfg_name + '_' + time_str)\n",
    "    print('=> creating {}'.format(tensorboard_log_dir))\n",
    "    tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return logger, str(final_output_dir), str(tensorboard_log_dir)\n",
    "\n",
    "def get_confusion_matrix(label, pred, size, num_class, ignore=-1):\n",
    "    \"\"\"\n",
    "    Calcute the confusion matrix by given label and pred\n",
    "    \"\"\"\n",
    "    output = pred.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    seg_pred = np.asarray(np.argmax(output, axis=3), dtype=np.uint8)\n",
    "    seg_gt = np.asarray(\n",
    "    label.cpu().numpy()[:, :size[-2], :size[-1]], dtype=int)\n",
    "\n",
    "    ignore_index = seg_gt != ignore\n",
    "    seg_gt = seg_gt[ignore_index]\n",
    "    seg_pred = seg_pred[ignore_index]\n",
    "\n",
    "    index = (seg_gt * num_class + seg_pred).astype('int32')\n",
    "    label_count = np.bincount(index)\n",
    "    confusion_matrix = np.zeros((num_class, num_class))\n",
    "\n",
    "    for i_label in range(num_class):\n",
    "        for i_pred in range(num_class):\n",
    "            cur_index = i_label * num_class + i_pred\n",
    "            if cur_index < len(label_count):\n",
    "                confusion_matrix[i_label,\n",
    "                                 i_pred] = label_count[cur_index]\n",
    "    return confusion_matrix\n",
    "\n",
    "def adjust_learning_rate(optimizer, base_lr, max_iters,cur_iters, power=0.9, nbb_mult=10):\n",
    "    \n",
    "    lr = base_lr*((1-float(cur_iters)/max_iters)**(power))\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    if len(optimizer.param_groups) == 2:\n",
    "        optimizer.param_groups[1]['lr'] = lr * nbb_mult\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a9CgnuKo-6G"
   },
   "source": [
    "# function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:24.322920Z",
     "iopub.status.busy": "2025-05-24T10:32:24.322680Z",
     "iopub.status.idle": "2025-05-24T10:32:24.374634Z",
     "shell.execute_reply": "2025-05-24T10:32:24.374010Z",
     "shell.execute_reply.started": "2025-05-24T10:32:24.322895Z"
    },
    "id": "wzdMHgT9htZC"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(config, epoch, num_epoch, epoch_iters, base_lr,\n",
    "          num_iters, trainloader, optimizer, model, writer_dict, targetloader=None):\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    ave_loss = AverageMeter()\n",
    "    ave_acc  = AverageMeter()\n",
    "    avg_sem_loss = AverageMeter()\n",
    "    avg_bce_loss = AverageMeter()\n",
    "    tic = time.time()\n",
    "    cur_iters = epoch*epoch_iters\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['train_global_steps']\n",
    "\n",
    "    if targetloader is not None:\n",
    "        target_iter = iter(targetloader)\n",
    "\n",
    "    for i_iter, batch in enumerate(trainloader, 0):\n",
    "       \n",
    "        images, labels, bd_gts, _, _ = batch\n",
    "        images = images.cuda()\n",
    "        labels = labels.long().cuda()\n",
    "        bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "\n",
    "        losses, _, acc, loss_list = model(images, labels, bd_gts)\n",
    "        loss = losses.mean()\n",
    "        acc  = acc.mean()\n",
    "        sem_loss = loss_list[0]\n",
    "        bce_loss = loss_list[1]\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - tic)\n",
    "        tic = time.time()\n",
    "\n",
    "        # update average loss\n",
    "        ave_loss.update(loss.item())\n",
    "        ave_acc.update(acc.item())\n",
    "        avg_sem_loss.update(sem_loss.mean().item())\n",
    "        avg_bce_loss.update(bce_loss.mean().item())\n",
    "\n",
    "        lr = adjust_learning_rate(optimizer,\n",
    "                                  base_lr,\n",
    "                                  num_iters,\n",
    "                                  i_iter+cur_iters)\n",
    "\n",
    "        if i_iter % config.PRINT_FREQ == 0:\n",
    "            msg = 'Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, ' \\\n",
    "                  'lr: {}, Loss: {:.6f}, Acc:{:.6f}, Semantic loss: {:.6f}, BCE loss: {:.6f}, SB loss: {:.6f}' .format(\n",
    "                      epoch, num_epoch, i_iter, epoch_iters,\n",
    "                      batch_time.average(), [x['lr'] for x in optimizer.param_groups], ave_loss.average(),\n",
    "                      ave_acc.average(), avg_sem_loss.average(), avg_bce_loss.average(),ave_loss.average()-avg_sem_loss.average()-avg_bce_loss.average())\n",
    "            logging.info(msg)\n",
    "\n",
    "    writer.add_scalar('train_loss', ave_loss.average(), global_steps)\n",
    "    writer_dict['train_global_steps'] = global_steps + 1\n",
    "\n",
    "    # Ritorna la loss media per l'epoca\n",
    "    return ave_loss.average()\n",
    "\n",
    "def validate(config, testloader, model, writer_dict):\n",
    "    model.eval()\n",
    "    ave_loss = AverageMeter()\n",
    "    nums = config.MODEL.NUM_OUTPUTS\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES, nums))\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testloader):\n",
    "            image, label, bd_gts, _, _ = batch\n",
    "            size = label.size()\n",
    "            image = image.cuda()\n",
    "            label = label.long().cuda()\n",
    "            bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "            losses, pred, _, _ = model(image, label, bd_gts)\n",
    "            if not isinstance(pred, (list, tuple)):\n",
    "                pred = [pred]\n",
    "            for i, x in enumerate(pred):\n",
    "                x = F.interpolate(\n",
    "                    input=x, size=size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "                confusion_matrix[..., i] += get_confusion_matrix(\n",
    "                    label,\n",
    "                    x,\n",
    "                    size,\n",
    "                    config.DATASET.NUM_CLASSES,\n",
    "                    config.TRAIN.IGNORE_LABEL\n",
    "                )\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            loss = losses.mean()\n",
    "            ave_loss.update(loss.item())\n",
    "\n",
    "    for i in range(nums):\n",
    "        pos = confusion_matrix[..., i].sum(1)\n",
    "        res = confusion_matrix[..., i].sum(0)\n",
    "        tp = np.diag(confusion_matrix[..., i])\n",
    "        IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "        \n",
    "        ignore_index = 0 \n",
    "        valid_classes = [i for i in range(config.DATASET.NUM_CLASSES) if i != ignore_index]\n",
    "        mean_IoU = IoU_array[valid_classes].mean()\n",
    "\n",
    "        logging.info('{} {} {}'.format(i, IoU_array, mean_IoU))\n",
    "\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['valid_global_steps']\n",
    "    writer.add_scalar('valid_loss', ave_loss.average(), global_steps)\n",
    "    writer.add_scalar('valid_mIoU', mean_IoU, global_steps)\n",
    "    writer_dict['valid_global_steps'] = global_steps + 1\n",
    "    return ave_loss.average(), mean_IoU, IoU_array\n",
    "\n",
    "\n",
    "def testval(config, test_dataset, testloader, model,\n",
    "            sv_dir='./', sv_pred=False):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(testloader)):\n",
    "            image, label, _, _, name = batch\n",
    "            size = label.size()\n",
    "            pred = test_dataset.single_scale_inference(config, model, image.cuda())\n",
    "\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.interpolate(\n",
    "                    pred, size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                test_dataset.save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum()/pos.sum()\n",
    "    mean_acc = (tp/np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def test(config, test_dataset, testloader, model,\n",
    "         sv_dir='./', sv_pred=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(tqdm(testloader)):\n",
    "            image, size, name = batch\n",
    "            size = size[0]\n",
    "            pred = test_dataset.single_scale_inference(\n",
    "                config,\n",
    "                model,\n",
    "                image.cuda())\n",
    "\n",
    "            if pred.size()[-2] != size[0] or pred.size()[-1] != size[1]:\n",
    "                pred = F.interpolate(\n",
    "                    pred, size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir,'test_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                test_dataset.save_pred(pred, sv_path, name)\n",
    "\n",
    "def train_adv(config, epoch, num_epoch, epoch_iters, base_lr,\n",
    "          num_iters, trainloader, targetloader, optimizer_G, optimizer_D, \n",
    "          model, discriminator, writer_dict, lambda_adv=0.01, iter_size=4):\n",
    "\n",
    "    if epoch < 10:\n",
    "        lambda_adv = 0.01  # all'inizio, il D è debole → serve feedback forte\n",
    "    else:\n",
    "        lambda_adv = 0.002  # poi riduci, per non far dominare il D\n",
    "\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    ave_loss = AverageMeter()\n",
    "    ave_acc = AverageMeter()\n",
    "    avg_sem_loss = AverageMeter()\n",
    "    avg_bce_loss = AverageMeter()\n",
    "    \n",
    "    tic = time.time()\n",
    "    cur_iters = epoch * epoch_iters\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['train_global_steps']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    cumulative_loss_G = 0.0\n",
    "    cumulative_loss_adv = 0.0\n",
    "    cumulative_loss_D_src = 0.0\n",
    "    cumulative_loss_D_trg = 0.0\n",
    "    count=0\n",
    "    base_lr_D = 0.0005\n",
    "    loss_D_src = 0.0 #per eventuale warmup\n",
    "    loss_D_trg= 0.0\n",
    "    \n",
    "\n",
    "    freeze_until_epoch = 0 #freeze del discriminatore\n",
    "\n",
    "\n",
    "    for i_iter, (batch_source, batch_target) in enumerate(zip(trainloader, targetloader)):\n",
    "\n",
    "        freeze_D = epoch < freeze_until_epoch\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        \n",
    "\n",
    "        #Train G\n",
    "        # don't accumulate grads in D\n",
    "        for param in discriminator.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        images_source, labels, bd_gts, _, _ = batch_source\n",
    "        images_target, _, _, _, _ = batch_target\n",
    "\n",
    "        images_source = images_source.to(device)\n",
    "        images_target = images_target.to(device)\n",
    "        labels = labels.long().to(device)\n",
    "        bd_gts = bd_gts.float().to(device)\n",
    "\n",
    "\n",
    "        # ------------------ TRAINING DEL GENERATORE ------------------\n",
    "        # 1. Forward seg net per dominio sorgente (supervisionato)\n",
    "        loss_seg1, output_source, _, _ = model(images_source, labels, bd_gts) #retun delle 3 loss sommate ma unsqueezed\n",
    "        loss_seg1 = torch.squeeze(loss_seg1, 0).mean()\n",
    "        loss_seg1.backward()\n",
    "        cumulative_loss_G += loss_seg1.data.cpu().numpy()\n",
    "\n",
    "        # Forward pass per il dominio target (adversarial)\n",
    "        _, output_target, _, _ = model(images_target, labels, bd_gts)\n",
    "        fake_preds = discriminator(F.softmax(output_target[-1], dim=1))\n",
    "\n",
    "        bce = nn.BCEWithLogitsLoss()\n",
    "        loss_adv = bce(fake_preds, torch.zeros_like(fake_preds))\n",
    "        loss_adv = loss_adv * lambda_adv\n",
    "        #cumulative_loss_G += loss_adv.item()\n",
    "        loss_adv.backward()\n",
    "        cumulative_loss_adv += loss_adv.data.cpu().numpy()\n",
    "\n",
    "\n",
    "        # ------------------ TRAINING DEL DISCRIMINATORE------------------\n",
    "        if not freeze_D: #per freeze globale \n",
    "            \n",
    "            if 10 <= epoch <= 12:\n",
    "                for p in discriminator.parameters():\n",
    "                    p.requires_grad = False\n",
    "                pass\n",
    "            else:\n",
    "                for p in discriminator.parameters():\n",
    "                    p.requires_grad = True\n",
    "    \n",
    "                output_source = [t.detach() for t in output_source]\n",
    "                output_target = [t.detach() for t in output_target]\n",
    "        \n",
    "               \n",
    "                # train su source\n",
    "                fake_preds1_d = discriminator(F.softmax(output_source[-1], dim=1)) \n",
    "                bce = nn.BCEWithLogitsLoss()\n",
    "                loss_D_src = bce(fake_preds1_d, torch.zeros_like(fake_preds1_d))\n",
    "                loss_D_src.backward()\n",
    "                cumulative_loss_D_src += loss_D_src.data.cpu().numpy()\n",
    "             \n",
    "                \n",
    "                # train su target\n",
    "                fake_preds1_d_t = discriminator(F.softmax(output_target[-1], dim=1)) \n",
    "                bce = nn.BCEWithLogitsLoss()\n",
    "                loss_D_trg = bce(fake_preds1_d_t, torch.ones_like(fake_preds1_d_t))\n",
    "                loss_D_trg.backward()\n",
    "                cumulative_loss_D_trg += loss_D_trg.data.cpu().numpy()\n",
    "    \n",
    "                if i_iter % 2 == 0: #aggiorno ogni 2 epoche\n",
    "                    optimizer_D.step()\n",
    "        else:\n",
    "            # se D è freezato, skippa completamente backward e step\n",
    "            pass\n",
    "        #--\n",
    "       \n",
    "        optimizer_G.step()\n",
    "        \n",
    "\n",
    "        # Log\n",
    "        count+=1\n",
    "        batch_time.update(time.time() - tic)\n",
    "        tic = time.time()\n",
    "\n",
    "        lr_g = adjust_learning_rate(optimizer_G, base_lr, num_iters, i_iter + cur_iters)\n",
    "        lr_d = adjust_learning_rate(optimizer_D, base_lr_D, num_iters, i_iter + cur_iters, power=1.5)\n",
    "        \n",
    "\n",
    "        if i_iter % config.PRINT_FREQ == 0:\n",
    "            msg = ('Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, lr_generatore: {}, '\n",
    "                   'Loss_seg: {:.6f}, loss_adv: {:.6f}, loss_D_src: {:.6f}, loss_D_trg: {:.6f}').format(\n",
    "                      epoch, num_epoch, i_iter, epoch_iters, batch_time.average(),[x['lr'] for x in optimizer_G.param_groups], \n",
    "                      loss_seg1, loss_adv, loss_D_src, loss_D_trg\n",
    "                  )\n",
    "            logging.info(msg)\n",
    "\n",
    "\n",
    "    avg_loss_seg   = cumulative_loss_G      / count \n",
    "    avg_loss_adv   = cumulative_loss_adv    / count\n",
    "    avg_loss_D_src = cumulative_loss_D_src  / count\n",
    "    avg_loss_D_trg = cumulative_loss_D_trg  / count\n",
    "\n",
    "    writer.add_scalar('Loss/seg',   avg_loss_seg,   global_steps)\n",
    "    writer.add_scalar('Loss/adv',   avg_loss_adv,   global_steps)\n",
    "    writer.add_scalar('Loss/D_src', avg_loss_D_src, global_steps)\n",
    "    writer.add_scalar('Loss/D_trg', avg_loss_D_trg, global_steps)\n",
    "    writer_dict['train_global_steps'] += 1\n",
    "\n",
    "    \n",
    "    # Ritorna la loss media per l'epoca\n",
    "    final_loss  = ( cumulative_loss_adv + cumulative_loss_D_src + cumulative_loss_D_trg + cumulative_loss_G) / count\n",
    "    msg = ('Epoch: [{}/{}], loss_sum: {:.6f}').format(epoch, num_epoch, final_loss)\n",
    "    logging.info(msg)\n",
    "\n",
    "    return final_loss, avg_loss_seg, avg_loss_adv, avg_loss_D_src, avg_loss_D_trg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:32:24.375496Z",
     "iopub.status.busy": "2025-05-24T10:32:24.375311Z",
     "iopub.status.idle": "2025-05-24T13:06:08.835006Z",
     "shell.execute_reply": "2025-05-24T13:06:08.834116Z",
     "shell.execute_reply.started": "2025-05-24T10:32:24.375481Z"
    },
    "id": "fhmkK1Xpg8Uk",
    "outputId": "070b97ec-3dfc-4042-d058-9ead37ba2cad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/loveda/pidnet_small_loveda.yaml', seed=304, opts=[])\n",
      "AUTO_RESUME: False\n",
      "CUDNN:\n",
      "  BENCHMARK: True\n",
      "  DETERMINISTIC: False\n",
      "  ENABLED: True\n",
      "DATASET:\n",
      "  DATASET: loveda\n",
      "  EXTRA_TRAIN_SET: \n",
      "  NUM_CLASSES: 8\n",
      "  ROOT: data/\n",
      "  TARGET_SET: list/loveda/rural/train.lst\n",
      "  TEST_SET: list/loveda/urban_rural/val.lst\n",
      "  TRAIN_SET: list/loveda/urban_rural/train.lst\n",
      "GPUS: (0,)\n",
      "LOG_DIR: log\n",
      "LOSS:\n",
      "  BALANCE_WEIGHTS: [0.4, 1.0]\n",
      "  CLASS_BALANCE: False\n",
      "  OHEMKEEP: 131072\n",
      "  OHEMTHRES: 0.9\n",
      "  SB_WEIGHTS: 1.0\n",
      "  USE_OHEM: True\n",
      "MODEL:\n",
      "  ALIGN_CORNERS: True\n",
      "  NAME: pidnet_small\n",
      "  NUM_OUTPUTS: 2\n",
      "  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar\n",
      "OUTPUT_DIR: output\n",
      "PIN_MEMORY: True\n",
      "PRINT_FREQ: 10\n",
      "TEST:\n",
      "  BASE_SIZE: 1024\n",
      "  BATCH_SIZE_PER_GPU: 6\n",
      "  FLIP_TEST: False\n",
      "  IMAGE_SIZE: [1024, 1024]\n",
      "  MODEL_FILE: output/loveda/pidnet_small_loveda/final_state.pt\n",
      "  MULTI_SCALE: False\n",
      "  OUTPUT_INDEX: 1\n",
      "TRAIN:\n",
      "  AUGMENTATION:\n",
      "    ENABLE: True\n",
      "    PROBABILITY: 0.5\n",
      "    TECHNIQUES:\n",
      "      COLOR_JITTER: True\n",
      "      GAUSSIAN_BLUR: False\n",
      "      GAUSSIAN_NOISE: False\n",
      "      HORIZONTAL_FLIP: False\n",
      "      RANDOM_CROP: False\n",
      "  BASE_SIZE: 1024\n",
      "  BATCH_SIZE_PER_GPU: 6\n",
      "  BEGIN_EPOCH: 0\n",
      "  DACS:\n",
      "    ENABLE: False\n",
      "    THRESHOLD: 0.968\n",
      "  END_EPOCH: 20\n",
      "  EXTRA_EPOCH: 0\n",
      "  EXTRA_LR: 0.001\n",
      "  FDA:\n",
      "    ENABLE: False\n",
      "  FLIP: False\n",
      "  GAN:\n",
      "    ENABLE: True\n",
      "    MULTI_LEVEL: False\n",
      "  IGNORE_LABEL: 0\n",
      "  IMAGE_SIZE: [1024, 1024]\n",
      "  LR: 0.005\n",
      "  MOMENTUM: 0.9\n",
      "  MULTI_SCALE: False\n",
      "  NESTEROV: False\n",
      "  OPTIMIZER: sgd\n",
      "  RESUME: False\n",
      "  SCALE_FACTOR: 16\n",
      "  SHUFFLE: True\n",
      "  WD: 0.0005\n",
      "WORKERS: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding with 304\n",
      "=> creating output/loveda/pidnet_small_loveda/gan_cj\n",
      "=> creating log/loveda/pidnet_small/pidnet_small_loveda_2025-05-24-10-32\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/4253090261.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
      "Attention!!!\n",
      "Loaded 302 parameters!\n",
      "Over!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train with standard dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [0/20] Iter:[0/192], Time: 50.20, lr_generatore: [0.005], Loss_seg: 12.420799, loss_adv: 0.006964, loss_D_src: 0.696476, loss_D_trg: 0.689862\n",
      "Epoch: [0/20] Iter:[10/192], Time: 5.67, lr_generatore: [0.004988279722662096], Loss_seg: 6.692202, loss_adv: 0.006715, loss_D_src: 0.670698, loss_D_trg: 0.715478\n",
      "Epoch: [0/20] Iter:[20/192], Time: 3.56, lr_generatore: [0.0049765563847963806], Loss_seg: 5.239687, loss_adv: 0.007074, loss_D_src: 0.705183, loss_D_trg: 0.680651\n",
      "Epoch: [0/20] Iter:[30/192], Time: 2.81, lr_generatore: [0.004964829977588641], Loss_seg: 3.403477, loss_adv: 0.006508, loss_D_src: 0.649604, loss_D_trg: 0.738825\n",
      "Epoch: [0/20] Iter:[40/192], Time: 2.42, lr_generatore: [0.004953100492176077], Loss_seg: 2.860073, loss_adv: 0.007009, loss_D_src: 0.700411, loss_D_trg: 0.685498\n",
      "Epoch: [0/20] Iter:[50/192], Time: 2.18, lr_generatore: [0.0049413679196469015], Loss_seg: 3.381996, loss_adv: 0.006719, loss_D_src: 0.668850, loss_D_trg: 0.715194\n",
      "Epoch: [0/20] Iter:[60/192], Time: 2.03, lr_generatore: [0.004929632251039945], Loss_seg: 2.890526, loss_adv: 0.006966, loss_D_src: 0.702288, loss_D_trg: 0.691637\n",
      "Epoch: [0/20] Iter:[70/192], Time: 1.92, lr_generatore: [0.004917893477344243], Loss_seg: 4.182461, loss_adv: 0.007160, loss_D_src: 0.700159, loss_D_trg: 0.673072\n",
      "Epoch: [0/20] Iter:[80/192], Time: 1.83, lr_generatore: [0.00490615158949863], Loss_seg: 5.818488, loss_adv: 0.006940, loss_D_src: 0.645541, loss_D_trg: 0.701334\n",
      "Epoch: [0/20] Iter:[90/192], Time: 1.77, lr_generatore: [0.004894406578391331], Loss_seg: 2.635214, loss_adv: 0.007574, loss_D_src: 0.734778, loss_D_trg: 0.643448\n",
      "Epoch: [0/20] Iter:[100/192], Time: 1.72, lr_generatore: [0.004882658434859534], Loss_seg: 3.393737, loss_adv: 0.007059, loss_D_src: 0.691253, loss_D_trg: 0.680820\n",
      "Epoch: [0/20] Iter:[110/192], Time: 1.68, lr_generatore: [0.004870907149688971], Loss_seg: 2.352908, loss_adv: 0.007254, loss_D_src: 0.709295, loss_D_trg: 0.662758\n",
      "Epoch: [0/20] Iter:[120/192], Time: 1.64, lr_generatore: [0.004859152713613493], Loss_seg: 2.335856, loss_adv: 0.006769, loss_D_src: 0.645291, loss_D_trg: 0.730384\n",
      "Epoch: [0/20] Iter:[130/192], Time: 1.61, lr_generatore: [0.004847395117314633], Loss_seg: 2.883937, loss_adv: 0.007114, loss_D_src: 0.684421, loss_D_trg: 0.703210\n",
      "Epoch: [0/20] Iter:[140/192], Time: 1.59, lr_generatore: [0.004835634351421169], Loss_seg: 3.258329, loss_adv: 0.007476, loss_D_src: 0.680749, loss_D_trg: 0.666475\n",
      "Epoch: [0/20] Iter:[150/192], Time: 1.56, lr_generatore: [0.004823870406508688], Loss_seg: 3.043337, loss_adv: 0.007581, loss_D_src: 0.722893, loss_D_trg: 0.649971\n",
      "Epoch: [0/20] Iter:[160/192], Time: 1.55, lr_generatore: [0.004812103273099131], Loss_seg: 2.663294, loss_adv: 0.006960, loss_D_src: 0.715955, loss_D_trg: 0.716413\n",
      "Epoch: [0/20] Iter:[170/192], Time: 1.53, lr_generatore: [0.004800332941660344], Loss_seg: 2.265907, loss_adv: 0.006803, loss_D_src: 0.675858, loss_D_trg: 0.707217\n",
      "Epoch: [0/20] Iter:[180/192], Time: 1.51, lr_generatore: [0.004788559402605627], Loss_seg: 2.723429, loss_adv: 0.006757, loss_D_src: 0.642822, loss_D_trg: 0.714527\n",
      "Epoch: [0/20] Iter:[190/192], Time: 1.50, lr_generatore: [0.004776782646293261], Loss_seg: 2.126683, loss_adv: 0.007793, loss_D_src: 0.699444, loss_D_trg: 0.647991\n",
      "Epoch: [0/20], loss_sum: 4.733057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 3.347218, Loss_Adv (G): 0.007073, Loss_D_Src: 0.687284, Loss_D_Trg: 0.691482\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.24545734 0.15255376 0.05766185 0.22351673 0.0652692\n",
      " 0.11030354 0.1525339 ] 0.14389947399636904\n",
      "1 [0.         0.31828617 0.21302041 0.0893231  0.33829139 0.02465713\n",
      " 0.15134987 0.18679645] 0.18881778847487457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.538, MeanIU:  0.1888, Best_mIoU:  0.1888\n",
      "[0.         0.31828617 0.21302041 0.0893231  0.33829139 0.02465713\n",
      " 0.15134987 0.18679645]\n",
      "Epoch: [1/20] Iter:[0/192], Time: 5.67, lr_generatore: [0.004774426908107499], Loss_seg: 2.260573, loss_adv: 0.006926, loss_D_src: 0.692738, loss_D_trg: 0.693731\n",
      "Epoch: [1/20] Iter:[10/192], Time: 1.74, lr_generatore: [0.004762646278280739], Loss_seg: 2.459379, loss_adv: 0.007623, loss_D_src: 0.755802, loss_D_trg: 0.643798\n",
      "Epoch: [1/20] Iter:[20/192], Time: 1.50, lr_generatore: [0.004750862409788595], Loss_seg: 3.041398, loss_adv: 0.006562, loss_D_src: 0.634964, loss_D_trg: 0.740494\n",
      "Epoch: [1/20] Iter:[30/192], Time: 1.40, lr_generatore: [0.004739075292810143], Loss_seg: 2.424478, loss_adv: 0.007337, loss_D_src: 0.716458, loss_D_trg: 0.657314\n",
      "Epoch: [1/20] Iter:[40/192], Time: 1.35, lr_generatore: [0.004727284917467442], Loss_seg: 2.940837, loss_adv: 0.006957, loss_D_src: 0.704952, loss_D_trg: 0.702315\n",
      "Epoch: [1/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.004715491273825057], Loss_seg: 2.590853, loss_adv: 0.006812, loss_D_src: 0.676255, loss_D_trg: 0.706739\n",
      "Epoch: [1/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.004703694351889546], Loss_seg: 2.012800, loss_adv: 0.007183, loss_D_src: 0.695345, loss_D_trg: 0.678567\n",
      "Epoch: [1/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.004691894141608977], Loss_seg: 1.994076, loss_adv: 0.007909, loss_D_src: 0.651473, loss_D_trg: 0.636905\n",
      "Epoch: [1/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.00468009063287241], Loss_seg: 2.185005, loss_adv: 0.007545, loss_D_src: 0.629885, loss_D_trg: 0.683509\n",
      "Epoch: [1/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.0046682838155093845], Loss_seg: 2.427005, loss_adv: 0.009753, loss_D_src: 0.691522, loss_D_trg: 0.508401\n",
      "Epoch: [1/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.004656473679289407], Loss_seg: 2.761575, loss_adv: 0.008741, loss_D_src: 0.636786, loss_D_trg: 0.632673\n",
      "Epoch: [1/20] Iter:[110/192], Time: 1.27, lr_generatore: [0.004644660213921421], Loss_seg: 2.580738, loss_adv: 0.007984, loss_D_src: 0.691978, loss_D_trg: 0.642003\n",
      "Epoch: [1/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.004632843409053276], Loss_seg: 2.175821, loss_adv: 0.007620, loss_D_src: 0.682849, loss_D_trg: 0.652577\n",
      "Epoch: [1/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.004621023254271196], Loss_seg: 2.712144, loss_adv: 0.008865, loss_D_src: 0.712189, loss_D_trg: 0.597081\n",
      "Epoch: [1/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.004609199739099233], Loss_seg: 2.045662, loss_adv: 0.007114, loss_D_src: 0.644232, loss_D_trg: 0.714737\n",
      "Epoch: [1/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.004597372852998714], Loss_seg: 2.386621, loss_adv: 0.007544, loss_D_src: 0.698219, loss_D_trg: 0.657844\n",
      "Epoch: [1/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.00458554258536769], Loss_seg: 2.024621, loss_adv: 0.006767, loss_D_src: 0.623073, loss_D_trg: 0.742233\n",
      "Epoch: [1/20] Iter:[170/192], Time: 1.25, lr_generatore: [0.004573708925540375], Loss_seg: 2.145882, loss_adv: 0.006950, loss_D_src: 0.646367, loss_D_trg: 0.709375\n",
      "Epoch: [1/20] Iter:[180/192], Time: 1.25, lr_generatore: [0.00456187186278657], Loss_seg: 2.757121, loss_adv: 0.007231, loss_D_src: 0.655192, loss_D_trg: 0.714940\n",
      "Epoch: [1/20] Iter:[190/192], Time: 1.25, lr_generatore: [0.004550031386311093], Loss_seg: 2.835657, loss_adv: 0.007473, loss_D_src: 0.728079, loss_D_trg: 0.649861\n",
      "Epoch: [1/20], loss_sum: 3.910451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.546431, Loss_Adv (G): 0.007502, Loss_D_Src: 0.679735, Loss_D_Trg: 0.676783\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.28306815 0.19149935 0.09250078 0.30980898 0.06499999\n",
      " 0.11307334 0.26377663] 0.1883896025846928\n",
      "1 [0.         0.35519436 0.25364594 0.17991356 0.35505457 0.05283632\n",
      " 0.13373754 0.36854048] 0.24270325241669305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.370, MeanIU:  0.2427, Best_mIoU:  0.2427\n",
      "[0.         0.35519436 0.25364594 0.17991356 0.35505457 0.05283632\n",
      " 0.13373754 0.36854048]\n",
      "Epoch: [2/20] Iter:[0/192], Time: 5.31, lr_generatore: [0.004547662880414811], Loss_seg: 2.392314, loss_adv: 0.006893, loss_D_src: 0.689238, loss_D_trg: 0.697006\n",
      "Epoch: [2/20] Iter:[10/192], Time: 1.76, lr_generatore: [0.004535818293131326], Loss_seg: 2.014481, loss_adv: 0.006983, loss_D_src: 0.670023, loss_D_trg: 0.703776\n",
      "Epoch: [2/20] Iter:[20/192], Time: 1.50, lr_generatore: [0.004523970268145139], Loss_seg: 2.001599, loss_adv: 0.007254, loss_D_src: 0.641262, loss_D_trg: 0.675063\n",
      "Epoch: [2/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.004512118794449168], Loss_seg: 2.281231, loss_adv: 0.009993, loss_D_src: 0.915180, loss_D_trg: 0.567052\n",
      "Epoch: [2/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.004500263860968848], Loss_seg: 2.323744, loss_adv: 0.007489, loss_D_src: 0.684554, loss_D_trg: 0.666026\n",
      "Epoch: [2/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0044884054565615256], Loss_seg: 2.638832, loss_adv: 0.007479, loss_D_src: 0.691128, loss_D_trg: 0.656283\n",
      "Epoch: [2/20] Iter:[60/192], Time: 1.32, lr_generatore: [0.004476543570015834], Loss_seg: 2.690230, loss_adv: 0.007307, loss_D_src: 0.665154, loss_D_trg: 0.688068\n",
      "Epoch: [2/20] Iter:[70/192], Time: 1.31, lr_generatore: [0.004464678190051071], Loss_seg: 2.277838, loss_adv: 0.007708, loss_D_src: 0.711058, loss_D_trg: 0.638438\n",
      "Epoch: [2/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.004452809305316556], Loss_seg: 1.670204, loss_adv: 0.007094, loss_D_src: 0.658944, loss_D_trg: 0.701894\n",
      "Epoch: [2/20] Iter:[90/192], Time: 1.29, lr_generatore: [0.004440936904390996], Loss_seg: 2.429480, loss_adv: 0.007721, loss_D_src: 0.639047, loss_D_trg: 0.651425\n",
      "Epoch: [2/20] Iter:[100/192], Time: 1.29, lr_generatore: [0.004429060975781829], Loss_seg: 1.843623, loss_adv: 0.008672, loss_D_src: 0.617736, loss_D_trg: 0.719816\n",
      "Epoch: [2/20] Iter:[110/192], Time: 1.28, lr_generatore: [0.004417181507924568], Loss_seg: 2.289537, loss_adv: 0.006632, loss_D_src: 0.624047, loss_D_trg: 0.762869\n",
      "Epoch: [2/20] Iter:[120/192], Time: 1.28, lr_generatore: [0.004405298489182137], Loss_seg: 2.288553, loss_adv: 0.008128, loss_D_src: 0.747112, loss_D_trg: 0.595634\n",
      "Epoch: [2/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.004393411907844189], Loss_seg: 2.167844, loss_adv: 0.006664, loss_D_src: 0.820576, loss_D_trg: 0.833033\n",
      "Epoch: [2/20] Iter:[140/192], Time: 1.27, lr_generatore: [0.0043815217521264325], Loss_seg: 2.879741, loss_adv: 0.007801, loss_D_src: 0.661137, loss_D_trg: 0.641693\n",
      "Epoch: [2/20] Iter:[150/192], Time: 1.27, lr_generatore: [0.004369628010169933], Loss_seg: 2.556203, loss_adv: 0.007687, loss_D_src: 0.705786, loss_D_trg: 0.640571\n",
      "Epoch: [2/20] Iter:[160/192], Time: 1.27, lr_generatore: [0.004357730670040415], Loss_seg: 2.288608, loss_adv: 0.008248, loss_D_src: 0.702993, loss_D_trg: 0.613914\n",
      "Epoch: [2/20] Iter:[170/192], Time: 1.27, lr_generatore: [0.0043458297197275534], Loss_seg: 2.472415, loss_adv: 0.007553, loss_D_src: 0.646268, loss_D_trg: 0.704992\n",
      "Epoch: [2/20] Iter:[180/192], Time: 1.26, lr_generatore: [0.004333925147144258], Loss_seg: 2.675487, loss_adv: 0.010076, loss_D_src: 0.765248, loss_D_trg: 0.535284\n",
      "Epoch: [2/20] Iter:[190/192], Time: 1.26, lr_generatore: [0.004322016940125944], Loss_seg: 2.776982, loss_adv: 0.007303, loss_D_src: 0.591021, loss_D_trg: 0.682064\n",
      "Epoch: [2/20], loss_sum: 3.743531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.389508, Loss_Adv (G): 0.007670, Loss_D_Src: 0.675342, Loss_D_Trg: 0.671011\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.29078622 0.21407116 0.08811689 0.21808045 0.06240692\n",
      " 0.12603334 0.22043356] 0.174275506121121\n",
      "1 [0.         0.19438987 0.29008911 0.22420639 0.2939413  0.02769125\n",
      " 0.14529364 0.41794662] 0.22765116861734752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 5.947, MeanIU:  0.2277, Best_mIoU:  0.2427\n",
      "[0.         0.19438987 0.29008911 0.22420639 0.2939413  0.02769125\n",
      " 0.14529364 0.41794662]\n",
      "Epoch: [3/20] Iter:[0/192], Time: 5.80, lr_generatore: [0.0043196348615140955], Loss_seg: 2.480508, loss_adv: 0.006914, loss_D_src: 0.691406, loss_D_trg: 0.694890\n",
      "Epoch: [3/20] Iter:[10/192], Time: 1.74, lr_generatore: [0.004307722277006307], Loss_seg: 2.572667, loss_adv: 0.007061, loss_D_src: 0.682537, loss_D_trg: 0.685573\n",
      "Epoch: [3/20] Iter:[20/192], Time: 1.51, lr_generatore: [0.004295806031024994], Loss_seg: 2.619229, loss_adv: 0.007336, loss_D_src: 0.686203, loss_D_trg: 0.678557\n",
      "Epoch: [3/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.004283886111152608], Loss_seg: 2.591919, loss_adv: 0.006751, loss_D_src: 0.599630, loss_D_trg: 0.769287\n",
      "Epoch: [3/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.004271962504890943], Loss_seg: 2.611689, loss_adv: 0.007943, loss_D_src: 0.663595, loss_D_trg: 0.639479\n",
      "Epoch: [3/20] Iter:[50/192], Time: 1.34, lr_generatore: [0.00426003519966038], Loss_seg: 2.918418, loss_adv: 0.007802, loss_D_src: 0.656556, loss_D_trg: 0.745276\n",
      "Epoch: [3/20] Iter:[60/192], Time: 1.32, lr_generatore: [0.00424810418279909], Loss_seg: 2.158384, loss_adv: 0.007931, loss_D_src: 0.785892, loss_D_trg: 0.621420\n",
      "Epoch: [3/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.004236169441562239], Loss_seg: 2.205156, loss_adv: 0.007461, loss_D_src: 0.713502, loss_D_trg: 0.656741\n",
      "Epoch: [3/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.004224230963121187], Loss_seg: 2.315525, loss_adv: 0.007114, loss_D_src: 0.611249, loss_D_trg: 0.711865\n",
      "Epoch: [3/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.004212288734562668], Loss_seg: 2.714860, loss_adv: 0.008381, loss_D_src: 0.642429, loss_D_trg: 0.657019\n",
      "Epoch: [3/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.004200342742887967], Loss_seg: 3.412669, loss_adv: 0.008600, loss_D_src: 0.646141, loss_D_trg: 0.593557\n",
      "Epoch: [3/20] Iter:[110/192], Time: 1.28, lr_generatore: [0.004188392975012077], Loss_seg: 2.393079, loss_adv: 0.007185, loss_D_src: 0.667100, loss_D_trg: 0.690798\n",
      "Epoch: [3/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.004176439417762855], Loss_seg: 3.208938, loss_adv: 0.008372, loss_D_src: 0.717847, loss_D_trg: 0.590225\n",
      "Epoch: [3/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.004164482057880162], Loss_seg: 1.956771, loss_adv: 0.007862, loss_D_src: 0.664157, loss_D_trg: 0.785227\n",
      "Epoch: [3/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.004152520882014994], Loss_seg: 2.144225, loss_adv: 0.007710, loss_D_src: 0.618093, loss_D_trg: 0.680951\n",
      "Epoch: [3/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.004140555876728594], Loss_seg: 1.757376, loss_adv: 0.008419, loss_D_src: 0.727109, loss_D_trg: 0.584871\n",
      "Epoch: [3/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.004128587028491566], Loss_seg: 2.160398, loss_adv: 0.008363, loss_D_src: 0.632606, loss_D_trg: 0.608145\n",
      "Epoch: [3/20] Iter:[170/192], Time: 1.26, lr_generatore: [0.004116614323682965], Loss_seg: 2.394842, loss_adv: 0.008400, loss_D_src: 0.626842, loss_D_trg: 0.680695\n",
      "Epoch: [3/20] Iter:[180/192], Time: 1.26, lr_generatore: [0.004104637748589382], Loss_seg: 2.207753, loss_adv: 0.008273, loss_D_src: 0.654838, loss_D_trg: 0.634367\n",
      "Epoch: [3/20] Iter:[190/192], Time: 1.26, lr_generatore: [0.004092657289404011], Loss_seg: 1.936785, loss_adv: 0.007406, loss_D_src: 0.587280, loss_D_trg: 0.693387\n",
      "Epoch: [3/20], loss_sum: 3.715367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.370248, Loss_Adv (G): 0.007810, Loss_D_Src: 0.672164, Loss_D_Trg: 0.665145\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.32593921 0.19031596 0.10897974 0.27618689 0.0765556\n",
      " 0.12560443 0.20293539] 0.1866453168944351\n",
      "1 [0.         0.33165204 0.29405632 0.23244284 0.42389938 0.04268829\n",
      " 0.15542017 0.3690527 ] 0.26417310643278524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.061, MeanIU:  0.2642, Best_mIoU:  0.2642\n",
      "[0.         0.33165204 0.29405632 0.23244284 0.42389938 0.04268829\n",
      " 0.15542017 0.3690527 ]\n",
      "Epoch: [4/20] Iter:[0/192], Time: 5.48, lr_generatore: [0.004090260730254292], Loss_seg: 1.916226, loss_adv: 0.006872, loss_D_src: 0.687557, loss_D_trg: 0.699141\n",
      "Epoch: [4/20] Iter:[10/192], Time: 1.76, lr_generatore: [0.0040782755918008975], Loss_seg: 2.016449, loss_adv: 0.006802, loss_D_src: 0.652898, loss_D_trg: 0.713691\n",
      "Epoch: [4/20] Iter:[20/192], Time: 1.51, lr_generatore: [0.004066286538547334], Loss_seg: 2.244363, loss_adv: 0.006503, loss_D_src: 0.641286, loss_D_trg: 0.776929\n",
      "Epoch: [4/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.004054293556381539], Loss_seg: 1.893283, loss_adv: 0.007610, loss_D_src: 0.729125, loss_D_trg: 0.639835\n",
      "Epoch: [4/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.004042296631094014], Loss_seg: 2.327324, loss_adv: 0.007082, loss_D_src: 0.686244, loss_D_trg: 0.681370\n",
      "Epoch: [4/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.004030295748376826], Loss_seg: 2.239837, loss_adv: 0.007523, loss_D_src: 0.696318, loss_D_trg: 0.660831\n",
      "Epoch: [4/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.004018290893822602], Loss_seg: 2.104703, loss_adv: 0.007373, loss_D_src: 0.695269, loss_D_trg: 0.696505\n",
      "Epoch: [4/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.004006282052923497], Loss_seg: 2.726613, loss_adv: 0.006907, loss_D_src: 0.662764, loss_D_trg: 0.700523\n",
      "Epoch: [4/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.0039942692110701665], Loss_seg: 1.886055, loss_adv: 0.007682, loss_D_src: 0.679786, loss_D_trg: 0.684318\n",
      "Epoch: [4/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.0039822523535507056], Loss_seg: 2.499926, loss_adv: 0.007094, loss_D_src: 0.667947, loss_D_trg: 0.686969\n",
      "Epoch: [4/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.003970231465549588], Loss_seg: 2.289865, loss_adv: 0.007253, loss_D_src: 0.692835, loss_D_trg: 0.677245\n",
      "Epoch: [4/20] Iter:[110/192], Time: 1.27, lr_generatore: [0.003958206532146582], Loss_seg: 2.604535, loss_adv: 0.008046, loss_D_src: 0.709813, loss_D_trg: 0.610025\n",
      "Epoch: [4/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.003946177538315659], Loss_seg: 3.017568, loss_adv: 0.007531, loss_D_src: 0.710253, loss_D_trg: 0.685178\n",
      "Epoch: [4/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.003934144468923876], Loss_seg: 1.937451, loss_adv: 0.008046, loss_D_src: 0.727553, loss_D_trg: 0.613948\n",
      "Epoch: [4/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.003922107308730254], Loss_seg: 2.108897, loss_adv: 0.008109, loss_D_src: 0.670090, loss_D_trg: 0.633982\n",
      "Epoch: [4/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.003910066042384634], Loss_seg: 2.447987, loss_adv: 0.006913, loss_D_src: 0.603222, loss_D_trg: 0.722999\n",
      "Epoch: [4/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.003898020654426515], Loss_seg: 2.356992, loss_adv: 0.008754, loss_D_src: 0.715020, loss_D_trg: 0.578454\n",
      "Epoch: [4/20] Iter:[170/192], Time: 1.26, lr_generatore: [0.0038859711292838863], Loss_seg: 2.283827, loss_adv: 0.007386, loss_D_src: 0.710017, loss_D_trg: 0.676072\n",
      "Epoch: [4/20] Iter:[180/192], Time: 1.26, lr_generatore: [0.003873917451272028], Loss_seg: 1.856482, loss_adv: 0.007236, loss_D_src: 0.658573, loss_D_trg: 0.741808\n",
      "Epoch: [4/20] Iter:[190/192], Time: 1.25, lr_generatore: [0.0038618596045923103], Loss_seg: 1.432732, loss_adv: 0.008564, loss_D_src: 0.729461, loss_D_trg: 0.618589\n",
      "Epoch: [4/20], loss_sum: 3.640708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.282358, Loss_Adv (G): 0.007474, Loss_D_Src: 0.676392, Loss_D_Trg: 0.674485\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.33974531 0.19849138 0.09366781 0.30040252 0.08118072\n",
      " 0.15121734 0.1924576 ] 0.19388038286054268\n",
      "1 [0.         0.39066545 0.28108913 0.24458031 0.4076374  0.05827952\n",
      " 0.16854392 0.40594135] 0.2795338680419473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.804, MeanIU:  0.2795, Best_mIoU:  0.2795\n",
      "[0.         0.39066545 0.28108913 0.24458031 0.4076374  0.05827952\n",
      " 0.16854392 0.40594135]\n",
      "Epoch: [5/20] Iter:[0/192], Time: 6.68, lr_generatore: [0.0038594475336178524], Loss_seg: 3.003114, loss_adv: 0.006925, loss_D_src: 0.692527, loss_D_trg: 0.693789\n",
      "Epoch: [5/20] Iter:[10/192], Time: 1.79, lr_generatore: [0.0038473846635203057], Loss_seg: 2.461599, loss_adv: 0.007851, loss_D_src: 0.726481, loss_D_trg: 0.640017\n",
      "Epoch: [5/20] Iter:[20/192], Time: 1.52, lr_generatore: [0.00383531758959087], Loss_seg: 2.212646, loss_adv: 0.007404, loss_D_src: 0.664455, loss_D_trg: 0.707662\n",
      "Epoch: [5/20] Iter:[30/192], Time: 1.43, lr_generatore: [0.003823246295658066], Loss_seg: 1.965146, loss_adv: 0.007019, loss_D_src: 0.648806, loss_D_trg: 0.709489\n",
      "Epoch: [5/20] Iter:[40/192], Time: 1.37, lr_generatore: [0.003811170765431238], Loss_seg: 2.398258, loss_adv: 0.008030, loss_D_src: 0.721824, loss_D_trg: 0.618282\n",
      "Epoch: [5/20] Iter:[50/192], Time: 1.34, lr_generatore: [0.0037990909824992493], Loss_seg: 2.089743, loss_adv: 0.008236, loss_D_src: 0.653986, loss_D_trg: 0.625815\n",
      "Epoch: [5/20] Iter:[60/192], Time: 1.33, lr_generatore: [0.0037870069303291586], Loss_seg: 1.962796, loss_adv: 0.008415, loss_D_src: 0.698531, loss_D_trg: 0.633716\n",
      "Epoch: [5/20] Iter:[70/192], Time: 1.31, lr_generatore: [0.003774918592264888], Loss_seg: 1.953786, loss_adv: 0.007746, loss_D_src: 0.667582, loss_D_trg: 0.646896\n",
      "Epoch: [5/20] Iter:[80/192], Time: 1.30, lr_generatore: [0.0037628259515258607], Loss_seg: 2.180291, loss_adv: 0.008549, loss_D_src: 0.655792, loss_D_trg: 0.663341\n",
      "Epoch: [5/20] Iter:[90/192], Time: 1.29, lr_generatore: [0.003750728991205618], Loss_seg: 2.330503, loss_adv: 0.007158, loss_D_src: 0.529616, loss_D_trg: 0.764140\n",
      "Epoch: [5/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.0037386276942704302], Loss_seg: 2.088016, loss_adv: 0.008698, loss_D_src: 0.667563, loss_D_trg: 0.647629\n",
      "Epoch: [5/20] Iter:[110/192], Time: 1.28, lr_generatore: [0.0037265220435578686], Loss_seg: 2.357956, loss_adv: 0.007634, loss_D_src: 0.608357, loss_D_trg: 0.675784\n",
      "Epoch: [5/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.003714412021775367], Loss_seg: 3.080898, loss_adv: 0.008761, loss_D_src: 0.701326, loss_D_trg: 0.600283\n",
      "Epoch: [5/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.003702297611498763], Loss_seg: 2.126524, loss_adv: 0.008127, loss_D_src: 0.663358, loss_D_trg: 0.675676\n",
      "Epoch: [5/20] Iter:[140/192], Time: 1.27, lr_generatore: [0.0036901787951708117], Loss_seg: 2.036876, loss_adv: 0.007311, loss_D_src: 0.613393, loss_D_trg: 0.687149\n",
      "Epoch: [5/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.003678055555099677], Loss_seg: 1.668760, loss_adv: 0.008186, loss_D_src: 0.728155, loss_D_trg: 0.651302\n",
      "Epoch: [5/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.00366592787345741], Loss_seg: 2.655572, loss_adv: 0.007891, loss_D_src: 0.721582, loss_D_trg: 0.681456\n",
      "Epoch: [5/20] Iter:[170/192], Time: 1.26, lr_generatore: [0.0036537957322783916], Loss_seg: 2.426663, loss_adv: 0.008056, loss_D_src: 0.585058, loss_D_trg: 0.658044\n",
      "Epoch: [5/20] Iter:[180/192], Time: 1.26, lr_generatore: [0.003641659113457757], Loss_seg: 1.991993, loss_adv: 0.007756, loss_D_src: 0.723331, loss_D_trg: 0.673425\n",
      "Epoch: [5/20] Iter:[190/192], Time: 1.25, lr_generatore: [0.003629517998749802], Loss_seg: 1.684365, loss_adv: 0.008765, loss_D_src: 0.657713, loss_D_trg: 0.605064\n",
      "Epoch: [5/20], loss_sum: 3.586924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.256604, Loss_Adv (G): 0.007906, Loss_D_Src: 0.654934, Loss_D_Trg: 0.667480\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.38037407 0.20787596 0.08804858 0.26476331 0.07740929\n",
      " 0.13626862 0.16895172] 0.18909879497160378\n",
      "1 [0.         0.39705386 0.25431287 0.24335598 0.31009277 0.04514226\n",
      " 0.15955771 0.34302803] 0.25036335381118907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.361, MeanIU:  0.2504, Best_mIoU:  0.2795\n",
      "[0.         0.39705386 0.25431287 0.24335598 0.31009277 0.04514226\n",
      " 0.15955771 0.34302803]\n",
      "Epoch: [6/20] Iter:[0/192], Time: 4.91, lr_generatore: [0.0036270892346860996], Loss_seg: 1.755899, loss_adv: 0.006931, loss_D_src: 0.692913, loss_D_trg: 0.693153\n",
      "Epoch: [6/20] Iter:[10/192], Time: 1.73, lr_generatore: [0.003614942700628321], Loss_seg: 1.893091, loss_adv: 0.007562, loss_D_src: 0.719687, loss_D_trg: 0.671642\n",
      "Epoch: [6/20] Iter:[20/192], Time: 1.50, lr_generatore: [0.0036027916300388667], Loss_seg: 2.261861, loss_adv: 0.007286, loss_D_src: 0.634725, loss_D_trg: 0.694317\n",
      "Epoch: [6/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.003590636004210302], Loss_seg: 1.815525, loss_adv: 0.007175, loss_D_src: 0.675963, loss_D_trg: 0.685203\n",
      "Epoch: [6/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.0035784758042873635], Loss_seg: 2.450273, loss_adv: 0.006939, loss_D_src: 0.661919, loss_D_trg: 0.697002\n",
      "Epoch: [6/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0035663110112652235], Loss_seg: 2.021801, loss_adv: 0.006737, loss_D_src: 0.614312, loss_D_trg: 0.738826\n",
      "Epoch: [6/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.0035541416059877385], Loss_seg: 2.008510, loss_adv: 0.008192, loss_D_src: 0.723161, loss_D_trg: 0.622256\n",
      "Epoch: [6/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.0035419675691456595], Loss_seg: 1.950404, loss_adv: 0.007824, loss_D_src: 0.686838, loss_D_trg: 0.632086\n",
      "Epoch: [6/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.003529788881274818], Loss_seg: 2.102353, loss_adv: 0.007681, loss_D_src: 0.616825, loss_D_trg: 0.653285\n",
      "Epoch: [6/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.003517605522754288], Loss_seg: 2.079385, loss_adv: 0.007976, loss_D_src: 0.751679, loss_D_trg: 0.709703\n",
      "Epoch: [6/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.0035054174738045132], Loss_seg: 1.938975, loss_adv: 0.007194, loss_D_src: 0.598842, loss_D_trg: 0.703434\n",
      "Epoch: [6/20] Iter:[110/192], Time: 1.27, lr_generatore: [0.003493224714485405], Loss_seg: 2.193308, loss_adv: 0.007710, loss_D_src: 0.686556, loss_D_trg: 0.662757\n",
      "Epoch: [6/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.0034810272246944135], Loss_seg: 1.918274, loss_adv: 0.008049, loss_D_src: 0.666317, loss_D_trg: 0.632733\n",
      "Epoch: [6/20] Iter:[130/192], Time: 1.26, lr_generatore: [0.0034688249841645677], Loss_seg: 1.889704, loss_adv: 0.008643, loss_D_src: 0.598170, loss_D_trg: 0.678196\n",
      "Epoch: [6/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.003456617972462477], Loss_seg: 2.722622, loss_adv: 0.008037, loss_D_src: 0.657864, loss_D_trg: 0.641367\n",
      "Epoch: [6/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.0034444061689863103], Loss_seg: 1.807056, loss_adv: 0.007157, loss_D_src: 0.592408, loss_D_trg: 0.697692\n",
      "Epoch: [6/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.00343218955296374], Loss_seg: 2.100507, loss_adv: 0.008758, loss_D_src: 0.574065, loss_D_trg: 0.598125\n",
      "Epoch: [6/20] Iter:[170/192], Time: 1.25, lr_generatore: [0.003419968103449845], Loss_seg: 2.489946, loss_adv: 0.008021, loss_D_src: 0.579844, loss_D_trg: 0.633994\n",
      "Epoch: [6/20] Iter:[180/192], Time: 1.25, lr_generatore: [0.0034077417993249887], Loss_seg: 2.311340, loss_adv: 0.008349, loss_D_src: 0.647086, loss_D_trg: 0.611518\n",
      "Epoch: [6/20] Iter:[190/192], Time: 1.25, lr_generatore: [0.0033955106192926614], Loss_seg: 2.373339, loss_adv: 0.007326, loss_D_src: 0.633582, loss_D_trg: 0.767678\n",
      "Epoch: [6/20], loss_sum: 3.558234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.215270, Loss_Adv (G): 0.007676, Loss_D_Src: 0.661668, Loss_D_Trg: 0.673621\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.37338397 0.23518217 0.11886703 0.27247671 0.08625772\n",
      " 0.12280629 0.24726103] 0.2080335591053743\n",
      "1 [0.         0.40509772 0.33346009 0.28154699 0.34473364 0.03608903\n",
      " 0.11979309 0.40383835] 0.2749369858005757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.647, MeanIU:  0.2749, Best_mIoU:  0.2795\n",
      "[0.         0.40509772 0.33346009 0.28154699 0.34473364 0.03608903\n",
      " 0.11979309 0.40383835]\n",
      "Epoch: [7/20] Iter:[0/192], Time: 6.24, lr_generatore: [0.0033930637962906254], Loss_seg: 2.187546, loss_adv: 0.006960, loss_D_src: 0.696056, loss_D_trg: 0.690273\n",
      "Epoch: [7/20] Iter:[10/192], Time: 1.77, lr_generatore: [0.0033808267368056477], Loss_seg: 1.978052, loss_adv: 0.007280, loss_D_src: 0.656234, loss_D_trg: 0.688990\n",
      "Epoch: [7/20] Iter:[20/192], Time: 1.51, lr_generatore: [0.003368584753927398], Loss_seg: 2.002740, loss_adv: 0.006852, loss_D_src: 0.613885, loss_D_trg: 0.718240\n",
      "Epoch: [7/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.003356337825778429], Loss_seg: 2.315912, loss_adv: 0.007257, loss_D_src: 0.667365, loss_D_trg: 0.687727\n",
      "Epoch: [7/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.0033440859302949523], Loss_seg: 2.260123, loss_adv: 0.007507, loss_D_src: 0.609780, loss_D_trg: 0.690243\n",
      "Epoch: [7/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0033318290452244792], Loss_seg: 2.101941, loss_adv: 0.007291, loss_D_src: 0.661498, loss_D_trg: 0.719586\n",
      "Epoch: [7/20] Iter:[60/192], Time: 1.30, lr_generatore: [0.003319567148123437], Loss_seg: 1.968499, loss_adv: 0.006869, loss_D_src: 0.639179, loss_D_trg: 0.720394\n",
      "Epoch: [7/20] Iter:[70/192], Time: 1.29, lr_generatore: [0.0033073002163547293], Loss_seg: 2.114707, loss_adv: 0.007173, loss_D_src: 0.682338, loss_D_trg: 0.685955\n",
      "Epoch: [7/20] Iter:[80/192], Time: 1.28, lr_generatore: [0.0032950282270852683], Loss_seg: 2.296773, loss_adv: 0.007224, loss_D_src: 0.677456, loss_D_trg: 0.673947\n",
      "Epoch: [7/20] Iter:[90/192], Time: 1.27, lr_generatore: [0.003282751157283456], Loss_seg: 2.245153, loss_adv: 0.007198, loss_D_src: 0.671495, loss_D_trg: 0.712979\n",
      "Epoch: [7/20] Iter:[100/192], Time: 1.26, lr_generatore: [0.0032704689837166276], Loss_seg: 2.058852, loss_adv: 0.007523, loss_D_src: 0.679256, loss_D_trg: 0.703259\n",
      "Epoch: [7/20] Iter:[110/192], Time: 1.26, lr_generatore: [0.003258181682948447], Loss_seg: 1.787479, loss_adv: 0.007598, loss_D_src: 0.706955, loss_D_trg: 0.640876\n",
      "Epoch: [7/20] Iter:[120/192], Time: 1.25, lr_generatore: [0.0032458892313362653], Loss_seg: 2.261466, loss_adv: 0.006720, loss_D_src: 0.575585, loss_D_trg: 0.757691\n",
      "Epoch: [7/20] Iter:[130/192], Time: 1.25, lr_generatore: [0.0032335916050284215], Loss_seg: 2.200603, loss_adv: 0.007519, loss_D_src: 0.684686, loss_D_trg: 0.680728\n",
      "Epoch: [7/20] Iter:[140/192], Time: 1.25, lr_generatore: [0.0032212887799615087], Loss_seg: 2.267959, loss_adv: 0.007760, loss_D_src: 0.668861, loss_D_trg: 0.634865\n",
      "Epoch: [7/20] Iter:[150/192], Time: 1.24, lr_generatore: [0.003208980731857586], Loss_seg: 2.398319, loss_adv: 0.007758, loss_D_src: 0.693175, loss_D_trg: 0.659428\n",
      "Epoch: [7/20] Iter:[160/192], Time: 1.24, lr_generatore: [0.0031966674362213406], Loss_seg: 2.101471, loss_adv: 0.008518, loss_D_src: 0.612283, loss_D_trg: 0.663102\n",
      "Epoch: [7/20] Iter:[170/192], Time: 1.24, lr_generatore: [0.0031843488683372056], Loss_seg: 2.028146, loss_adv: 0.008031, loss_D_src: 0.665847, loss_D_trg: 0.688623\n",
      "Epoch: [7/20] Iter:[180/192], Time: 1.24, lr_generatore: [0.003172025003266424], Loss_seg: 1.917728, loss_adv: 0.007559, loss_D_src: 0.670469, loss_D_trg: 0.658238\n",
      "Epoch: [7/20] Iter:[190/192], Time: 1.23, lr_generatore: [0.003159695815844057], Loss_seg: 2.762912, loss_adv: 0.009040, loss_D_src: 0.741053, loss_D_trg: 0.582853\n",
      "Epoch: [7/20], loss_sum: 3.534869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.183926, Loss_Adv (G): 0.007560, Loss_D_Src: 0.667008, Loss_D_Trg: 0.676374\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.33601811 0.21249992 0.12278594 0.26907939 0.07335025\n",
      " 0.11554311 0.25775897] 0.1981479543550107\n",
      "1 [0.         0.43278494 0.2916396  0.3016392  0.27579168 0.04773104\n",
      " 0.12076038 0.42048148] 0.2701183345906496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.378, MeanIU:  0.2701, Best_mIoU:  0.2795\n",
      "[0.         0.43278494 0.2916396  0.3016392  0.27579168 0.04773104\n",
      " 0.12076038 0.42048148]\n",
      "Epoch: [8/20] Iter:[0/192], Time: 6.21, lr_generatore: [0.0031572293374467764], Loss_seg: 1.598182, loss_adv: 0.006903, loss_D_src: 0.690262, loss_D_trg: 0.696020\n",
      "Epoch: [8/20] Iter:[10/192], Time: 1.78, lr_generatore: [0.0031448937296618285], Loss_seg: 1.839499, loss_adv: 0.007470, loss_D_src: 0.726685, loss_D_trg: 0.671132\n",
      "Epoch: [8/20] Iter:[20/192], Time: 1.50, lr_generatore: [0.003132552743351212], Loss_seg: 2.037698, loss_adv: 0.007188, loss_D_src: 0.629290, loss_D_trg: 0.677383\n",
      "Epoch: [8/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.0031202063526055085], Loss_seg: 2.690792, loss_adv: 0.007625, loss_D_src: 0.638232, loss_D_trg: 0.672964\n",
      "Epoch: [8/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.0031078545312759743], Loss_seg: 1.515136, loss_adv: 0.007778, loss_D_src: 0.649296, loss_D_trg: 0.673297\n",
      "Epoch: [8/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0030954972529712646], Loss_seg: 2.237839, loss_adv: 0.007728, loss_D_src: 0.682815, loss_D_trg: 0.642190\n",
      "Epoch: [8/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.003083134491054096], Loss_seg: 2.134081, loss_adv: 0.007444, loss_D_src: 0.636993, loss_D_trg: 0.668260\n",
      "Epoch: [8/20] Iter:[70/192], Time: 1.29, lr_generatore: [0.0030707662186378465], Loss_seg: 1.936623, loss_adv: 0.007845, loss_D_src: 0.697559, loss_D_trg: 0.643107\n",
      "Epoch: [8/20] Iter:[80/192], Time: 1.28, lr_generatore: [0.003058392408583097], Loss_seg: 1.963285, loss_adv: 0.006544, loss_D_src: 0.626637, loss_D_trg: 0.756972\n",
      "Epoch: [8/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.003046013033494107], Loss_seg: 2.272575, loss_adv: 0.007014, loss_D_src: 0.633948, loss_D_trg: 0.706477\n",
      "Epoch: [8/20] Iter:[100/192], Time: 1.27, lr_generatore: [0.003033628065715221], Loss_seg: 2.517765, loss_adv: 0.007083, loss_D_src: 0.682644, loss_D_trg: 0.783164\n",
      "Epoch: [8/20] Iter:[110/192], Time: 1.26, lr_generatore: [0.003021237477327215], Loss_seg: 2.367358, loss_adv: 0.007833, loss_D_src: 0.721885, loss_D_trg: 0.651176\n",
      "Epoch: [8/20] Iter:[120/192], Time: 1.26, lr_generatore: [0.0030088412401435716], Loss_seg: 1.751637, loss_adv: 0.008342, loss_D_src: 0.676561, loss_D_trg: 0.638146\n",
      "Epoch: [8/20] Iter:[130/192], Time: 1.25, lr_generatore: [0.002996439325706685], Loss_seg: 2.238877, loss_adv: 0.008403, loss_D_src: 0.770620, loss_D_trg: 0.601727\n",
      "Epoch: [8/20] Iter:[140/192], Time: 1.25, lr_generatore: [0.0029840317052839916], Loss_seg: 1.789027, loss_adv: 0.007233, loss_D_src: 0.643419, loss_D_trg: 0.676440\n",
      "Epoch: [8/20] Iter:[150/192], Time: 1.25, lr_generatore: [0.002971618349864035], Loss_seg: 2.047590, loss_adv: 0.008030, loss_D_src: 0.665765, loss_D_trg: 0.642164\n",
      "Epoch: [8/20] Iter:[160/192], Time: 1.25, lr_generatore: [0.002959199230152446], Loss_seg: 2.952166, loss_adv: 0.008602, loss_D_src: 0.691148, loss_D_trg: 0.608376\n",
      "Epoch: [8/20] Iter:[170/192], Time: 1.24, lr_generatore: [0.0029467743165678562], Loss_seg: 2.204847, loss_adv: 0.007675, loss_D_src: 0.535873, loss_D_trg: 0.679159\n",
      "Epoch: [8/20] Iter:[180/192], Time: 1.24, lr_generatore: [0.0029343435792377236], Loss_seg: 2.204136, loss_adv: 0.008805, loss_D_src: 0.608622, loss_D_trg: 0.593684\n",
      "Epoch: [8/20] Iter:[190/192], Time: 1.24, lr_generatore: [0.0029219069879940847], Loss_seg: 2.039953, loss_adv: 0.009253, loss_D_src: 0.756581, loss_D_trg: 0.555173\n",
      "Epoch: [8/20], loss_sum: 3.480222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.131480, Loss_Adv (G): 0.007612, Loss_D_Src: 0.667139, Loss_D_Trg: 0.673991\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.38573164 0.19246117 0.12161674 0.27694328 0.08968216\n",
      " 0.1174429  0.26773055] 0.20737263487157337\n",
      "1 [0.         0.47227813 0.27647617 0.2823968  0.33365714 0.0599754\n",
      " 0.10689863 0.41655542] 0.27831966907671835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.760, MeanIU:  0.2783, Best_mIoU:  0.2795\n",
      "[0.         0.47227813 0.27647617 0.2823968  0.33365714 0.0599754\n",
      " 0.10689863 0.41655542]\n",
      "Epoch: [9/20] Iter:[0/192], Time: 6.11, lr_generatore: [0.0029194189645999013], Loss_seg: 2.289113, loss_adv: 0.006947, loss_D_src: 0.694589, loss_D_trg: 0.691609\n",
      "Epoch: [9/20] Iter:[10/192], Time: 1.73, lr_generatore: [0.0029069753084159738], Loss_seg: 2.388954, loss_adv: 0.007354, loss_D_src: 0.658292, loss_D_trg: 0.662720\n",
      "Epoch: [9/20] Iter:[20/192], Time: 1.48, lr_generatore: [0.0028945257308876514], Loss_seg: 2.064065, loss_adv: 0.007793, loss_D_src: 0.693451, loss_D_trg: 0.656400\n",
      "Epoch: [9/20] Iter:[30/192], Time: 1.39, lr_generatore: [0.0028820702008720786], Loss_seg: 1.452788, loss_adv: 0.007505, loss_D_src: 0.633105, loss_D_trg: 0.683820\n",
      "Epoch: [9/20] Iter:[40/192], Time: 1.35, lr_generatore: [0.0028696086869121986], Loss_seg: 2.494412, loss_adv: 0.006866, loss_D_src: 0.602358, loss_D_trg: 0.743114\n",
      "Epoch: [9/20] Iter:[50/192], Time: 1.32, lr_generatore: [0.0028571411572320543], Loss_seg: 2.073709, loss_adv: 0.006967, loss_D_src: 0.680970, loss_D_trg: 0.692477\n",
      "Epoch: [9/20] Iter:[60/192], Time: 1.30, lr_generatore: [0.002844667579731992], Loss_seg: 1.796378, loss_adv: 0.007315, loss_D_src: 0.695187, loss_D_trg: 0.658766\n",
      "Epoch: [9/20] Iter:[70/192], Time: 1.29, lr_generatore: [0.0028321879219837653], Loss_seg: 1.781743, loss_adv: 0.007115, loss_D_src: 0.668702, loss_D_trg: 0.696419\n",
      "Epoch: [9/20] Iter:[80/192], Time: 1.28, lr_generatore: [0.0028197021512255524], Loss_seg: 1.904301, loss_adv: 0.008128, loss_D_src: 0.739205, loss_D_trg: 0.616927\n",
      "Epoch: [9/20] Iter:[90/192], Time: 1.27, lr_generatore: [0.002807210234356861], Loss_seg: 2.290312, loss_adv: 0.007634, loss_D_src: 0.664156, loss_D_trg: 0.654007\n",
      "Epoch: [9/20] Iter:[100/192], Time: 1.26, lr_generatore: [0.002794712137933334], Loss_seg: 2.104418, loss_adv: 0.008234, loss_D_src: 0.666134, loss_D_trg: 0.615635\n",
      "Epoch: [9/20] Iter:[110/192], Time: 1.26, lr_generatore: [0.0027822078281614566], Loss_seg: 2.232707, loss_adv: 0.009542, loss_D_src: 0.736494, loss_D_trg: 0.593539\n",
      "Epoch: [9/20] Iter:[120/192], Time: 1.25, lr_generatore: [0.00276969727089314], Loss_seg: 2.029625, loss_adv: 0.010143, loss_D_src: 0.850044, loss_D_trg: 0.522218\n",
      "Epoch: [9/20] Iter:[130/192], Time: 1.25, lr_generatore: [0.0027571804316202063], Loss_seg: 2.406479, loss_adv: 0.006871, loss_D_src: 0.597028, loss_D_trg: 0.744395\n",
      "Epoch: [9/20] Iter:[140/192], Time: 1.25, lr_generatore: [0.0027446572754687556], Loss_seg: 2.308452, loss_adv: 0.009233, loss_D_src: 0.717182, loss_D_trg: 0.580693\n",
      "Epoch: [9/20] Iter:[150/192], Time: 1.25, lr_generatore: [0.0027321277671934125], Loss_seg: 2.348357, loss_adv: 0.007409, loss_D_src: 0.595368, loss_D_trg: 0.721870\n",
      "Epoch: [9/20] Iter:[160/192], Time: 1.25, lr_generatore: [0.002719591871171457], Loss_seg: 2.075339, loss_adv: 0.008401, loss_D_src: 0.625162, loss_D_trg: 0.620768\n",
      "Epoch: [9/20] Iter:[170/192], Time: 1.24, lr_generatore: [0.00270704955139683], Loss_seg: 2.716518, loss_adv: 0.008299, loss_D_src: 0.651426, loss_D_trg: 0.653321\n",
      "Epoch: [9/20] Iter:[180/192], Time: 1.24, lr_generatore: [0.0026945007714740126], Loss_seg: 1.695744, loss_adv: 0.007710, loss_D_src: 0.572315, loss_D_trg: 0.694081\n",
      "Epoch: [9/20] Iter:[190/192], Time: 1.24, lr_generatore: [0.0026819454946117737], Loss_seg: 2.210461, loss_adv: 0.007374, loss_D_src: 0.620774, loss_D_trg: 0.717981\n",
      "Epoch: [9/20], loss_sum: 3.475759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.128314, Loss_Adv (G): 0.007660, Loss_D_Src: 0.661671, Loss_D_Trg: 0.678113\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.39845488 0.22389112 0.12381364 0.25896321 0.09978463\n",
      " 0.12010201 0.22539399] 0.20720049679340233\n",
      "1 [0.         0.51438882 0.32865355 0.30263174 0.34312454 0.09693555\n",
      " 0.1131941  0.43137786] 0.30432945309055853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.285, MeanIU:  0.3043, Best_mIoU:  0.3043\n",
      "[0.         0.51438882 0.32865355 0.30263174 0.34312454 0.09693555\n",
      " 0.1131941  0.43137786]\n",
      "Epoch: [10/20] Iter:[0/192], Time: 5.59, lr_generatore: [0.002679433656340733], Loss_seg: 2.000309, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[10/192], Time: 1.55, lr_generatore: [0.002666870534020157], Loss_seg: 2.239584, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[20/192], Time: 1.32, lr_generatore: [0.0026543008323948857], Loss_seg: 2.444124, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[30/192], Time: 1.22, lr_generatore: [0.0026417245133638313], Loss_seg: 2.105612, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[40/192], Time: 1.17, lr_generatore: [0.0026291415384024426], Loss_seg: 2.204154, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[50/192], Time: 1.14, lr_generatore: [0.00261655186855572], Loss_seg: 1.954418, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[60/192], Time: 1.13, lr_generatore: [0.0026039554644310793], Loss_seg: 2.324209, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[70/192], Time: 1.11, lr_generatore: [0.0025913522861910547], Loss_seg: 1.908977, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[80/192], Time: 1.10, lr_generatore: [0.002578742293545842], Loss_seg: 2.169363, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[90/192], Time: 1.09, lr_generatore: [0.0025661254457456785], Loss_seg: 1.940781, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[100/192], Time: 1.08, lr_generatore: [0.0025535017015730437], Loss_seg: 2.250439, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[110/192], Time: 1.08, lr_generatore: [0.002540871019334694], Loss_seg: 2.076679, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[120/192], Time: 1.08, lr_generatore: [0.002528233356853512], Loss_seg: 1.460011, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[130/192], Time: 1.07, lr_generatore: [0.0025155886714601683], Loss_seg: 1.411566, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[140/192], Time: 1.06, lr_generatore: [0.002502936919984596], Loss_seg: 2.010492, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[150/192], Time: 1.06, lr_generatore: [0.00249027805874727], Loss_seg: 1.562334, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[160/192], Time: 1.06, lr_generatore: [0.002477612043550276], Loss_seg: 2.105167, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[170/192], Time: 1.05, lr_generatore: [0.002464938829668181], Loss_seg: 2.824100, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[180/192], Time: 1.05, lr_generatore: [0.0024522583718386854], Loss_seg: 2.505535, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20] Iter:[190/192], Time: 1.04, lr_generatore: [0.002439570624253055], Loss_seg: 1.970937, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [10/20], loss_sum: 2.091172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.089772, Loss_Adv (G): 0.001401, Loss_D_Src: 0.000000, Loss_D_Trg: 0.000000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.38779101 0.21937805 0.12113133 0.29258496 0.09496504\n",
      " 0.10755974 0.20781125] 0.2044601970053108\n",
      "1 [0.         0.51322462 0.29030243 0.26788891 0.36288112 0.11255247\n",
      " 0.12798767 0.36390534] 0.29124893711953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.305, MeanIU:  0.2912, Best_mIoU:  0.3043\n",
      "[0.         0.51322462 0.29030243 0.26788891 0.36288112 0.11255247\n",
      " 0.12798767 0.36390534]\n",
      "Epoch: [11/20] Iter:[0/192], Time: 5.86, lr_generatore: [0.002437032195894977], Loss_seg: 2.274434, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[10/192], Time: 1.53, lr_generatore: [0.0024243356393505795], Loss_seg: 2.307408, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[20/192], Time: 1.31, lr_generatore: [0.0024116316902987648], Loss_seg: 2.007440, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[30/192], Time: 1.21, lr_generatore: [0.002398920301115225], Loss_seg: 2.261481, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[40/192], Time: 1.17, lr_generatore: [0.0023862014235864755], Loss_seg: 1.944606, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[50/192], Time: 1.14, lr_generatore: [0.002373475008899032], Loss_seg: 2.093661, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[60/192], Time: 1.12, lr_generatore: [0.0023607410076283194], Loss_seg: 2.683332, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[70/192], Time: 1.11, lr_generatore: [0.0023479993697273164], Loss_seg: 2.207919, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[80/192], Time: 1.10, lr_generatore: [0.0023352500445149083], Loss_seg: 2.558567, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[90/192], Time: 1.09, lr_generatore: [0.0023224929806639574], Loss_seg: 1.859366, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[100/192], Time: 1.08, lr_generatore: [0.0023097281261890753], Loss_seg: 2.114908, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[110/192], Time: 1.08, lr_generatore: [0.0022969554284340797], Loss_seg: 2.007530, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[120/192], Time: 1.07, lr_generatore: [0.0022841748340591407], Loss_seg: 1.637293, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[130/192], Time: 1.07, lr_generatore: [0.002271386289027598], Loss_seg: 1.821981, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[140/192], Time: 1.06, lr_generatore: [0.002258589738592435], Loss_seg: 2.187770, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[150/192], Time: 1.06, lr_generatore: [0.0022457851272824087], Loss_seg: 2.245099, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[160/192], Time: 1.06, lr_generatore: [0.002232972398887818], Loss_seg: 2.262851, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[170/192], Time: 1.06, lr_generatore: [0.002220151496445898], Loss_seg: 1.915164, loss_adv: 0.001401, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[180/192], Time: 1.06, lr_generatore: [0.0022073223622258295], Loss_seg: 2.495610, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20] Iter:[190/192], Time: 1.05, lr_generatore: [0.002194484937713357], Loss_seg: 1.938683, loss_adv: 0.001400, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [11/20], loss_sum: 2.059341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.057941, Loss_Adv (G): 0.001400, Loss_D_Src: 0.000000, Loss_D_Trg: 0.000000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.38125049 0.2133106  0.13465267 0.29671122 0.09509885\n",
      " 0.10879949 0.2682611 ] 0.21401205911214174\n",
      "1 [0.         0.49935976 0.3151943  0.33679493 0.35235254 0.10793156\n",
      " 0.12387743 0.41977376] 0.3078977551023955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.739, MeanIU:  0.3079, Best_mIoU:  0.3079\n",
      "[0.         0.49935976 0.3151943  0.33679493 0.35235254 0.10793156\n",
      " 0.12387743 0.41977376]\n",
      "Epoch: [12/20] Iter:[0/192], Time: 4.71, lr_generatore: [0.0021919164527704348], Loss_seg: 1.986874, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[10/192], Time: 1.59, lr_generatore: [0.0021790690015417967], Loss_seg: 1.815037, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[20/192], Time: 1.30, lr_generatore: [0.0021662131284532118], Loss_seg: 2.083725, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[30/192], Time: 1.21, lr_generatore: [0.0021533487723751532], Loss_seg: 2.032231, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[40/192], Time: 1.16, lr_generatore: [0.00214047587132539], Loss_seg: 2.119558, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[50/192], Time: 1.14, lr_generatore: [0.0021275943624513116], Loss_seg: 1.854472, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[60/192], Time: 1.12, lr_generatore: [0.0021147041820117596], Loss_seg: 2.010138, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[70/192], Time: 1.11, lr_generatore: [0.002101805265358363], Loss_seg: 1.495976, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[80/192], Time: 1.10, lr_generatore: [0.0020888975469163466], Loss_seg: 2.242212, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[90/192], Time: 1.09, lr_generatore: [0.0020759809601647965], Loss_seg: 2.365368, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[100/192], Time: 1.09, lr_generatore: [0.002063055437616372], Loss_seg: 1.759085, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[110/192], Time: 1.08, lr_generatore: [0.002050120910796433], Loss_seg: 2.197673, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[120/192], Time: 1.08, lr_generatore: [0.00203717731022157], Loss_seg: 1.838519, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[130/192], Time: 1.07, lr_generatore: [0.002024224565377508], Loss_seg: 2.275748, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[140/192], Time: 1.07, lr_generatore: [0.0020112626046963743], Loss_seg: 1.842780, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[150/192], Time: 1.07, lr_generatore: [0.001998291355533286], Loss_seg: 2.378544, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[160/192], Time: 1.07, lr_generatore: [0.001985310744142257], Loss_seg: 1.680199, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[170/192], Time: 1.07, lr_generatore: [0.0019723206956513794], Loss_seg: 2.306354, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[180/192], Time: 1.06, lr_generatore: [0.001959321134037261], Loss_seg: 2.185659, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20] Iter:[190/192], Time: 1.05, lr_generatore: [0.001946311982098689], Loss_seg: 2.091133, loss_adv: 0.001395, loss_D_src: 0.000000, loss_D_trg: 0.000000\n",
      "Epoch: [12/20], loss_sum: 2.050629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.049234, Loss_Adv (G): 0.001395, Loss_D_Src: 0.000000, Loss_D_Trg: 0.000000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.3323072  0.23675809 0.14026029 0.27154259 0.10207621\n",
      " 0.11509865 0.2550419 ] 0.20758356263643338\n",
      "1 [0.         0.5185087  0.3314621  0.30310599 0.36529773 0.1381725\n",
      " 0.14295592 0.40493849] 0.3149202041394273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 6.804, MeanIU:  0.3149, Best_mIoU:  0.3149\n",
      "[0.         0.5185087  0.3314621  0.30310599 0.36529773 0.1381725\n",
      " 0.14295592 0.40493849]\n",
      "Epoch: [13/20] Iter:[0/192], Time: 5.30, lr_generatore: [0.0019437089939938173], Loss_seg: 2.060287, loss_adv: 0.001379, loss_D_src: 0.689784, loss_D_trg: 0.696578\n",
      "Epoch: [13/20] Iter:[10/192], Time: 1.74, lr_generatore: [0.001930688230061766], Loss_seg: 2.908937, loss_adv: 0.001392, loss_D_src: 0.672939, loss_D_trg: 0.695250\n",
      "Epoch: [13/20] Iter:[20/192], Time: 1.49, lr_generatore: [0.001917657701681707], Loss_seg: 2.422890, loss_adv: 0.001431, loss_D_src: 0.659756, loss_D_trg: 0.708844\n",
      "Epoch: [13/20] Iter:[30/192], Time: 1.40, lr_generatore: [0.00190461732769689], Loss_seg: 1.657917, loss_adv: 0.001499, loss_D_src: 0.758896, loss_D_trg: 0.680805\n",
      "Epoch: [13/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.0018915670256530101], Loss_seg: 2.991158, loss_adv: 0.001496, loss_D_src: 0.703479, loss_D_trg: 0.658270\n",
      "Epoch: [13/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0018785067117673446], Loss_seg: 2.825634, loss_adv: 0.001489, loss_D_src: 0.679139, loss_D_trg: 0.663678\n",
      "Epoch: [13/20] Iter:[60/192], Time: 1.32, lr_generatore: [0.0018654363008969175], Loss_seg: 1.602235, loss_adv: 0.001632, loss_D_src: 0.678216, loss_D_trg: 0.643927\n",
      "Epoch: [13/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.0018523557065056448], Loss_seg: 2.029770, loss_adv: 0.001511, loss_D_src: 0.631172, loss_D_trg: 0.735501\n",
      "Epoch: [13/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.0018392648406304203], Loss_seg: 2.002339, loss_adv: 0.001494, loss_D_src: 0.671447, loss_D_trg: 0.677335\n",
      "Epoch: [13/20] Iter:[90/192], Time: 1.29, lr_generatore: [0.0018261636138461005], Loss_seg: 2.375448, loss_adv: 0.001350, loss_D_src: 0.635728, loss_D_trg: 0.741248\n",
      "Epoch: [13/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.0018130519352293518], Loss_seg: 2.412825, loss_adv: 0.001621, loss_D_src: 0.688844, loss_D_trg: 0.618329\n",
      "Epoch: [13/20] Iter:[110/192], Time: 1.28, lr_generatore: [0.001799929712321292], Loss_seg: 2.205799, loss_adv: 0.001523, loss_D_src: 0.673734, loss_D_trg: 0.682934\n",
      "Epoch: [13/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.0017867968510889031], Loss_seg: 2.410172, loss_adv: 0.001743, loss_D_src: 0.734136, loss_D_trg: 0.595929\n",
      "Epoch: [13/20] Iter:[130/192], Time: 1.27, lr_generatore: [0.0017736532558851443], Loss_seg: 2.472123, loss_adv: 0.001473, loss_D_src: 0.598869, loss_D_trg: 0.709289\n",
      "Epoch: [13/20] Iter:[140/192], Time: 1.27, lr_generatore: [0.0017604988294077164], Loss_seg: 2.082098, loss_adv: 0.001689, loss_D_src: 0.678973, loss_D_trg: 0.589474\n",
      "Epoch: [13/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.0017473334726564255], Loss_seg: 1.953594, loss_adv: 0.001412, loss_D_src: 0.611081, loss_D_trg: 0.724268\n",
      "Epoch: [13/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.00173415708488908], Loss_seg: 1.757454, loss_adv: 0.001656, loss_D_src: 0.656010, loss_D_trg: 0.617676\n",
      "Epoch: [13/20] Iter:[170/192], Time: 1.26, lr_generatore: [0.001720969563575858], Loss_seg: 2.048717, loss_adv: 0.001552, loss_D_src: 0.682606, loss_D_trg: 0.667569\n",
      "Epoch: [13/20] Iter:[180/192], Time: 1.26, lr_generatore: [0.0017077708043520823], Loss_seg: 2.485700, loss_adv: 0.001501, loss_D_src: 0.575025, loss_D_trg: 0.711134\n",
      "Epoch: [13/20] Iter:[190/192], Time: 1.26, lr_generatore: [0.0016945607009693326], Loss_seg: 1.827465, loss_adv: 0.001480, loss_D_src: 0.638833, loss_D_trg: 0.716663\n",
      "Epoch: [13/20], loss_sum: 3.364036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.029331, Loss_Adv (G): 0.001525, Loss_D_Src: 0.659902, Loss_D_Trg: 0.673278\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.37217644 0.2269674  0.13099338 0.26945178 0.09133513\n",
      " 0.11367452 0.23806631] 0.20609499578129034\n",
      "1 [0.         0.52316686 0.27400006 0.29857558 0.29075602 0.10456092\n",
      " 0.1390951  0.37189345] 0.28600685573586027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 7.666, MeanIU:  0.2860, Best_mIoU:  0.3149\n",
      "[0.         0.52316686 0.27400006 0.29857558 0.29075602 0.10456092\n",
      " 0.1390951  0.37189345]\n",
      "Epoch: [14/20] Iter:[0/192], Time: 5.96, lr_generatore: [0.0016919173095082494], Loss_seg: 2.149324, loss_adv: 0.001379, loss_D_src: 0.689860, loss_D_trg: 0.696607\n",
      "Epoch: [14/20] Iter:[10/192], Time: 1.73, lr_generatore: [0.0016786934501595463], Loss_seg: 2.288499, loss_adv: 0.001335, loss_D_src: 0.659133, loss_D_trg: 0.720770\n",
      "Epoch: [14/20] Iter:[20/192], Time: 1.48, lr_generatore: [0.0016654580060223797], Loss_seg: 2.238271, loss_adv: 0.001366, loss_D_src: 0.640786, loss_D_trg: 0.708065\n",
      "Epoch: [14/20] Iter:[30/192], Time: 1.39, lr_generatore: [0.0016522108644710604], Loss_seg: 2.154948, loss_adv: 0.001445, loss_D_src: 0.681718, loss_D_trg: 0.680166\n",
      "Epoch: [14/20] Iter:[40/192], Time: 1.34, lr_generatore: [0.0016389519107709097], Loss_seg: 2.038935, loss_adv: 0.001520, loss_D_src: 0.653181, loss_D_trg: 0.666124\n",
      "Epoch: [14/20] Iter:[50/192], Time: 1.32, lr_generatore: [0.0016256810280194398], Loss_seg: 2.181321, loss_adv: 0.001676, loss_D_src: 0.737443, loss_D_trg: 0.607768\n",
      "Epoch: [14/20] Iter:[60/192], Time: 1.30, lr_generatore: [0.0016123980970853356], Loss_seg: 1.884769, loss_adv: 0.001326, loss_D_src: 0.640379, loss_D_trg: 0.788772\n",
      "Epoch: [14/20] Iter:[70/192], Time: 1.29, lr_generatore: [0.0015991029965451516], Loss_seg: 1.949691, loss_adv: 0.001427, loss_D_src: 0.596964, loss_D_trg: 0.708374\n",
      "Epoch: [14/20] Iter:[80/192], Time: 1.28, lr_generatore: [0.0015857956026176102], Loss_seg: 2.449787, loss_adv: 0.001562, loss_D_src: 0.730570, loss_D_trg: 0.634847\n",
      "Epoch: [14/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.0015724757890953778], Loss_seg: 1.908857, loss_adv: 0.001438, loss_D_src: 0.607167, loss_D_trg: 0.704119\n",
      "Epoch: [14/20] Iter:[100/192], Time: 1.27, lr_generatore: [0.001559143427274212], Loss_seg: 2.186801, loss_adv: 0.001538, loss_D_src: 0.606679, loss_D_trg: 0.678402\n",
      "Epoch: [14/20] Iter:[110/192], Time: 1.27, lr_generatore: [0.0015457983858793464], Loss_seg: 1.606793, loss_adv: 0.001627, loss_D_src: 0.674930, loss_D_trg: 0.655279\n",
      "Epoch: [14/20] Iter:[120/192], Time: 1.26, lr_generatore: [0.0015324405309889717], Loss_seg: 1.344139, loss_adv: 0.001682, loss_D_src: 0.759097, loss_D_trg: 0.631210\n",
      "Epoch: [14/20] Iter:[130/192], Time: 1.26, lr_generatore: [0.0015190697259546801], Loss_seg: 1.895669, loss_adv: 0.001596, loss_D_src: 0.711584, loss_D_trg: 0.630677\n",
      "Epoch: [14/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.0015056858313187158], Loss_seg: 1.904208, loss_adv: 0.001553, loss_D_src: 0.703834, loss_D_trg: 0.647573\n",
      "Epoch: [14/20] Iter:[150/192], Time: 1.25, lr_generatore: [0.0014922887047278672], Loss_seg: 1.857726, loss_adv: 0.001344, loss_D_src: 0.566099, loss_D_trg: 0.758295\n",
      "Epoch: [14/20] Iter:[160/192], Time: 1.25, lr_generatore: [0.001478878200843839], Loss_seg: 1.836466, loss_adv: 0.001524, loss_D_src: 0.628766, loss_D_trg: 0.678205\n",
      "Epoch: [14/20] Iter:[170/192], Time: 1.25, lr_generatore: [0.0014654541712499146], Loss_seg: 2.014500, loss_adv: 0.001715, loss_D_src: 0.720493, loss_D_trg: 0.608124\n",
      "Epoch: [14/20] Iter:[180/192], Time: 1.25, lr_generatore: [0.0014520164643537184], Loss_seg: 1.855532, loss_adv: 0.001344, loss_D_src: 0.531690, loss_D_trg: 0.813660\n",
      "Epoch: [14/20] Iter:[190/192], Time: 1.24, lr_generatore: [0.0014385649252858777], Loss_seg: 2.281191, loss_adv: 0.001448, loss_D_src: 0.678012, loss_D_trg: 0.720830\n",
      "Epoch: [14/20], loss_sum: 3.351349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.016315, Loss_Adv (G): 0.001517, Loss_D_Src: 0.657796, Loss_D_Trg: 0.675721\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.36855472 0.25677471 0.13970914 0.26350404 0.08363968\n",
      " 0.11893519 0.23258417] 0.20910023567615915\n",
      "1 [0.         0.52303312 0.31496198 0.27879022 0.29404389 0.1149912\n",
      " 0.1466051  0.34630313] 0.28838980674643283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.045, MeanIU:  0.2884, Best_mIoU:  0.3149\n",
      "[0.         0.52303312 0.31496198 0.27879022 0.29404389 0.1149912\n",
      " 0.1466051  0.34630313]\n",
      "Epoch: [15/20] Iter:[0/192], Time: 5.74, lr_generatore: [0.0014358729437462937], Loss_seg: 1.744200, loss_adv: 0.001402, loss_D_src: 0.701261, loss_D_trg: 0.685172\n",
      "Epoch: [15/20] Iter:[10/192], Time: 1.72, lr_generatore: [0.0014224045968744162], Loss_seg: 1.557738, loss_adv: 0.001408, loss_D_src: 0.675073, loss_D_trg: 0.685845\n",
      "Epoch: [15/20] Iter:[20/192], Time: 1.49, lr_generatore: [0.001408922065055791], Loss_seg: 2.359068, loss_adv: 0.001482, loss_D_src: 0.694085, loss_D_trg: 0.659855\n",
      "Epoch: [15/20] Iter:[30/192], Time: 1.39, lr_generatore: [0.0013954251822017997], Loss_seg: 1.885549, loss_adv: 0.001510, loss_D_src: 0.676257, loss_D_trg: 0.662337\n",
      "Epoch: [15/20] Iter:[40/192], Time: 1.35, lr_generatore: [0.0013819137784712048], Loss_seg: 1.981625, loss_adv: 0.001472, loss_D_src: 0.621733, loss_D_trg: 0.681003\n",
      "Epoch: [15/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0013683876801436285], Loss_seg: 2.088893, loss_adv: 0.001435, loss_D_src: 0.641172, loss_D_trg: 0.712604\n",
      "Epoch: [15/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.001354846709487322], Loss_seg: 2.828292, loss_adv: 0.001585, loss_D_src: 0.668826, loss_D_trg: 0.634594\n",
      "Epoch: [15/20] Iter:[70/192], Time: 1.30, lr_generatore: [0.0013412906846209081], Loss_seg: 1.463001, loss_adv: 0.001492, loss_D_src: 0.672058, loss_D_trg: 0.676991\n",
      "Epoch: [15/20] Iter:[80/192], Time: 1.29, lr_generatore: [0.00132771941936875], Loss_seg: 2.461886, loss_adv: 0.001484, loss_D_src: 0.715183, loss_D_trg: 0.664825\n",
      "Epoch: [15/20] Iter:[90/192], Time: 1.28, lr_generatore: [0.0013141327231095804], Loss_seg: 2.147729, loss_adv: 0.001342, loss_D_src: 0.640823, loss_D_trg: 0.738351\n",
      "Epoch: [15/20] Iter:[100/192], Time: 1.28, lr_generatore: [0.001300530400617986], Loss_seg: 1.819134, loss_adv: 0.001381, loss_D_src: 0.666579, loss_D_trg: 0.720950\n",
      "Epoch: [15/20] Iter:[110/192], Time: 1.27, lr_generatore: [0.0012869122518983356], Loss_seg: 1.857882, loss_adv: 0.001490, loss_D_src: 0.670254, loss_D_trg: 0.658635\n",
      "Epoch: [15/20] Iter:[120/192], Time: 1.27, lr_generatore: [0.00127327807201069], Loss_seg: 1.927079, loss_adv: 0.001493, loss_D_src: 0.625365, loss_D_trg: 0.670802\n",
      "Epoch: [15/20] Iter:[130/192], Time: 1.26, lr_generatore: [0.0012596276508882059], Loss_seg: 1.911325, loss_adv: 0.001439, loss_D_src: 0.673538, loss_D_trg: 0.721735\n",
      "Epoch: [15/20] Iter:[140/192], Time: 1.26, lr_generatore: [0.001245960773145517], Loss_seg: 2.039631, loss_adv: 0.001518, loss_D_src: 0.671030, loss_D_trg: 0.677165\n",
      "Epoch: [15/20] Iter:[150/192], Time: 1.26, lr_generatore: [0.0012322772178775287], Loss_seg: 2.137980, loss_adv: 0.001586, loss_D_src: 0.647973, loss_D_trg: 0.637935\n",
      "Epoch: [15/20] Iter:[160/192], Time: 1.26, lr_generatore: [0.001218576758448014], Loss_seg: 1.795822, loss_adv: 0.001575, loss_D_src: 0.688073, loss_D_trg: 0.642040\n",
      "Epoch: [15/20] Iter:[170/192], Time: 1.25, lr_generatore: [0.0012048591622673733], Loss_seg: 2.750056, loss_adv: 0.001533, loss_D_src: 0.669393, loss_D_trg: 0.659864\n",
      "Epoch: [15/20] Iter:[180/192], Time: 1.25, lr_generatore: [0.00119112419055885], Loss_seg: 1.864655, loss_adv: 0.001590, loss_D_src: 0.613464, loss_D_trg: 0.629189\n",
      "Epoch: [15/20] Iter:[190/192], Time: 1.25, lr_generatore: [0.0011773715981124454], Loss_seg: 1.269472, loss_adv: 0.001517, loss_D_src: 0.579117, loss_D_trg: 0.680881\n",
      "Epoch: [15/20], loss_sum: 3.345526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 2.005264, Loss_Adv (G): 0.001486, Loss_D_Src: 0.662873, Loss_D_Trg: 0.675902\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.36771914 0.23836872 0.12634823 0.27119297 0.08294224\n",
      " 0.12332025 0.23240025] 0.20604168579825785\n",
      "1 [0.         0.52294869 0.33324327 0.27623097 0.3218531  0.09981379\n",
      " 0.13147329 0.37863578] 0.29488555419509893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.078, MeanIU:  0.2949, Best_mIoU:  0.3149\n",
      "[0.         0.52294869 0.33324327 0.27623097 0.3218531  0.09981379\n",
      " 0.13147329 0.37863578]\n",
      "Epoch: [16/20] Iter:[0/192], Time: 5.13, lr_generatore: [0.0011746189430880188], Loss_seg: 1.825383, loss_adv: 0.001404, loss_D_src: 0.702328, loss_D_trg: 0.684319\n",
      "Epoch: [16/20] Iter:[10/192], Time: 1.71, lr_generatore: [0.0011608448726369374], Loss_seg: 1.754373, loss_adv: 0.001367, loss_D_src: 0.676841, loss_D_trg: 0.704992\n",
      "Epoch: [16/20] Iter:[20/192], Time: 1.46, lr_generatore: [0.0011470526180429013], Loss_seg: 1.404680, loss_adv: 0.001405, loss_D_src: 0.669664, loss_D_trg: 0.690684\n",
      "Epoch: [16/20] Iter:[30/192], Time: 1.37, lr_generatore: [0.0011332419116973614], Loss_seg: 2.321593, loss_adv: 0.001465, loss_D_src: 0.662735, loss_D_trg: 0.671203\n",
      "Epoch: [16/20] Iter:[40/192], Time: 1.33, lr_generatore: [0.0011194124783710509], Loss_seg: 1.821412, loss_adv: 0.001472, loss_D_src: 0.722742, loss_D_trg: 0.688272\n",
      "Epoch: [16/20] Iter:[50/192], Time: 1.30, lr_generatore: [0.0011055640348892135], Loss_seg: 2.802655, loss_adv: 0.001560, loss_D_src: 0.683307, loss_D_trg: 0.643362\n",
      "Epoch: [16/20] Iter:[60/192], Time: 1.28, lr_generatore: [0.0010916962897882718], Loss_seg: 1.596485, loss_adv: 0.001486, loss_D_src: 0.672629, loss_D_trg: 0.676750\n",
      "Epoch: [16/20] Iter:[70/192], Time: 1.27, lr_generatore: [0.0010778089429525984], Loss_seg: 1.522414, loss_adv: 0.001507, loss_D_src: 0.672071, loss_D_trg: 0.669769\n",
      "Epoch: [16/20] Iter:[80/192], Time: 1.26, lr_generatore: [0.001063901685229926], Loss_seg: 2.094275, loss_adv: 0.001476, loss_D_src: 0.657591, loss_D_trg: 0.689636\n",
      "Epoch: [16/20] Iter:[90/192], Time: 1.25, lr_generatore: [0.0010499741980238254], Loss_seg: 1.932797, loss_adv: 0.001532, loss_D_src: 0.645720, loss_D_trg: 0.661301\n",
      "Epoch: [16/20] Iter:[100/192], Time: 1.25, lr_generatore: [0.0010360261528615147], Loss_seg: 1.759286, loss_adv: 0.001499, loss_D_src: 0.690612, loss_D_trg: 0.682753\n",
      "Epoch: [16/20] Iter:[110/192], Time: 1.24, lr_generatore: [0.001022057210935114], Loss_seg: 2.108810, loss_adv: 0.001511, loss_D_src: 0.668866, loss_D_trg: 0.672880\n",
      "Epoch: [16/20] Iter:[120/192], Time: 1.24, lr_generatore: [0.0010080670226142933], Loss_seg: 2.296489, loss_adv: 0.001526, loss_D_src: 0.604727, loss_D_trg: 0.685900\n",
      "Epoch: [16/20] Iter:[130/192], Time: 1.23, lr_generatore: [0.000994055226928056], Loss_seg: 2.001158, loss_adv: 0.001604, loss_D_src: 0.656455, loss_D_trg: 0.639661\n",
      "Epoch: [16/20] Iter:[140/192], Time: 1.23, lr_generatore: [0.0009800214510131803], Loss_seg: 1.322964, loss_adv: 0.001544, loss_D_src: 0.576374, loss_D_trg: 0.715132\n",
      "Epoch: [16/20] Iter:[150/192], Time: 1.23, lr_generatore: [0.0009659653095266238], Loss_seg: 2.443021, loss_adv: 0.001747, loss_D_src: 0.671260, loss_D_trg: 0.607766\n",
      "Epoch: [16/20] Iter:[160/192], Time: 1.23, lr_generatore: [0.0009518864040189021], Loss_seg: 2.175698, loss_adv: 0.001697, loss_D_src: 0.609138, loss_D_trg: 0.635930\n",
      "Epoch: [16/20] Iter:[170/192], Time: 1.23, lr_generatore: [0.0009377843222651657], Loss_seg: 1.745895, loss_adv: 0.001763, loss_D_src: 0.666681, loss_D_trg: 0.620444\n",
      "Epoch: [16/20] Iter:[180/192], Time: 1.22, lr_generatore: [0.000923658637550369], Loss_seg: 1.695889, loss_adv: 0.001647, loss_D_src: 0.583176, loss_D_trg: 0.633878\n",
      "Epoch: [16/20] Iter:[190/192], Time: 1.22, lr_generatore: [0.0009095089079045436], Loss_seg: 1.731323, loss_adv: 0.001617, loss_D_src: 0.754732, loss_D_trg: 0.642482\n",
      "Epoch: [16/20], loss_sum: 3.322786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 1.987060, Loss_Adv (G): 0.001531, Loss_D_Src: 0.664617, Loss_D_Trg: 0.669578\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.35479957 0.24591447 0.14983137 0.26333037 0.09383257\n",
      " 0.10989554 0.25727042] 0.2106963303045386\n",
      "1 [0.         0.5029211  0.31496623 0.30543622 0.30799137 0.11039458\n",
      " 0.11592753 0.37111429] 0.28982161569902426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.899, MeanIU:  0.2898, Best_mIoU:  0.3149\n",
      "[0.         0.5029211  0.31496623 0.30543622 0.30799137 0.11039458\n",
      " 0.11592753 0.37111429]\n",
      "Epoch: [17/20] Iter:[0/192], Time: 6.07, lr_generatore: [0.0009066760365683728], Loss_seg: 1.949369, loss_adv: 0.001380, loss_D_src: 0.690162, loss_D_trg: 0.696408\n",
      "Epoch: [17/20] Iter:[10/192], Time: 1.73, lr_generatore: [0.000892496846911698], Loss_seg: 2.096294, loss_adv: 0.001318, loss_D_src: 0.646847, loss_D_trg: 0.730665\n",
      "Epoch: [17/20] Iter:[20/192], Time: 1.47, lr_generatore: [0.0008782925821687058], Loss_seg: 2.387231, loss_adv: 0.001348, loss_D_src: 0.645368, loss_D_trg: 0.716472\n",
      "Epoch: [17/20] Iter:[30/192], Time: 1.37, lr_generatore: [0.0008640627457500401], Loss_seg: 2.569891, loss_adv: 0.001401, loss_D_src: 0.649572, loss_D_trg: 0.692341\n",
      "Epoch: [17/20] Iter:[40/192], Time: 1.32, lr_generatore: [0.0008498068219461516], Loss_seg: 1.834267, loss_adv: 0.001391, loss_D_src: 0.665281, loss_D_trg: 0.706830\n",
      "Epoch: [17/20] Iter:[50/192], Time: 1.29, lr_generatore: [0.0008355242748201926], Loss_seg: 2.070236, loss_adv: 0.001397, loss_D_src: 0.671586, loss_D_trg: 0.708704\n",
      "Epoch: [17/20] Iter:[60/192], Time: 1.27, lr_generatore: [0.0008212145470145029], Loss_seg: 1.972908, loss_adv: 0.001490, loss_D_src: 0.667112, loss_D_trg: 0.672751\n",
      "Epoch: [17/20] Iter:[70/192], Time: 1.26, lr_generatore: [0.0008068770584621481], Loss_seg: 1.886371, loss_adv: 0.001487, loss_D_src: 0.687145, loss_D_trg: 0.673481\n",
      "Epoch: [17/20] Iter:[80/192], Time: 1.25, lr_generatore: [0.0007925112049939223], Loss_seg: 2.148973, loss_adv: 0.001516, loss_D_src: 0.691601, loss_D_trg: 0.669147\n",
      "Epoch: [17/20] Iter:[90/192], Time: 1.24, lr_generatore: [0.0007781163568300455], Loss_seg: 1.445455, loss_adv: 0.001452, loss_D_src: 0.676103, loss_D_trg: 0.701172\n",
      "Epoch: [17/20] Iter:[100/192], Time: 1.23, lr_generatore: [0.0007636918569444497], Loss_seg: 2.190280, loss_adv: 0.001608, loss_D_src: 0.689914, loss_D_trg: 0.632439\n",
      "Epoch: [17/20] Iter:[110/192], Time: 1.23, lr_generatore: [0.0007492370192879776], Loss_seg: 2.084598, loss_adv: 0.001566, loss_D_src: 0.695083, loss_D_trg: 0.637131\n",
      "Epoch: [17/20] Iter:[120/192], Time: 1.23, lr_generatore: [0.0007347511268550237], Loss_seg: 2.029077, loss_adv: 0.001509, loss_D_src: 0.587382, loss_D_trg: 0.670502\n",
      "Epoch: [17/20] Iter:[130/192], Time: 1.22, lr_generatore: [0.0007202334295760923], Loss_seg: 1.854714, loss_adv: 0.001329, loss_D_src: 0.629745, loss_D_trg: 0.768263\n",
      "Epoch: [17/20] Iter:[140/192], Time: 1.22, lr_generatore: [0.0007056831420163294], Loss_seg: 2.227687, loss_adv: 0.001565, loss_D_src: 0.669401, loss_D_trg: 0.634574\n",
      "Epoch: [17/20] Iter:[150/192], Time: 1.22, lr_generatore: [0.0006910994408572893], Loss_seg: 1.775067, loss_adv: 0.001565, loss_D_src: 0.634425, loss_D_trg: 0.656238\n",
      "Epoch: [17/20] Iter:[160/192], Time: 1.22, lr_generatore: [0.0006764814621359547], Loss_seg: 1.870332, loss_adv: 0.001501, loss_D_src: 0.634676, loss_D_trg: 0.711630\n",
      "Epoch: [17/20] Iter:[170/192], Time: 1.21, lr_generatore: [0.0006618282982111901], Loss_seg: 2.004117, loss_adv: 0.001626, loss_D_src: 0.679255, loss_D_trg: 0.626863\n",
      "Epoch: [17/20] Iter:[180/192], Time: 1.21, lr_generatore: [0.0006471389944233259], Loss_seg: 1.875885, loss_adv: 0.001548, loss_D_src: 0.643441, loss_D_trg: 0.653908\n",
      "Epoch: [17/20] Iter:[190/192], Time: 1.21, lr_generatore: [0.0006324125454072901], Loss_seg: 2.377745, loss_adv: 0.001615, loss_D_src: 0.616664, loss_D_trg: 0.639989\n",
      "Epoch: [17/20], loss_sum: 3.316426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 1.972712, Loss_Adv (G): 0.001474, Loss_D_Src: 0.660393, Loss_D_Trg: 0.681847\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.37230148 0.2386368  0.14577339 0.27241076 0.09269948\n",
      " 0.11761403 0.27175055] 0.21588378588204368\n",
      "1 [0.         0.5236077  0.30489813 0.30961906 0.31166429 0.11903204\n",
      " 0.14693414 0.36863108] 0.2977694919083915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.320, MeanIU:  0.2978, Best_mIoU:  0.3149\n",
      "[0.         0.5236077  0.30489813 0.30961906 0.31166429 0.11903204\n",
      " 0.14693414 0.36863108]\n",
      "Epoch: [18/20] Iter:[0/192], Time: 5.65, lr_generatore: [0.0006294627058970835], Loss_seg: 1.651242, loss_adv: 0.001402, loss_D_src: 0.701309, loss_D_trg: 0.685472\n",
      "Epoch: [18/20] Iter:[10/192], Time: 1.72, lr_generatore: [0.0006146902780755803], Loss_seg: 2.062602, loss_adv: 0.001334, loss_D_src: 0.656394, loss_D_trg: 0.721321\n",
      "Epoch: [18/20] Iter:[20/192], Time: 1.47, lr_generatore: [0.0005998782939750377], Loss_seg: 1.760207, loss_adv: 0.001352, loss_D_src: 0.673697, loss_D_trg: 0.712250\n",
      "Epoch: [18/20] Iter:[30/192], Time: 1.38, lr_generatore: [0.0005850255562722003], Loss_seg: 1.568467, loss_adv: 0.001364, loss_D_src: 0.667010, loss_D_trg: 0.706715\n",
      "Epoch: [18/20] Iter:[40/192], Time: 1.33, lr_generatore: [0.0005701307964885376], Loss_seg: 2.222525, loss_adv: 0.001383, loss_D_src: 0.661696, loss_D_trg: 0.699682\n",
      "Epoch: [18/20] Iter:[50/192], Time: 1.30, lr_generatore: [0.0005551926685652707], Loss_seg: 1.534316, loss_adv: 0.001396, loss_D_src: 0.669720, loss_D_trg: 0.694493\n",
      "Epoch: [18/20] Iter:[60/192], Time: 1.28, lr_generatore: [0.0005402097416479865], Loss_seg: 2.182002, loss_adv: 0.001405, loss_D_src: 0.653588, loss_D_trg: 0.692412\n",
      "Epoch: [18/20] Iter:[70/192], Time: 1.27, lr_generatore: [0.0005251804919561193], Loss_seg: 1.690702, loss_adv: 0.001429, loss_D_src: 0.668149, loss_D_trg: 0.680811\n",
      "Epoch: [18/20] Iter:[80/192], Time: 1.25, lr_generatore: [0.0005101032935882801], Loss_seg: 1.927838, loss_adv: 0.001440, loss_D_src: 0.645420, loss_D_trg: 0.681085\n",
      "Epoch: [18/20] Iter:[90/192], Time: 1.25, lr_generatore: [0.000494976408084457], Loss_seg: 1.850749, loss_adv: 0.001457, loss_D_src: 0.666686, loss_D_trg: 0.683590\n",
      "Epoch: [18/20] Iter:[100/192], Time: 1.24, lr_generatore: [0.0004797979725288414], Loss_seg: 2.226158, loss_adv: 0.001467, loss_D_src: 0.668718, loss_D_trg: 0.677461\n",
      "Epoch: [18/20] Iter:[110/192], Time: 1.24, lr_generatore: [0.000464565985930452], Loss_seg: 2.071929, loss_adv: 0.001437, loss_D_src: 0.666456, loss_D_trg: 0.690326\n",
      "Epoch: [18/20] Iter:[120/192], Time: 1.23, lr_generatore: [0.0004492782935600459], Loss_seg: 2.142646, loss_adv: 0.001411, loss_D_src: 0.678413, loss_D_trg: 0.716059\n",
      "Epoch: [18/20] Iter:[130/192], Time: 1.23, lr_generatore: [0.0004339325688472477], Loss_seg: 2.434273, loss_adv: 0.001461, loss_D_src: 0.692511, loss_D_trg: 0.684904\n",
      "Epoch: [18/20] Iter:[140/192], Time: 1.23, lr_generatore: [0.0004185262923463735], Loss_seg: 1.947357, loss_adv: 0.001507, loss_D_src: 0.720442, loss_D_trg: 0.659506\n",
      "Epoch: [18/20] Iter:[150/192], Time: 1.22, lr_generatore: [0.000403056727156104], Loss_seg: 2.333714, loss_adv: 0.001476, loss_D_src: 0.679376, loss_D_trg: 0.682864\n",
      "Epoch: [18/20] Iter:[160/192], Time: 1.22, lr_generatore: [0.00038752089001721816], Loss_seg: 1.897722, loss_adv: 0.001451, loss_D_src: 0.658290, loss_D_trg: 0.686945\n",
      "Epoch: [18/20] Iter:[170/192], Time: 1.22, lr_generatore: [0.00037191551710044743], Loss_seg: 2.281618, loss_adv: 0.001511, loss_D_src: 0.646470, loss_D_trg: 0.663264\n",
      "Epoch: [18/20] Iter:[180/192], Time: 1.22, lr_generatore: [0.0003562370232136389], Loss_seg: 2.313210, loss_adv: 0.001474, loss_D_src: 0.679607, loss_D_trg: 0.674569\n",
      "Epoch: [18/20] Iter:[190/192], Time: 1.21, lr_generatore: [0.0003404814527755612], Loss_seg: 1.810899, loss_adv: 0.001529, loss_D_src: 0.672511, loss_D_trg: 0.656567\n",
      "Epoch: [18/20], loss_sum: 3.318670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 1.963361, Loss_Adv (G): 0.001437, Loss_D_Src: 0.667623, Loss_D_Trg: 0.686248\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.36376455 0.23972224 0.14810934 0.27127257 0.09734428\n",
      " 0.11098532 0.25919956] 0.21291397962529793\n",
      "1 [0.         0.52535056 0.31314963 0.31678495 0.31019041 0.12068669\n",
      " 0.14121419 0.36492354] 0.29889999497276115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.856, MeanIU:  0.2989, Best_mIoU:  0.3149\n",
      "[0.         0.52535056 0.31314963 0.31678495 0.31019041 0.12068669\n",
      " 0.14121419 0.36492354]\n",
      "Epoch: [19/20] Iter:[0/192], Time: 6.92, lr_generatore: [0.0003373207119183911], Loss_seg: 2.062080, loss_adv: 0.001377, loss_D_src: 0.688387, loss_D_trg: 0.697894\n",
      "Epoch: [19/20] Iter:[10/192], Time: 1.80, lr_generatore: [0.0003214668181169949], Loss_seg: 1.625670, loss_adv: 0.001372, loss_D_src: 0.670000, loss_D_trg: 0.701700\n",
      "Epoch: [19/20] Iter:[20/192], Time: 1.51, lr_generatore: [0.00030552552892554736], Loss_seg: 2.489949, loss_adv: 0.001381, loss_D_src: 0.679088, loss_D_trg: 0.698134\n",
      "Epoch: [19/20] Iter:[30/192], Time: 1.41, lr_generatore: [0.00028949123265094973], Loss_seg: 1.853954, loss_adv: 0.001339, loss_D_src: 0.676506, loss_D_trg: 0.721663\n",
      "Epoch: [19/20] Iter:[40/192], Time: 1.36, lr_generatore: [0.00027335758661013883], Loss_seg: 2.376482, loss_adv: 0.001385, loss_D_src: 0.679068, loss_D_trg: 0.696129\n",
      "Epoch: [19/20] Iter:[50/192], Time: 1.33, lr_generatore: [0.0002571173671675648], Loss_seg: 1.734505, loss_adv: 0.001385, loss_D_src: 0.688544, loss_D_trg: 0.696624\n",
      "Epoch: [19/20] Iter:[60/192], Time: 1.31, lr_generatore: [0.00024076227616562414], Loss_seg: 1.480648, loss_adv: 0.001371, loss_D_src: 0.674438, loss_D_trg: 0.703514\n",
      "Epoch: [19/20] Iter:[70/192], Time: 1.29, lr_generatore: [0.0002242826867552745], Loss_seg: 2.156863, loss_adv: 0.001393, loss_D_src: 0.687444, loss_D_trg: 0.692554\n",
      "Epoch: [19/20] Iter:[80/192], Time: 1.28, lr_generatore: [0.00020766730304944998], Loss_seg: 1.881043, loss_adv: 0.001362, loss_D_src: 0.678343, loss_D_trg: 0.707944\n",
      "Epoch: [19/20] Iter:[90/192], Time: 1.27, lr_generatore: [0.00019090269392665218], Loss_seg: 2.233283, loss_adv: 0.001391, loss_D_src: 0.669653, loss_D_trg: 0.693812\n",
      "Epoch: [19/20] Iter:[100/192], Time: 1.26, lr_generatore: [0.00017397263726258932], Loss_seg: 2.176733, loss_adv: 0.001394, loss_D_src: 0.677360, loss_D_trg: 0.691490\n",
      "Epoch: [19/20] Iter:[110/192], Time: 1.26, lr_generatore: [0.00015685716794115997], Loss_seg: 1.549355, loss_adv: 0.001393, loss_D_src: 0.671481, loss_D_trg: 0.692554\n",
      "Epoch: [19/20] Iter:[120/192], Time: 1.25, lr_generatore: [0.00013953114214185816], Loss_seg: 2.032348, loss_adv: 0.001385, loss_D_src: 0.682015, loss_D_trg: 0.697428\n",
      "Epoch: [19/20] Iter:[130/192], Time: 1.25, lr_generatore: [0.0001219619678176892], Loss_seg: 1.759820, loss_adv: 0.001395, loss_D_src: 0.693540, loss_D_trg: 0.692111\n",
      "Epoch: [19/20] Iter:[140/192], Time: 1.24, lr_generatore: [0.00010410579660501023], Loss_seg: 2.181159, loss_adv: 0.001395, loss_D_src: 0.676227, loss_D_trg: 0.691466\n",
      "Epoch: [19/20] Iter:[150/192], Time: 1.24, lr_generatore: [8.590061314414471e-05], Loss_seg: 2.077161, loss_adv: 0.001377, loss_D_src: 0.678571, loss_D_trg: 0.700625\n",
      "Epoch: [19/20] Iter:[160/192], Time: 1.24, lr_generatore: [6.725225993591909e-05], Loss_seg: 2.454037, loss_adv: 0.001389, loss_D_src: 0.672532, loss_D_trg: 0.695344\n",
      "Epoch: [19/20] Iter:[170/192], Time: 1.23, lr_generatore: [4.800122437596268e-05], Loss_seg: 1.241160, loss_adv: 0.001411, loss_D_src: 0.690603, loss_D_trg: 0.684909\n",
      "Epoch: [19/20] Iter:[180/192], Time: 1.23, lr_generatore: [2.7818584240241676e-05], Loss_seg: 1.839340, loss_adv: 0.001386, loss_D_src: 0.689995, loss_D_trg: 0.697582\n",
      "Epoch: [19/20] Iter:[190/192], Time: 1.23, lr_generatore: [5.546243062674748e-06], Loss_seg: 2.130520, loss_adv: 0.001388, loss_D_src: 0.678553, loss_D_trg: 0.695640\n",
      "Epoch: [19/20], loss_sum: 3.353111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Summary:  Loss_Seg (G): 1.975631, Loss_Adv (G): 0.001380, Loss_D_Src: 0.676754, Loss_D_Trg: 0.699347\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.39059344 0.24318124 0.13887818 0.26599414 0.10050989\n",
      " 0.10928571 0.25512575] 0.2147954794914581\n",
      "1 [0.         0.5279234  0.31785875 0.29347164 0.30257809 0.11993598\n",
      " 0.13484316 0.36415744] 0.2943954945501798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/gan_cjcheckpoint.pth.tar\n",
      "Loss: 8.926, MeanIU:  0.2944, Best_mIoU:  0.3149\n",
      "[0.         0.5279234  0.31785875 0.29347164 0.30257809 0.11993598\n",
      " 0.13484316 0.36415744]\n",
      "Hours: 2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# from re import L\n",
    "# ------------------------------------------------------------------------------\n",
    "# Modified based on https://github.com/HRNet/HRNet-Semantic-Segmentation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import albumentations as A\n",
    "import logging\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "import sys\n",
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        default=\"configs/loveda/pidnet_small_loveda.yaml\", #file di configurazione da usare\n",
    "                        type=str)\n",
    "    parser.add_argument('--seed', type=int, default=304)\n",
    "    parser.add_argument('--opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=[],\n",
    "                        nargs=argparse.REMAINDER)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    update_config(config, args) #aggiorna config con tutti i parametri trovati nel file di configurazione\n",
    "\n",
    "    return args\n",
    "\n",
    "def plot_metrics(train_loss_history, eval_loss_history, mean_iou_history):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 8))\n",
    "\n",
    "    ax[0].plot(train_loss_history, label='Training Loss', color='blue', marker='o')\n",
    "    ax[0].plot(eval_loss_history, label='Evaluation Loss', color='orange', marker='x')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid()\n",
    "    \n",
    "    ax[1].plot(eval_loss_history, label='Evaluation Loss', color='orange', marker='x')\n",
    "    ax[1].set_title('Evaluation Loss')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid()\n",
    "\n",
    "    ax[2].plot(mean_iou_history, label='Mean IoU', color='green', marker='o')\n",
    "    ax[2].set_title('Mean IoU')\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('IoU')\n",
    "    ax[2].legend()\n",
    "    ax[2].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_iou(iou_array, mean_iou, epoch=None):\n",
    " \n",
    "    iou_array = np.array(iou_array)\n",
    "    num_classes = len(iou_array)\n",
    "    class_names = [\n",
    "        'ignored',     # 0\n",
    "        'background',  # 1\n",
    "        'building',    # 2\n",
    "        'road',        # 3\n",
    "        'water',       # 4\n",
    "        'barren',      # 5\n",
    "        'forest',      # 6\n",
    "        'agriculture'  # 7\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(class_names, iou_array, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Linea per la media\n",
    "    plt.axhline(mean_iou, color='red', linestyle='--', label=f'Mean IoU = {mean_iou:.2f}')\n",
    "\n",
    "    # Annotazioni sopra le barre\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, height + 0.01, f'{height:.2f}',\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    title = \"IoU per Classe\"\n",
    "    if epoch is not None:\n",
    "        title += f\" - Epoch {epoch}\"\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_gan_metrics(loss_seg_hist, loss_adv_hist,loss_D_src_hist, loss_D_trg_hist):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "    # 1) loss di segmentazione\n",
    "    ax[0].plot(loss_seg_hist,  label=\"Loss Seg (G)\", marker=\"o\")\n",
    "    ax[0].set_title(\"Segmentation Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].grid();  ax[0].legend()\n",
    "\n",
    "    # 2) loss adversarial del generatore\n",
    "    ax[1].plot(loss_adv_hist, label=\"Loss Adv (G)\", marker=\"x\", color=\"tab:red\")\n",
    "    ax[1].set_title(\"Adversarial Loss\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"Loss\")\n",
    "    ax[1].grid();  ax[1].legend()\n",
    "\n",
    "    # 3) loss del discriminatore (source vs target)\n",
    "    ax[2].plot(loss_D_src_hist, label=\"Loss D Src\", marker=\"s\", color=\"tab:green\")\n",
    "    ax[2].plot(loss_D_trg_hist, label=\"Loss D Trg\", marker=\"d\", color=\"tab:orange\")\n",
    "    ax[2].set_title(\"Discriminator Loss\")\n",
    "    ax[2].set_xlabel(\"Epoch\")\n",
    "    ax[2].set_ylabel(\"Loss\")\n",
    "    ax[2].grid();  ax[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.seed > 0:\n",
    "        import random\n",
    "        print('Seeding with', args.seed)\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)        \n",
    "\n",
    "    logger, final_output_dir, tb_log_dir = create_logger(config, args.cfg, 'train')\n",
    "    logger.info(pprint.pformat(args))\n",
    "    logger.info(config)\n",
    "\n",
    "    writer_dict = {\n",
    "        'writer': SummaryWriter(tb_log_dir),\n",
    "        'train_global_steps': 0,\n",
    "        'valid_global_steps': 0,\n",
    "    }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # cudnn related setting\n",
    "        cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "        cudnn.deterministic = config.CUDNN.DETERMINISTIC\n",
    "        cudnn.enabled = config.CUDNN.ENABLED\n",
    "        gpus = list(config.GPUS)\n",
    "        if torch.cuda.device_count() != len(gpus):\n",
    "            print(\"The gpu numbers do not match!\")\n",
    "            return 0\n",
    "    gpus = list(config.GPUS)\n",
    "    \n",
    "    imgnet = 'imagenet' in config.MODEL.PRETRAINED\n",
    "\n",
    "    \n",
    "    model = get_seg_model(config, imgnet_pretrained=imgnet)\n",
    " \n",
    "    batch_size = config.TRAIN.BATCH_SIZE_PER_GPU * len(gpus)\n",
    "    # prepare data\n",
    "    #crop_size = (config.TRAIN.IMAGE_SIZE[1], config.TRAIN.IMAGE_SIZE[0])\n",
    "    crop_size = (1024, 1024)\n",
    "\n",
    "    train_trasform = None\n",
    "\n",
    "    if config.TRAIN.AUGMENTATION.ENABLE:\n",
    "        list_augmentations = []\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP:\n",
    "            list_augmentations.append(A.RandomResizedCrop(1024, 1024, p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP:\n",
    "            list_augmentations.append(A.HorizontalFlip(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER:\n",
    "            list_augmentations.append(A.ColorJitter(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR:\n",
    "            list_augmentations.append(A.GaussianBlur(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE:\n",
    "            list_augmentations.append(A.GaussNoise(var_limit=(100, 1000), p=1.0))\n",
    "        if len(list_augmentations) != 0:\n",
    "            train_trasform = A.Compose(list_augmentations)\n",
    "\n",
    "    \n",
    "    print(\"train with standard dataset\")\n",
    "    #The eval() function evaluates the specified expression, if the expression is a legal Python statement, it will be executed.\n",
    "    train_dataset = LoveDA(\n",
    "                        root=config.DATASET.ROOT,\n",
    "                        list_path=config.DATASET.TRAIN_SET,\n",
    "                        num_classes=config.DATASET.NUM_CLASSES,\n",
    "                        multi_scale=config.TRAIN.MULTI_SCALE,\n",
    "                        flip=config.TRAIN.FLIP,\n",
    "                        ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                        base_size=config.TRAIN.BASE_SIZE,\n",
    "                        crop_size=crop_size,\n",
    "                        scale_factor=config.TRAIN.SCALE_FACTOR,\n",
    "                        enable_augmentation=True,\n",
    "                        horizontal_flip=config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP,\n",
    "                        gaussian_blur=config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR,\n",
    "                        transform=train_trasform)\n",
    "    \n",
    "    \n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=config.TRAIN.SHUFFLE,\n",
    "        num_workers=config.WORKERS,\n",
    "        pin_memory=False,\n",
    "        drop_last=True)\n",
    "    \n",
    "\n",
    "    targetloader = None\n",
    "    if config.TRAIN.DACS.ENABLE or config.TRAIN.GAN.ENABLE:\n",
    "        target_dataset = LoveDA(\n",
    "                            root=config.DATASET.ROOT, \n",
    "                            list_path=config.DATASET.TARGET_SET,\n",
    "                            num_classes=config.DATASET.NUM_CLASSES, \n",
    "                            multi_scale=config.TRAIN.MULTI_SCALE,\n",
    "                            flip=config.TRAIN.FLIP, \n",
    "                            enable_augmentation=True,\n",
    "                            ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                            base_size=config.TRAIN.BASE_SIZE,\n",
    "                            crop_size=crop_size, \n",
    "                            scale_factor=config.TRAIN.SCALE_FACTOR,\n",
    "                            horizontal_flip=config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP,\n",
    "                            gaussian_blur=config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR,\n",
    "                            transform=train_trasform)\n",
    "\n",
    "        targetloader = torch.utils.data.DataLoader(\n",
    "            target_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=config.TRAIN.SHUFFLE,\n",
    "            num_workers=config.WORKERS, \n",
    "            pin_memory=False, \n",
    "            drop_last=True)\n",
    "\n",
    "\n",
    "    test_size = (config.TEST.IMAGE_SIZE[1], config.TEST.IMAGE_SIZE[0])\n",
    "    test_dataset = LoveDA(\n",
    "                        root=config.DATASET.ROOT,\n",
    "                        list_path=config.DATASET.TEST_SET,\n",
    "                        num_classes=config.DATASET.NUM_CLASSES,\n",
    "                        multi_scale=False,\n",
    "                        flip=False,\n",
    "                        ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                        base_size=config.TEST.BASE_SIZE,\n",
    "                        crop_size=test_size)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.TEST.BATCH_SIZE_PER_GPU * len(gpus),\n",
    "        shuffle=False,\n",
    "        num_workers=config.WORKERS,\n",
    "        pin_memory=False)\n",
    "\n",
    "    # criterion\n",
    "    if config.LOSS.USE_OHEM:\n",
    "        sem_criterion = OhemCrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                        thres=config.LOSS.OHEMTHRES,\n",
    "                                        min_kept=config.LOSS.OHEMKEEP,\n",
    "                                        weight=train_dataset.class_weights)\n",
    "    else:\n",
    "        sem_criterion = CrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                    weight=train_dataset.class_weights)\n",
    "\n",
    "    bd_criterion = BondaryLoss()\n",
    "    \n",
    "    \n",
    "    model = FullModel(model, sem_criterion, bd_criterion)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = nn.DataParallel(model, device_ids=gpus).cuda() #per noi inutile\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    if config.TRAIN.OPTIMIZER == 'sgd':\n",
    "        params_dict = dict(model.named_parameters())\n",
    "        params = [{'params': list(params_dict.values()), 'lr': config.TRAIN.LR}]\n",
    "\n",
    "        optimizer = torch.optim.SGD(params,\n",
    "                                lr=config.TRAIN.LR,\n",
    "                                momentum=config.TRAIN.MOMENTUM,\n",
    "                                weight_decay=config.TRAIN.WD,\n",
    "                                nesterov=config.TRAIN.NESTEROV,\n",
    "                                )\n",
    "        #optimizer = Optimizer(model=model.module, loss=bd_criterion,\n",
    "        #                  lr0=1e-2, momentum=0.9, wd=5e-4,\n",
    "        #                  warmup_steps=960, warmup_start_lr=1e-5,\n",
    "        #                  max_iter=len(trainloader)*20,\n",
    "        #                  power=0.9)\n",
    "    else:\n",
    "        raise ValueError('Only Support SGD optimizer')\n",
    "\n",
    "    epoch_iters = int(train_dataset.__len__() / config.TRAIN.BATCH_SIZE_PER_GPU / len(gpus))\n",
    "        \n",
    "    best_mIoU = 0\n",
    "    last_epoch = 0\n",
    "    flag_rm = config.TRAIN.RESUME\n",
    "    if config.TRAIN.RESUME:\n",
    "        model_state_file = os.path.join(final_output_dir, 'checkpoint.pth.tar')\n",
    "        if os.path.isfile(model_state_file):\n",
    "            print('-'*60)\n",
    "            checkpoint = torch.load(model_state_file, map_location={'cuda:0': 'cpu'})\n",
    "            best_mIoU = checkpoint['best_mIoU']\n",
    "            last_epoch = checkpoint['epoch']\n",
    "            dct = checkpoint['state_dict']\n",
    "            \n",
    "            model.module.model.load_state_dict({k.replace('model.', ''): v for k, v in dct.items() if k.startswith('model.')})\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            logger.info(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    end_epoch = config.TRAIN.END_EPOCH\n",
    "    num_iters = config.TRAIN.END_EPOCH * epoch_iters\n",
    "    real_end = 120+1 if 'camvid' in config.DATASET.TRAIN_SET else end_epoch\n",
    "    \n",
    "\n",
    "    train_loss_history = []\n",
    "    eval_loss_history = []\n",
    "    mean_iou_history = []\n",
    "    hist_seg, hist_adv, hist_D_src, hist_D_trg = [], [], [], []\n",
    "\n",
    "    for epoch in range(last_epoch, real_end):\n",
    "\n",
    "        current_trainloader = trainloader\n",
    "        if current_trainloader.sampler is not None and hasattr(current_trainloader.sampler, 'set_epoch'):\n",
    "            current_trainloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        if config.TRAIN.GAN.ENABLE:\n",
    "            \n",
    "            discriminator1 = FCDiscriminator(num_classes=8).to(device)\n",
    "            optimizer_G = optimizer\n",
    "            optimizer_D1 = optim.Adam(discriminator1.parameters(), lr=0.0005, betas=(0.9, 0.99)) #given by the paper\n",
    "\n",
    "            train_loss, avg_seg, avg_adv, avg_D_src, avg_D_trg =train_adv(config, epoch, config.TRAIN.END_EPOCH, epoch_iters, config.TRAIN.LR, num_iters, trainloader, targetloader, optimizer_G, optimizer_D1, model, discriminator1, writer_dict)\n",
    "            hist_seg.append(avg_seg)\n",
    "            hist_adv.append(avg_adv)\n",
    "            hist_D_src.append(avg_D_src)\n",
    "            hist_D_trg.append(avg_D_trg)\n",
    "            print(\"Loss Summary:  Loss_Seg (G): {:.6f}, Loss_Adv (G): {:.6f}, Loss_D_Src: {:.6f}, Loss_D_Trg: {:.6f}\".format(avg_seg, avg_adv, avg_D_src, avg_D_trg))\n",
    "\n",
    "        else:\n",
    "            train_loss=train(config, epoch, config.TRAIN.END_EPOCH, \n",
    "                  epoch_iters, config.TRAIN.LR, num_iters,\n",
    "                  trainloader, optimizer, model, writer_dict, targetloader=targetloader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        if flag_rm == 1 or (epoch % 5 == 0 and epoch < real_end - 100) or (epoch >= real_end - 100):\n",
    "            valid_loss, mean_IoU, IoU_array = validate(config, testloader, model, writer_dict)\n",
    "            eval_loss_history.append(valid_loss)\n",
    "            mean_iou_history.append(mean_IoU)\n",
    "\n",
    "        if flag_rm == 1:\n",
    "            flag_rm = 0\n",
    "\n",
    "        #if epoch % 5 == 0 or epoch == real_end - 1:\n",
    "        plot_metrics(train_loss_history, eval_loss_history, mean_iou_history)\n",
    "        if config.TRAIN.GAN.ENABLE:\n",
    "            plot_gan_metrics(hist_seg, hist_adv, hist_D_src, hist_D_trg)\n",
    "        plot_class_iou(iou_array=IoU_array, mean_iou=mean_IoU, epoch=epoch)\n",
    "        \n",
    "\n",
    "\n",
    "        logger.info('=> saving checkpoint to {}'.format(\n",
    "            final_output_dir + 'checkpoint.pth.tar'))\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'best_mIoU': best_mIoU,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
    "        if mean_IoU > best_mIoU:\n",
    "            best_mIoU = mean_IoU\n",
    "            torch.save(model.module.state_dict(),\n",
    "                    os.path.join(final_output_dir, 'best.pt'))\n",
    "        msg = 'Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f}'.format(\n",
    "                    valid_loss, mean_IoU, best_mIoU)\n",
    "        logging.info(msg)\n",
    "        logging.info(IoU_array)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(model.module.state_dict(),\n",
    "            os.path.join(final_output_dir, 'final_state.pt'))\n",
    "\n",
    "    writer_dict['writer'].close()\n",
    "    end = timeit.default_timer()\n",
    "    logger.info('Hours: %d' % int((end-start)/3600))\n",
    "    logger.info('Done')\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:06:08.837552Z",
     "iopub.status.busy": "2025-05-24T13:06:08.836765Z",
     "iopub.status.idle": "2025-05-24T13:06:15.012882Z",
     "shell.execute_reply": "2025-05-24T13:06:15.012132Z",
     "shell.execute_reply.started": "2025-05-24T13:06:08.837519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/output.zip'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zippa la cartella dei log\n",
    "shutil.make_archive('/kaggle/working/log', 'zip', '/kaggle/working/log')\n",
    "shutil.make_archive('/kaggle/working/output', 'zip', '/kaggle/working/output')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7153698,
     "sourceId": 11422827,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7154101,
     "sourceId": 11423306,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7160745,
     "sourceId": 11432913,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7444675,
     "sourceId": 11848379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
