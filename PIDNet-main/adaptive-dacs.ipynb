{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def1fcf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:28.494123Z",
     "iopub.status.busy": "2025-05-20T21:48:28.493874Z",
     "iopub.status.idle": "2025-05-20T21:48:28.520323Z",
     "shell.execute_reply": "2025-05-20T21:48:28.519667Z"
    },
    "papermill": {
     "duration": 0.037315,
     "end_time": "2025-05-20T21:48:28.521485",
     "exception": false,
     "start_time": "2025-05-20T21:48:28.484170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.config/kaggle/kaggle.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "os.makedirs('/root/.config/kaggle', exist_ok=True)\n",
    "shutil.copy('/kaggle/input/kaggle-api/kaggle.json', '/root/.config/kaggle/kaggle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2eab86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:28.537595Z",
     "iopub.status.busy": "2025-05-20T21:48:28.537387Z",
     "iopub.status.idle": "2025-05-20T21:48:28.542844Z",
     "shell.execute_reply": "2025-05-20T21:48:28.542094Z"
    },
    "papermill": {
     "duration": 0.014684,
     "end_time": "2025-05-20T21:48:28.543917",
     "exception": false,
     "start_time": "2025-05-20T21:48:28.529233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "working_dir = '/kaggle/working/'\n",
    "\n",
    "if os.path.exists(working_dir):\n",
    "    for filename in os.listdir(working_dir):\n",
    "        file_path = os.path.join(working_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove file or symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directory and contents\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    print('Done ✅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8ae9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:28.558732Z",
     "iopub.status.busy": "2025-05-20T21:48:28.558513Z",
     "iopub.status.idle": "2025-05-20T21:48:33.652192Z",
     "shell.execute_reply": "2025-05-20T21:48:33.651262Z"
    },
    "papermill": {
     "duration": 5.102821,
     "end_time": "2025-05-20T21:48:33.653815",
     "exception": false,
     "start_time": "2025-05-20T21:48:28.550994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q albumentations==1.4.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52785955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:33.670265Z",
     "iopub.status.busy": "2025-05-20T21:48:33.669720Z",
     "iopub.status.idle": "2025-05-20T21:48:40.172516Z",
     "shell.execute_reply": "2025-05-20T21:48:40.171797Z"
    },
    "id": "Pqh-LuR5inRH",
    "outputId": "c05502f6-b016-43bd-b554-1e4ea2614543",
    "papermill": {
     "duration": 6.512427,
     "end_time": "2025-05-20T21:48:40.174010",
     "exception": false,
     "start_time": "2025-05-20T21:48:33.661583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yacs\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs) (6.0.2)\r\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.8\r\n",
      "Collecting tensorboardX\r\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (25.0)\r\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX) (2024.2.0)\r\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tensorboardX\r\n",
      "Successfully installed tensorboardX-2.6.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install yacs\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcdcc4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:40.191003Z",
     "iopub.status.busy": "2025-05-20T21:48:40.190738Z",
     "iopub.status.idle": "2025-05-20T21:48:40.196827Z",
     "shell.execute_reply": "2025-05-20T21:48:40.196193Z"
    },
    "id": "9qCYBoYv1WQZ",
    "outputId": "bc9151bb-d1fa-4c35-f86d-7f2aaa284b17",
    "papermill": {
     "duration": 0.015662,
     "end_time": "2025-05-20T21:48:40.197872",
     "exception": false,
     "start_time": "2025-05-20T21:48:40.182210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /kaggle/working/data/loveda/train/\n",
      "Created: /kaggle/working/data/loveda/val/\n",
      "Created: /kaggle/working/data/list/loveda/rural\n",
      "Created: /kaggle/working/data/list/loveda/urban_rural\n",
      "Created: /kaggle/working/data/list/loveda/urban_urban\n",
      "Created: /kaggle/working/pretrained_models/imagenet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_kaggle_path = \"/kaggle/working/\"\n",
    "folder_names = [\n",
    "    'data/loveda/train/',\n",
    "    'data/loveda/val/',\n",
    "    'data/list/loveda/rural',\n",
    "    'data/list/loveda/urban_rural',\n",
    "    'data/list/loveda/urban_urban',\n",
    "    'pretrained_models/imagenet'\n",
    "]\n",
    "\n",
    "for relative_path in folder_names:\n",
    "    full_path = os.path.join(base_kaggle_path, relative_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)\n",
    "        print(f\"Created: {full_path}\")\n",
    "    else:\n",
    "        print(f\"Already exists: {full_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9552fd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:48:40.213819Z",
     "iopub.status.busy": "2025-05-20T21:48:40.213582Z",
     "iopub.status.idle": "2025-05-20T21:51:20.452798Z",
     "shell.execute_reply": "2025-05-20T21:51:20.451178Z"
    },
    "papermill": {
     "duration": 160.248941,
     "end_time": "2025-05-20T21:51:20.454330",
     "exception": false,
     "start_time": "2025-05-20T21:48:40.205389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: /kaggle/input/loveda-splits/train/train/Rural → /kaggle/working/data/loveda/train/Rural\n",
      "Copied: /kaggle/input/loveda-splits/train/train/Urban → /kaggle/working/data/loveda/train/Urban\n",
      "Copied: /kaggle/input/loveda-splits/val/val/Rural → /kaggle/working/data/loveda/val/Rural\n",
      "Copied: /kaggle/input/loveda-splits/val/val/Urban → /kaggle/working/data/loveda/val/Urban\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "list_src = [\n",
    "    '/kaggle/input/loveda-splits/train/train/Rural',\n",
    "    '/kaggle/input/loveda-splits/train/train/Urban',\n",
    "    '/kaggle/input/loveda-splits/val/val/Rural',\n",
    "    '/kaggle/input/loveda-splits/val/val/Urban'\n",
    "]\n",
    "\n",
    "list_dst = [\n",
    "    '/kaggle/working/data/loveda/train/Rural',\n",
    "    '/kaggle/working/data/loveda/train/Urban',\n",
    "    '/kaggle/working/data/loveda/val/Rural',\n",
    "    '/kaggle/working/data/loveda/val/Urban'\n",
    "]\n",
    "\n",
    "for src, dst in zip(list_src, list_dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copytree(src, dst)\n",
    "        print(f\"Copied: {src} → {dst}\")\n",
    "    else:\n",
    "        print(f\"Skipped (already exists): {dst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a78de1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:20.509224Z",
     "iopub.status.busy": "2025-05-20T21:51:20.508875Z",
     "iopub.status.idle": "2025-05-20T21:51:20.603000Z",
     "shell.execute_reply": "2025-05-20T21:51:20.602206Z"
    },
    "id": "x-_xpQCZcbRg",
    "outputId": "d91de478-c474-4944-ca0e-0b3a8de56f7b",
    "papermill": {
     "duration": 0.138162,
     "end_time": "2025-05-20T21:51:20.604584",
     "exception": false,
     "start_time": "2025-05-20T21:51:20.466422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/kaggle/input/configs/configs'\n",
    "dst = '/kaggle/working/configs/'\n",
    "\n",
    "if not os.path.exists(dst):\n",
    "    shutil.copytree(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b80d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:20.667173Z",
     "iopub.status.busy": "2025-05-20T21:51:20.666607Z",
     "iopub.status.idle": "2025-05-20T21:51:21.220959Z",
     "shell.execute_reply": "2025-05-20T21:51:21.220306Z"
    },
    "id": "PDsG8UU9gU8e",
    "outputId": "5874c528-5f6c-4525-db46-52b965768d00",
    "papermill": {
     "duration": 0.56479,
     "end_time": "2025-05-20T21:51:21.222032",
     "exception": false,
     "start_time": "2025-05-20T21:51:20.657242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy('/kaggle/input/pidnet-pretrained/PIDNet_S_ImageNet.pth.tar', '/kaggle/working/pretrained_models/imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696d0b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:21.240174Z",
     "iopub.status.busy": "2025-05-20T21:51:21.239979Z",
     "iopub.status.idle": "2025-05-20T21:51:21.244329Z",
     "shell.execute_reply": "2025-05-20T21:51:21.243742Z"
    },
    "papermill": {
     "duration": 0.013819,
     "end_time": "2025-05-20T21:51:21.245315",
     "exception": false,
     "start_time": "2025-05-20T21:51:21.231496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786b3f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:21.262221Z",
     "iopub.status.busy": "2025-05-20T21:51:21.262022Z",
     "iopub.status.idle": "2025-05-20T21:51:21.292379Z",
     "shell.execute_reply": "2025-05-20T21:51:21.291740Z"
    },
    "id": "WDp6olwIbTw9",
    "papermill": {
     "duration": 0.040334,
     "end_time": "2025-05-20T21:51:21.293642",
     "exception": false,
     "start_time": "2025-05-20T21:51:21.253308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_lst_file(image_dir, label_dir, output_lst):\n",
    "    # List and sort files numerically\n",
    "    images = sorted(os.listdir(image_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    labels = sorted(os.listdir(label_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_lst), exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    with open(output_lst, 'w') as f:\n",
    "        for img, lbl in zip(images, labels):\n",
    "            # Generate full paths and normalize to use forward slashes\n",
    "            img_path = os.path.join(image_dir, img).replace(\"\\\\\", \"/\")\n",
    "            lbl_path = os.path.join(label_dir, lbl).replace(\"\\\\\", \"/\")\n",
    "            # Write formatted line with consistent spacing\n",
    "            f.write(f\"{img_path} {lbl_path}\\n\")\n",
    "\n",
    "# Paths to the LoveDA dataset directories\n",
    "urban_train_image_dir = \"data/loveda/train/Urban/images_png\"\n",
    "urban_train_label_dir = \"data/loveda/train/Urban/masks_png\"\n",
    "\n",
    "urban_test_image_dir = \"data/loveda/val/Urban/images_png\"\n",
    "urban_test_label_dir = \"data/loveda/val/Urban/masks_png\"\n",
    "\n",
    "rural_train_image_dir = \"data/loveda/train/Rural/images_png\"\n",
    "rural_train_label_dir = \"data/loveda/train/Rural/masks_png\"\n",
    "\n",
    "rural_test_image_dir = \"data/loveda/val/Rural/images_png\"\n",
    "rural_test_label_dir = \"data/loveda/val/Rural/masks_png\"\n",
    "\n",
    "\n",
    "\n",
    "# train on urban - test on urban\n",
    "train_lst_path = \"data/list/loveda/urban_urban/train.lst\"\n",
    "test_lst_path = \"data/list/loveda/urban_urban/val.lst\"\n",
    "\n",
    "# Create .lst files\n",
    "create_lst_file(urban_train_image_dir, urban_train_label_dir, train_lst_path)\n",
    "create_lst_file(urban_test_image_dir, urban_test_label_dir, test_lst_path)\n",
    "\n",
    "train_lst_path = \"data/list/loveda/urban_rural/train.lst\"\n",
    "target_lst_path = \"data/list/loveda/rural/train.lst\"\n",
    "test_lst_path = \"data/list/loveda/urban_rural/val.lst\"\n",
    "\n",
    "# Create .lst files\n",
    "create_lst_file(urban_train_image_dir, urban_train_label_dir, train_lst_path)\n",
    "create_lst_file(rural_train_image_dir, rural_train_label_dir, target_lst_path)\n",
    "create_lst_file(rural_test_image_dir, rural_test_label_dir, test_lst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98a5be",
   "metadata": {
    "papermill": {
     "duration": 0.007581,
     "end_time": "2025-05-20T21:51:21.309098",
     "exception": false,
     "start_time": "2025-05-20T21:51:21.301517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DeepLab implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc41737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:21.325613Z",
     "iopub.status.busy": "2025-05-20T21:51:21.325420Z",
     "iopub.status.idle": "2025-05-20T21:51:31.465318Z",
     "shell.execute_reply": "2025-05-20T21:51:31.464669Z"
    },
    "papermill": {
     "duration": 10.14989,
     "end_time": "2025-05-20T21:51:31.466729",
     "exception": false,
     "start_time": "2025-05-20T21:51:21.316839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101\n",
    "affine_par = True\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        padding = dilation\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=padding, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n",
    "        for i in self.bn2.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n",
    "        for i in self.bn3.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ClassifierModule(nn.Module):\n",
    "    \"\"\" \n",
    "    This module implements the Atrous Spatial Pyramid Pooling (ASPP).\n",
    "    Parameters:\n",
    "        - inplanes: Number of input channels.\n",
    "        - dilation_series: List of dilation rates for the convolutions.\n",
    "        - padding_series: List of padding values corresponding to the dilation rates.\n",
    "        - num_classes: Number of output classes for semantic segmentation.\n",
    "    \"\"\" \n",
    "    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.conv2d_list = nn.ModuleList()\n",
    "        for dilation, padding in zip(dilation_series, padding_series):\n",
    "            self.conv2d_list.append(\n",
    "                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n",
    "                          dilation=dilation, bias=True))\n",
    "\n",
    "        for m in self.conv2d_list:\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_list[0](x)\n",
    "        for i in range(len(self.conv2d_list) - 1):\n",
    "            out += self.conv2d_list[i + 1](x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetMulti(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the main DeepLabv2 model. It uses a ResNet backbone (with dilation) for feature extraction, \n",
    "    followed by a classification module (ASPP).\n",
    "\n",
    "    Layers: \n",
    "        - Convolutional Stem:\n",
    "            - conv1: Initial 7x7 convolution with stride 2, reducing spatial resolution.\n",
    "            - bn1: Batch normalization for the first layer.\n",
    "            - relu: ReLU activation.\n",
    "            - maxpool: Reduces resolution further with a 3x3 max-pooling layer.\n",
    "        - ResNet Layers:\n",
    "            - layer1 to layer4: Residual layers (ResNet blocks) with bottleneck structures.\n",
    "            - layer3 and layer4 use dilated convolutions for larger receptive fields, instead of downsampling.\n",
    "            - dilation=2 for layer3 and dilation=4 for layer4.\n",
    "        - ASPP:\n",
    "            - Implemented as layer6 (using ClassifierModule).\n",
    "            - Applies parallel atrous convolutions with dilation rates [6, 12, 18, 24] to the high-level feature map from layer4.\n",
    "\n",
    "    Forward Pass: the forward pass processes an input tensor through the following steps:\n",
    "        - Extract low-level features using conv1, bn1, relu, and maxpool.\n",
    "        - Pass through ResNet blocks (layer1 to layer4) to extract high-level features.\n",
    "        - Use ASPP (layer6) to capture multi-scale context.\n",
    "        - Upsample the final predictions back to the input resolution using bilinear interpolation.\n",
    "    Output\n",
    "        - During training: Returns segmentation predictions.\n",
    "        - During inference: Returns predictions resized to match the input size\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, num_classes, multi_level=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Layers: \n",
    "            - Convolutional Stem:\n",
    "                - conv1: Initial 7x7 convolution with stride 2, reducing spatial resolution.\n",
    "                - bn1: Batch normalization for the first layer.\n",
    "                - relu: ReLU activation.\n",
    "                - maxpool: Reduces resolution further with a 3x3 max-pooling layer.\n",
    "            - ResNet Layers:\n",
    "                - layer1 to layer4: Residual layers (ResNet blocks) with bottleneck structures.\n",
    "                - layer3 and layer4 use dilated convolutions for larger receptive fields, instead of downsampling.\n",
    "                - dilation=2 for layer3 and dilation=4 for layer4.\n",
    "            - ASPP:\n",
    "                - Implemented as layer6 (using ClassifierModule).\n",
    "                - Applies parallel atrous convolutions with dilation rates [6, 12, 18, 24] to the high-level feature map from layer4.\n",
    "        \"\"\"\n",
    "        self.multi_level = multi_level\n",
    "        self.inplanes = 64\n",
    "        super(ResNetMulti, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "\n",
    "        \"\"\" \n",
    "        This method is responsible for creating a ResNet block.\n",
    "        Arguments:\n",
    "            - block:\n",
    "                - The class of the residual block to use (e.g., Bottleneck).\n",
    "                - A residual block consists of multiple convolutional layers with a skip connection.\n",
    "            - planes:\n",
    "                - The number of output channels for the block. The block will typically expand this to planes * expansion.\n",
    "                - For example, in Bottleneck class we have expansion = 4. Hence the number of output channels is planes * 4. \n",
    "            - blocks:\n",
    "                - The number of residual layers (or blocks) to include in this layer group.\n",
    "                - For example, in ResNet-101, layer3 has 23 blocks.\n",
    "            - stride:\n",
    "                - Controls the downsampling factor for the first block in the layer. A stride > 1 reduces the spatial resolution.\n",
    "            - dilation:\n",
    "                - Specifies the dilation rate for convolutions in the block.\n",
    "                - Used in layer3 and layer4 to replace downsampling with atrous convolution, maintaining spatial resolution while expanding the receptive field. \n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        if (stride != 1\n",
    "                or self.inplanes != planes * block.expansion\n",
    "                or dilation == 2\n",
    "                or dilation == 4):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n",
    "        for i in downsample._modules['1'].parameters():\n",
    "            i.requires_grad = False\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, H, W = x.size()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer6(x)\n",
    "\n",
    "        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n",
    "\n",
    "        if self.training == True:\n",
    "            return x\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_1x_lr_params_no_scale(self):\n",
    "        \"\"\"\n",
    "        This generator returns all the parameters of the net except for\n",
    "        the last classification layer. Note that for each batchnorm layer,\n",
    "        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
    "        any batchnorm parameter\n",
    "        \"\"\"\n",
    "        b = []\n",
    "\n",
    "        b.append(self.conv1)\n",
    "        b.append(self.bn1)\n",
    "        b.append(self.layer1)\n",
    "        b.append(self.layer2)\n",
    "        b.append(self.layer3)\n",
    "        b.append(self.layer4)\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            for j in b[i].modules():\n",
    "                jj = 0\n",
    "                for k in j.parameters():\n",
    "                    jj += 1\n",
    "                    if k.requires_grad:\n",
    "                        yield k\n",
    "\n",
    "    def get_10x_lr_params(self):\n",
    "        \"\"\"\n",
    "        This generator returns all the parameters for the last layer of the net,\n",
    "        which does the classification of pixel into classes\n",
    "        \"\"\"\n",
    "        b = []\n",
    "        if self.multi_level:\n",
    "            b.append(self.layer5.parameters())\n",
    "        b.append(self.layer6.parameters())\n",
    "\n",
    "        for j in range(len(b)):\n",
    "            for i in b[j]:\n",
    "                yield i\n",
    "\n",
    "    def optim_parameters(self, lr):\n",
    "        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n",
    "                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n",
    "\n",
    "\n",
    "def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n",
    "    \"\"\" model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n",
    "\n",
    "    # Pretraining loading\n",
    "    if pretrain:\n",
    "        resnet_model = resnet101(pretrained=True)\n",
    "        saved_state_dict = resnet_model.state_dict()\n",
    "\n",
    "        new_params = model.state_dict().copy()\n",
    "        for i in saved_state_dict:\n",
    "            i_parts = i.split('.')\n",
    "            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
    "        model.load_state_dict(new_params, strict=False)\n",
    "\n",
    "    return model \"\"\"\n",
    "\n",
    "    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n",
    "\n",
    "    # Pretraining loading from torchvision's ResNet-101\n",
    "    if pretrain:\n",
    "        print('Loading ResNet-101 pretrained weights...')\n",
    "        resnet_model = resnet101(pretrained=True)\n",
    "        saved_state_dict = resnet_model.state_dict()\n",
    "\n",
    "        # Load pretrained weights into DeepLab model\n",
    "        new_params = model.state_dict().copy()\n",
    "        for key in saved_state_dict:\n",
    "            # Remove 'layer' prefixes or other modifications if necessary\n",
    "            modified_key = key.split('.', 1)[-1] if key.startswith('layer') else key\n",
    "            if modified_key in new_params:\n",
    "                new_params[modified_key] = saved_state_dict[key]\n",
    "\n",
    "        model.load_state_dict(new_params, strict=False)\n",
    "        print('Pretrained weights loaded successfully.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d41a059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:31.484252Z",
     "iopub.status.busy": "2025-05-20T21:51:31.483960Z",
     "iopub.status.idle": "2025-05-20T21:51:34.177746Z",
     "shell.execute_reply": "2025-05-20T21:51:34.176927Z"
    },
    "papermill": {
     "duration": 2.703831,
     "end_time": "2025-05-20T21:51:34.178991",
     "exception": false,
     "start_time": "2025-05-20T21:51:31.475160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet-101 pretrained weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:00<00:00, 193MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "deeplab_model = get_deeplab_v2(num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e22db6",
   "metadata": {
    "id": "7LRO-dropYbt",
    "papermill": {
     "duration": 0.008807,
     "end_time": "2025-05-20T21:51:34.197105",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.188298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "_init_paths.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad132b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:34.215572Z",
     "iopub.status.busy": "2025-05-20T21:51:34.215287Z",
     "iopub.status.idle": "2025-05-20T21:51:34.219799Z",
     "shell.execute_reply": "2025-05-20T21:51:34.219082Z"
    },
    "id": "HZRc88q3pV0d",
    "papermill": {
     "duration": 0.015326,
     "end_time": "2025-05-20T21:51:34.221015",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.205689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft\n",
    "# Licensed under the MIT License.\n",
    "# Written by Ke Sun (sunk@mail.ustc.edu.cn)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf5072",
   "metadata": {
    "id": "sj2x9u3_lEmk",
    "papermill": {
     "duration": 0.008343,
     "end_time": "2025-05-20T21:51:34.237921",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.229578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "model_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529594c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:34.256334Z",
     "iopub.status.busy": "2025-05-20T21:51:34.256119Z",
     "iopub.status.idle": "2025-05-20T21:51:34.292454Z",
     "shell.execute_reply": "2025-05-20T21:51:34.291948Z"
    },
    "id": "RkXp_Vq6k_FR",
    "papermill": {
     "duration": 0.047025,
     "end_time": "2025-05-20T21:51:34.293537",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.246512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class segmenthead(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
    "        super(segmenthead, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
    "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(self.relu(self.bn1(x)))\n",
    "        out = self.conv2(self.relu(self.bn2(x)))\n",
    "\n",
    "        if self.scale_factor is not None:\n",
    "            height = x.shape[-2] * self.scale_factor\n",
    "            width = x.shape[-1] * self.scale_factor\n",
    "            out = F.interpolate(out,\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.process1 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process2 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process3 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process4 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        x_list = []\n",
    "\n",
    "        x_list.append(self.scale0(x))\n",
    "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
    "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
    "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
    "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
    "\n",
    "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "class PAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale_process = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        scale_list = []\n",
    "\n",
    "        x_ = self.scale0(x)\n",
    "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "\n",
    "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
    "\n",
    "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PagFM(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PagFM, self).__init__()\n",
    "        self.with_channel = with_channel\n",
    "        self.after_relu = after_relu\n",
    "        self.f_x = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        self.f_y = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        if with_channel:\n",
    "            self.up = nn.Sequential(\n",
    "                                    nn.Conv2d(mid_channels, in_channels,\n",
    "                                              kernel_size=1, bias=False),\n",
    "                                    BatchNorm(in_channels)\n",
    "                                   )\n",
    "        if after_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        input_size = x.size()\n",
    "        if self.after_relu:\n",
    "            y = self.relu(y)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        y_q = self.f_y(y)\n",
    "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x_k = self.f_x(x)\n",
    "\n",
    "        if self.with_channel:\n",
    "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
    "        else:\n",
    "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
    "\n",
    "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x = (1-sim_map)*x + sim_map*y\n",
    "\n",
    "        return x\n",
    "\n",
    "class Light_Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Light_Bag, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "\n",
    "class DDFMv2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DDFMv2, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "class Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Bag, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=3, padding=1, bias=False)\n",
    "                                )\n",
    "\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "        return self.conv(edge_att*p + (1-edge_att)*i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0cce2",
   "metadata": {
    "id": "nct1QBaLlIY-",
    "papermill": {
     "duration": 0.008228,
     "end_time": "2025-05-20T21:51:34.310380",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.302152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "pidnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e813c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:34.328324Z",
     "iopub.status.busy": "2025-05-20T21:51:34.328108Z",
     "iopub.status.idle": "2025-05-20T21:51:34.352153Z",
     "shell.execute_reply": "2025-05-20T21:51:34.351674Z"
    },
    "id": "3jboQ25HlLp2",
    "papermill": {
     "duration": 0.034367,
     "end_time": "2025-05-20T21:51:34.353138",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.318771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import logging\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class PIDNet(nn.Module):\n",
    "\n",
    "    def __init__(self, m=2, n=3, num_classes=19, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
    "        super(PIDNet, self).__init__()\n",
    "        self.augment = augment\n",
    "\n",
    "        # I Branch\n",
    "        self.conv1 =  nn.Sequential(\n",
    "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                      )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
    "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
    "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
    "\n",
    "        # P Branch\n",
    "        self.compression3 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "\n",
    "        self.compression4 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "        self.pag3 = PagFM(planes * 2, planes)\n",
    "        self.pag4 = PagFM(planes * 2, planes)\n",
    "\n",
    "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # D Branch\n",
    "        if m == 2:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
    "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
    "        else:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Bag(planes * 4, planes * 4)\n",
    "\n",
    "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # Prediction Head\n",
    "        if self.augment:\n",
    "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
    "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
    "\n",
    "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            if i == (blocks-1):\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
    "            else:\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        width_output = x.shape[-1] // 8\n",
    "        height_output = x.shape[-2] // 8\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(self.layer2(self.relu(x)))\n",
    "        x_ = self.layer3_(x)\n",
    "        x_d = self.layer3_d(x)\n",
    "\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x_ = self.pag3(x_, self.compression3(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff3(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_p = x_\n",
    "\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x_ = self.layer4_(self.relu(x_))\n",
    "        x_d = self.layer4_d(self.relu(x_d))\n",
    "\n",
    "        x_ = self.pag4(x_, self.compression4(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff4(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_d = x_d\n",
    "\n",
    "        x_ = self.layer5_(self.relu(x_))\n",
    "        x_d = self.layer5_d(self.relu(x_d))\n",
    "        x = F.interpolate(\n",
    "                        self.spp(self.layer5(x)),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
    "\n",
    "        if self.augment:\n",
    "            x_extra_p = self.seghead_p(temp_p)\n",
    "            x_extra_d = self.seghead_d(temp_d)\n",
    "            return [x_extra_p, x_, x_extra_d]\n",
    "        else:\n",
    "            return x_\n",
    "\n",
    "def get_seg_model(cfg, imgnet_pretrained):\n",
    "\n",
    "    if 's' in cfg.MODEL.NAME:\n",
    "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
    "    elif 'm' in cfg.MODEL.NAME:\n",
    "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=96, head_planes=128, augment=True)\n",
    "    else:\n",
    "        model = PIDNet(m=3, n=4, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=112, head_planes=256, augment=True)\n",
    "\n",
    "    if imgnet_pretrained:\n",
    "        pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
    "        model_dict.update(pretrained_state)\n",
    "        msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
    "        logging.info('Attention!!!')\n",
    "        logging.info(msg)\n",
    "        logging.info('Over!!!')\n",
    "        model.load_state_dict(model_dict, strict = False)\n",
    "    else:\n",
    "        pretrained_dict = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')\n",
    "        if 'state_dict' in pretrained_dict:\n",
    "            pretrained_dict = pretrained_dict['state_dict']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "        msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "        logging.info('Attention!!!')\n",
    "        logging.info(msg)\n",
    "        logging.info('Over!!!')\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict, strict = False)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_pred_model(name, num_classes):\n",
    "\n",
    "    if 's' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
    "    elif 'm' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
    "    else:\n",
    "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4a155",
   "metadata": {
    "id": "TL86sUi4ngtL",
    "papermill": {
     "duration": 0.008222,
     "end_time": "2025-05-20T21:51:34.370035",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.361813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "base_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57124860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:34.388049Z",
     "iopub.status.busy": "2025-05-20T21:51:34.387844Z",
     "iopub.status.idle": "2025-05-20T21:51:36.163546Z",
     "shell.execute_reply": "2025-05-20T21:51:36.162545Z"
    },
    "id": "yxhY6uIngb5e",
    "papermill": {
     "duration": 1.786123,
     "end_time": "2025-05-20T21:51:36.164811",
     "exception": false,
     "start_time": "2025-05-20T21:51:34.378688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.7 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "y_k_size = 6\n",
    "x_k_size = 6\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 ignore_label=255,\n",
    "                 base_size=2048,\n",
    "                 crop_size=(512, 512),\n",
    "                 scale_factor=16,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]):\n",
    "\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.ignore_label = ignore_label\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        self.files = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def input_transform(self, image, city=False):\n",
    "        if city:\n",
    "            image = image.astype(np.float32)[:, :, ::-1]\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        image = image / 255.0\n",
    "        image -= self.mean\n",
    "        image /= self.std\n",
    "        return image\n",
    "\n",
    "    def label_transform(self, label):\n",
    "        return np.array(label).astype(np.uint8)\n",
    "\n",
    "    def pad_image(self, image, h, w, size, padvalue):\n",
    "        pad_h = max(size[0] - h, 0)\n",
    "        pad_w = max(size[1] - w, 0)\n",
    "\n",
    "        # Se non è necessario il padding, restituisci l'immagine originale\n",
    "        if pad_h == 0 and pad_w == 0:\n",
    "            return image\n",
    "\n",
    "        # Verifica il formato dell'immagine (deve essere H, W, C)\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        # Aggiungi il padding\n",
    "        pad_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=padvalue)\n",
    "\n",
    "        # Ripristina il formato originale (C, H, W) se necessario\n",
    "        if len(image.shape) == 3 and image.shape[2] <= 3:  # Se era in formato (C, H, W)\n",
    "            pad_image = np.transpose(pad_image, (2, 0, 1))  # Converti di nuovo in (C, H, W)\n",
    "\n",
    "        return pad_image\n",
    "\n",
    "    def rand_crop(self, image, label, edge):\n",
    "        # Verifica il formato dell'immagine\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Aggiungi padding se necessario\n",
    "        if h < self.crop_size[0] or w < self.crop_size[1]:\n",
    "            image = self.pad_image(image, h, w, self.crop_size, (0.0, 0.0, 0.0))\n",
    "            label = self.pad_image(label, h, w, self.crop_size, (self.ignore_label,))\n",
    "            edge = self.pad_image(edge, h, w, self.crop_size, (0.0,))\n",
    "\n",
    "        # Aggiorna le dimensioni dopo il padding\n",
    "        new_h, new_w = label.shape\n",
    "        if new_h < self.crop_size[0] or new_w < self.crop_size[1]:\n",
    "            raise ValueError(f\"Dimensioni insufficienti per il ritaglio: label={label.shape}, crop_size={self.crop_size}\")\n",
    "\n",
    "        # Calcola le coordinate per il ritaglio casuale\n",
    "        x = random.randint(0, new_w - self.crop_size[1])\n",
    "        y = random.randint(0, new_h - self.crop_size[0])\n",
    "\n",
    "        # Esegui il ritaglio\n",
    "        image = image[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        label = label[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        edge = edge[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "\n",
    "        #in questo modo l'iimagine è 512x512x3\n",
    "        #se volessi croppare quella regione\n",
    "        '''\n",
    "        # Estrai la regione da sfocare\n",
    "        cropped_region = image[y:y+crop_size[0], x:x+crop_size[1]]\n",
    "\n",
    "        # Applica il Gaussian Blur alla regione\n",
    "        blurred_region = cv2.GaussianBlur(cropped_region, (15, 15), 0)\n",
    "\n",
    "        # Sostituisci la regione originale con quella sfocata\n",
    "        augmented_image = image.copy()\n",
    "        augmented_image[y:y+crop_size[0], x:x+crop_size[1]] = blurred_region\n",
    "        '''\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "    def multi_scale_aug(self, image, label=None, edge=None,\n",
    "                        rand_scale=1, rand_crop=True):\n",
    "        long_size = int(self.base_size * rand_scale + 0.5)\n",
    "        h, w = image.shape[:2]\n",
    "        if h > w:\n",
    "            new_h = long_size\n",
    "            new_w = int(w * long_size / h + 0.5)\n",
    "        else:\n",
    "            new_w = long_size\n",
    "            new_h = int(h * long_size / w + 0.5)\n",
    "\n",
    "        image = cv2.resize(image, (new_w, new_h),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (new_w, new_h),\n",
    "                               interpolation=cv2.INTER_NEAREST)\n",
    "            if edge is not None:\n",
    "                edge = cv2.resize(edge, (new_w, new_h),\n",
    "                                   interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        if rand_crop:\n",
    "            image, label, edge = self.rand_crop(image, label, edge)\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def gen_sample(self, image, label, edge_pad=True, edge_size=4, city=False, transform=None, show=False):\n",
    "\n",
    "\n",
    "        if transform is not None:\n",
    "            # Pass both image and mask\n",
    "            augmented = transform(image=image, mask=label)\n",
    "\n",
    "            if show:\n",
    "                show_images(image, augmented[\"image\"])\n",
    "\n",
    "            # Extract results\n",
    "            image = augmented['image']\n",
    "            label = augmented['mask']\n",
    "\n",
    "\n",
    "\n",
    "        #It' important keeping the edge generation after the data augmentation\n",
    "        edge = cv2.Canny(label, 0.1, 0.2)\n",
    "        kernel = np.ones((edge_size, edge_size), np.uint8)\n",
    "        if edge_pad:\n",
    "            edge = edge[y_k_size:-y_k_size, x_k_size:-x_k_size]\n",
    "            edge = np.pad(edge, ((y_k_size,y_k_size),(x_k_size,x_k_size)), mode='constant')\n",
    "        edge = (cv2.dilate(edge, kernel, iterations=1)>50)*1.0\n",
    "\n",
    "\n",
    "        #trasformazioni di input\n",
    "        image = self.input_transform(image, city=city) #Se city=True, converte l'immagine da RGB in BGR per opencv\n",
    "        label = self.label_transform(label) #converte la label in un array di interi\n",
    "        image = image.transpose((2, 0, 1)) #H,W,C -> C,H,W\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def inference(self, config, model, image):\n",
    "        size = image.size()\n",
    "        pred = model(image)\n",
    "\n",
    "        if config.MODEL.NUM_OUTPUTS > 1:\n",
    "            pred = pred[config.TEST.OUTPUT_INDEX]\n",
    "\n",
    "\n",
    "        pred = F.interpolate(\n",
    "            input=pred, size=size[-2:],\n",
    "            mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "        )\n",
    "\n",
    "\n",
    "        return pred.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6f93d2",
   "metadata": {
    "id": "QwgVWGZaqIdl",
    "papermill": {
     "duration": 0.008408,
     "end_time": "2025-05-20T21:51:36.182254",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.173846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "discriminator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27c2331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.200051Z",
     "iopub.status.busy": "2025-05-20T21:51:36.199704Z",
     "iopub.status.idle": "2025-05-20T21:51:36.205815Z",
     "shell.execute_reply": "2025-05-20T21:51:36.205265Z"
    },
    "id": "GI5TiVbdqLuY",
    "papermill": {
     "duration": 0.016225,
     "end_time": "2025-05-20T21:51:36.206841",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.190616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "    #Discriminator based on DCGAN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FCDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, ndf = 64):\n",
    "        super(FCDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
    "        self.classifier = nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        #self.up_sample = nn.Upsample(scale_factor=32, mode='bilinear')\n",
    "        #self.sigmoid = nn.Sigmoid() #non uso sigmoid per la stabilità numerica a discapito di avere i logits e non le probabilità\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.classifier(x)\n",
    "        #x = self.up_sample(x)\n",
    "        #x = self.sigmoid(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271e995",
   "metadata": {
    "id": "YOPrWJGJndSn",
    "papermill": {
     "duration": 0.008284,
     "end_time": "2025-05-20T21:51:36.223717",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.215433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "loveda.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135b2209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.241726Z",
     "iopub.status.busy": "2025-05-20T21:51:36.241454Z",
     "iopub.status.idle": "2025-05-20T21:51:36.266553Z",
     "shell.execute_reply": "2025-05-20T21:51:36.266020Z"
    },
    "id": "FMHg7dVtgmKS",
    "papermill": {
     "duration": 0.035483,
     "end_time": "2025-05-20T21:51:36.267571",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.232088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_images(image, blurred_image):\n",
    "    # Compute the absolute difference between the images\n",
    "    # Ensure both images are in the same format (H, W, C)\n",
    "    blurred_image = blurred_image.transpose(1, 2, 0)  # Change (C, H, W) to (H, W, C)\n",
    "\n",
    "    # Compute the absolute difference between the images\n",
    "    diff = np.abs(image - blurred_image)\n",
    "\n",
    "    # Plot the images and their difference side by side\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    axs[0].imshow(image)  # Original image\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(blurred_image)  # Blurred image\n",
    "    axs[1].set_title(\"Blurred Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    axs[2].imshow(diff)  # Difference image\n",
    "    axs[2].set_title(\"Difference Image\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#classe per fare la data augmentation\n",
    "class DataAugmentation:\n",
    "    def __init__(self, config, dataset_instance):\n",
    "        self.enable = config[\"ENABLE\"]\n",
    "        self.probability = config[\"PROBABILITY\"]\n",
    "        self.techniques = config[\"TECHNIQUES\"]\n",
    "        self.dataset = dataset_instance  # Riferimento all'istanza del dataset\n",
    "\n",
    "    def apply(self, image, label, edge):\n",
    "\n",
    "        if not self.enable or random.random() > self.probability: #50% di probabilità di applicare la data augmentation\n",
    "            return image,label,edge #non faccio augmentation\n",
    "\n",
    "        if self.techniques.get(\"HORIZONTAL_FLIP\", False):\n",
    "            image,label,edge = self.horizontal_flip(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"GAUSSIAN_BLUR\", False):\n",
    "            image, label, edge = self.gaussian_blur(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"MULTIPLY\", False):\n",
    "            image, label, edge = self.multiply(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"RANDOM_BRIGHTNESS\", False):\n",
    "            image, label, edge = self.random_brightness(image, label, edge)\n",
    "\n",
    "        if self.techniques.get(\"RANDOM_CROP\", False):\n",
    "            image, label, edge = self.random_crop(image, label, edge)\n",
    "\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "    def random_crop(self, image, label, edge):\n",
    "        return self.dataset.rand_crop(image, label, edge)  # Usa l'istanza del dataset\n",
    "\n",
    "\n",
    "\n",
    "    def horizontal_flip(self, image, label, edge):\n",
    "        # Inverti orizzontalmente immagine, label ed edge\n",
    "        flipped_image = image[:, :, ::-1]\n",
    "        flipped_label = label[:, ::-1]\n",
    "        flipped_edge = edge[:, ::-1]\n",
    "        return flipped_image, flipped_label, flipped_edge\n",
    "\n",
    "\n",
    "\n",
    "    def gaussian_blur(self, image, label, edge, kernel_size=5, show = False):\n",
    "        # Applica il Gaussian Blur solo all'immagine\n",
    "        transposed_image = image.transpose(1, 2, 0)  # From (C, H, W) to (H, W, C)\n",
    "\n",
    "        # Apply Gaussian blur\n",
    "        blurred_image = cv2.GaussianBlur(transposed_image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "        # If you want to return it to the PyTorch format (C, H, W)\n",
    "        blurred_image = blurred_image.transpose(2, 0, 1)  # From (H, W, C) to (C, H, W)\n",
    "\n",
    "        if show:\n",
    "            show_images(image, blurred_image)\n",
    "\n",
    "        return blurred_image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "    def multiply(self, image, label, edge, factor_range=(0.8, 1.2), show = False):\n",
    "        # Convert image to float32 to avoid overflow issues\n",
    "        factor = random.uniform(*factor_range)\n",
    "        image = image.astype(np.float32)  # Ensure safe multiplication\n",
    "\n",
    "        # Check if image is normalized (0-1), rescale before multiplication\n",
    "        if image.max() <= 1.0:\n",
    "            image *= 255.0  # Scale to 0-255 range before multiplication\n",
    "\n",
    "        multiplied_image = image * factor\n",
    "\n",
    "        if show:\n",
    "            show_images(image, multiplied_image)\n",
    "\n",
    "        return multiplied_image, label, edge\n",
    "\n",
    "    def random_brightness(self, image, label, edge, brightness_range=(-0.5, 0.5), show = False):\n",
    "        # Modify image brightness\n",
    "        brightness = np.float32(np.random.uniform(*brightness_range))\n",
    "        brightened_image = image + brightness  # Keep within [0,1]\n",
    "\n",
    "        if show:\n",
    "            show_images(image, brightened_image)\n",
    "        return brightened_image, label, edge\n",
    "\n",
    "\n",
    "\n",
    "class LoveDA(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 list_path,\n",
    "                 num_classes=7,\n",
    "                 multi_scale=False,\n",
    "                 flip=False,\n",
    "                 ignore_label=0,\n",
    "                 base_size=1024,\n",
    "                 crop_size=(512, 512),\n",
    "                 scale_factor=16, #multi scale usato come data augmentation alredy provided\n",
    "                 enable_augmentation=False,\n",
    "                 augmentation_probability=0.5,\n",
    "                 horizontal_flip=False,\n",
    "                 gaussian_blur=False,\n",
    "                 multiply=False,\n",
    "                 random_brightness=False,\n",
    "                 random_crop=True,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225],\n",
    "                 bd_dilate_size=4,\n",
    "                 pseudo_label=False,\n",
    "                 weighted=True,\n",
    "                 transform=None):\n",
    "\n",
    "        # estende il base_dataset\n",
    "        super(LoveDA, self).__init__(ignore_label, base_size,\n",
    "                                     crop_size, scale_factor, mean, std)\n",
    "\n",
    "        self.root = root\n",
    "        self.list_path = list_path\n",
    "        self.num_classes = num_classes\n",
    "        self.multi_scale = multi_scale\n",
    "        self.flip = flip\n",
    "        self.ignore_label = ignore_label\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.enable_augmentation = enable_augmentation\n",
    "        self.augmentation_probability = augmentation_probability\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.gaussian_blur = gaussian_blur\n",
    "        self.multiply = multiply\n",
    "        self.random_brightness = random_brightness\n",
    "        self.random_crop = random_crop\n",
    "        self.bd_dilate_size = bd_dilate_size\n",
    "\n",
    "        self.img_list = [line.strip().split() for line in open(root + list_path)]\n",
    "        self.files = self.read_files()\n",
    "        self.color_list = [[0, 0, 0], [1, 1, 1], [2, 2, 2],\n",
    "                            [3, 3, 3], [4, 4, 4], [5, 5, 5], [6, 6, 6], [7, 7, 7]]\n",
    "        self.class_weights = None\n",
    "        if weighted:\n",
    "            self.class_weights = torch.tensor([0.000000, 0.116411, 0.266041, 0.607794, 1.511413, 0.745507, 0.712438, 3.040396])\n",
    "        \n",
    "        self.pseudo_label = pseudo_label\n",
    "        self.transform=transform\n",
    "\n",
    "    def read_files(self):\n",
    "        files = []\n",
    "\n",
    "        for item in self.img_list:\n",
    "            image_path, label_path = item\n",
    "            name = os.path.splitext(os.path.basename(label_path))[0]\n",
    "            files.append({\n",
    "                \"img\": image_path,\n",
    "                \"label\": label_path,\n",
    "                \"name\": name\n",
    "            })\n",
    "\n",
    "        return files\n",
    "\n",
    "    # da immagine a label\n",
    "    def color2label(self, color_map):\n",
    "        label = np.ones(color_map.shape[:2]) * self.ignore_label\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            label[(color_map == v).sum(2) == 3] = i\n",
    "\n",
    "        return label.astype(np.uint8)\n",
    "\n",
    "    def convert_label(self, label, inverse=False):\n",
    "        temp = label.copy()\n",
    "        if inverse:\n",
    "            for v, k in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        else:\n",
    "            for k, v in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        return label\n",
    "\n",
    "    # da label a immagine\n",
    "    def label2color(self, label):\n",
    "        color_map = np.zeros(label.shape + (3,))\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            color_map[label == i] = self.color_list[i]\n",
    "\n",
    "        return color_map.astype(np.uint8)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.files[index]\n",
    "        name = item[\"name\"]\n",
    "        image = cv2.imread(item[\"img\"], cv2.IMREAD_COLOR)\n",
    "\n",
    "        size = image.shape\n",
    "\n",
    "        label = cv2.imread(item[\"label\"], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "        #edge (H,W)\n",
    "        image, label, edge = self.gen_sample(image, label, edge_pad=False,\n",
    "                                             edge_size=self.bd_dilate_size, city=False, transform=self.transform, show=False) #image diventa (C,H,W)\n",
    "\n",
    "        return image.copy(), label.copy(), edge.copy(), np.array(size), name\n",
    "\n",
    "    def single_scale_inference(self, config, model, image):\n",
    "        pred = self.inference(config, model, image)\n",
    "        return pred\n",
    "\n",
    "    def save_pred(self, preds, sv_path, name):\n",
    "        preds = np.asarray(np.argmax(preds.cpu(), axis=1), dtype=np.uint8)\n",
    "        for i in range(preds.shape[0]):\n",
    "            pred = self.label2color(preds[i])\n",
    "            save_img = Image.fromarray(pred)\n",
    "            save_img.save(os.path.join(sv_path, name[i] + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be4247",
   "metadata": {
    "id": "YWtVHwfinr5g",
    "papermill": {
     "duration": 0.008368,
     "end_time": "2025-05-20T21:51:36.284802",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.276434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "criterion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2932e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.303091Z",
     "iopub.status.busy": "2025-05-20T21:51:36.302864Z",
     "iopub.status.idle": "2025-05-20T21:51:36.318632Z",
     "shell.execute_reply": "2025-05-20T21:51:36.318124Z"
    },
    "id": "h1yOyy_NhYqb",
    "papermill": {
     "duration": 0.02639,
     "end_time": "2025-05-20T21:51:36.319703",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.293313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from configs import config\n",
    "\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if config.MODEL.NUM_OUTPUTS == 1:\n",
    "            score = [score]\n",
    "\n",
    "        balance_weights = config.LOSS.BALANCE_WEIGHTS\n",
    "        sb_weights = config.LOSS.SB_WEIGHTS\n",
    "        if len(balance_weights) == len(score):\n",
    "            return sum([w * self._forward(x, target) for (w, x) in zip(balance_weights, score)])\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class OhemCrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, thres=0.7,\n",
    "                 min_kept=100000, weight=None):\n",
    "        super(OhemCrossEntropy, self).__init__()\n",
    "        self.thresh = thres\n",
    "        self.min_kept = max(1, min_kept)\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label,\n",
    "            reduction='none'\n",
    "        )\n",
    "\n",
    "    def _ce_forward(self, score, target):\n",
    "\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _ohem_forward(self, score, target, **kwargs):\n",
    "\n",
    "        pred = F.softmax(score, dim=1)\n",
    "        pixel_losses = self.criterion(score, target).contiguous().view(-1)\n",
    "        mask = target.contiguous().view(-1) != self.ignore_label\n",
    "\n",
    "        tmp_target = target.clone()\n",
    "        tmp_target[tmp_target == self.ignore_label] = 0\n",
    "        pred = pred.gather(1, tmp_target.unsqueeze(1))\n",
    "        pred, ind = pred.contiguous().view(-1,)[mask].contiguous().sort()\n",
    "        min_value = pred[min(self.min_kept, pred.numel() - 1)]\n",
    "        threshold = max(min_value, self.thresh)\n",
    "\n",
    "        pixel_losses = pixel_losses[mask][ind]\n",
    "        pixel_losses = pixel_losses[pred < threshold]\n",
    "        return pixel_losses.mean()\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if not (isinstance(score, list) or isinstance(score, tuple)):\n",
    "            score = [score]\n",
    "\n",
    "        balance_weights = config.LOSS.BALANCE_WEIGHTS\n",
    "        sb_weights = config.LOSS.SB_WEIGHTS\n",
    "        if len(balance_weights) == len(score):\n",
    "            functions = [self._ce_forward] * \\\n",
    "                (len(balance_weights) - 1) + [self._ohem_forward]\n",
    "            return sum([\n",
    "                w * func(x, target)\n",
    "                for (w, x, func) in zip(balance_weights, score, functions)\n",
    "            ])\n",
    "\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._ohem_forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "def weighted_bce(bd_pre, target):\n",
    "    n, c, h, w = bd_pre.size()\n",
    "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
    "    target_t = target.view(1, -1)\n",
    "\n",
    "    pos_index = (target_t == 1)\n",
    "    neg_index = (target_t == 0)\n",
    "\n",
    "    weight = torch.zeros_like(log_p)\n",
    "    pos_num = pos_index.sum()\n",
    "    neg_num = neg_index.sum()\n",
    "    sum_num = pos_num + neg_num\n",
    "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
    "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class BondaryLoss(nn.Module):\n",
    "    def __init__(self, coeff_bce = 20.0):\n",
    "        super(BondaryLoss, self).__init__()\n",
    "        self.coeff_bce = coeff_bce\n",
    "\n",
    "    def forward(self, bd_pre, bd_gt):\n",
    "\n",
    "        bce_loss = self.coeff_bce * weighted_bce(bd_pre, bd_gt)\n",
    "        loss = bce_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406c260",
   "metadata": {
    "id": "WGSIbNfzoHXo",
    "papermill": {
     "duration": 0.008525,
     "end_time": "2025-05-20T21:51:36.337002",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.328477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9198f7b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.355294Z",
     "iopub.status.busy": "2025-05-20T21:51:36.355058Z",
     "iopub.status.idle": "2025-05-20T21:51:36.373967Z",
     "shell.execute_reply": "2025-05-20T21:51:36.373398Z"
    },
    "id": "n8P5mZLNh-Ho",
    "papermill": {
     "duration": 0.029498,
     "end_time": "2025-05-20T21:51:36.374970",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.345472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from configs import default\n",
    "config = default._C.clone()\n",
    "update_config = default.update_config\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "\n",
    "  def __init__(self, model, sem_loss, bd_loss):\n",
    "    super(FullModel, self).__init__()\n",
    "    self.model = model\n",
    "    self.sem_loss = sem_loss\n",
    "    self.bd_loss = bd_loss\n",
    "\n",
    "  def pixel_acc(self, pred, label):\n",
    "    _, preds = torch.max(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc\n",
    "\n",
    "  def forward(self, inputs, labels, bd_gt, *args, **kwargs):\n",
    "\n",
    "    outputs = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "    h, w = labels.size(1), labels.size(2)\n",
    "    ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
    "    if ph != h or pw != w:\n",
    "        for i in range(len(outputs)):\n",
    "            outputs[i] = F.interpolate(outputs[i], size=(\n",
    "                h, w), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "\n",
    "    acc  = self.pixel_acc(outputs[-2], labels)\n",
    "    loss_s = self.sem_loss(outputs[:-1], labels)\n",
    "    loss_b = self.bd_loss(outputs[-1], bd_gt)\n",
    "\n",
    "    filler = torch.ones_like(labels) * config.TRAIN.IGNORE_LABEL\n",
    "    try:\n",
    "        bd_label = torch.where(torch.sigmoid(outputs[-1][:, 0, :, :]) > 0.8, labels, filler) # 0.7\n",
    "        loss_sb = self.sem_loss([outputs[-2]], bd_label)\n",
    "    except:\n",
    "        print(\"Error in loss computation\")\n",
    "        loss_sb = self.sem_loss([outputs[-2]], labels)\n",
    "    loss = loss_s + loss_b + loss_sb\n",
    "\n",
    "    return torch.unsqueeze(loss,0), outputs[:-1], acc, [loss_s, loss_b] #aoutputs[:-1] è una lista di tensori\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg\n",
    "\n",
    "def create_logger(cfg, cfg_name, phase='train'):\n",
    "    root_output_dir = Path(cfg.OUTPUT_DIR)\n",
    "\n",
    "    if (\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE and\n",
    "        not cfg.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER\n",
    "        ):\n",
    "        folder_name = \"no_aug\"\n",
    "    else:\n",
    "        folder_name = \"aug\"\n",
    "\n",
    "    if cfg.TRAIN.DACS.ENABLE:\n",
    "        folder_name = \"dacs\"\n",
    "\n",
    "    if cfg.TRAIN.GAN.ENABLE:\n",
    "        folder_name = \"gan\"\n",
    "\n",
    "    if cfg.TRAIN.AUGMENTATION.ENABLE:\n",
    "        folder_name+= \"_hf\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP else \"\"\n",
    "        folder_name+= \"_gb\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR else \"\"\n",
    "        folder_name+= \"_rc\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP else \"\"\n",
    "        folder_name+= \"_cj\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER else \"\"\n",
    "        folder_name+= \"_gn\" if cfg.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE else \"\"\n",
    "\n",
    "    # set up logger\n",
    "    if not root_output_dir.exists():\n",
    "        print('=> creating {}'.format(root_output_dir))\n",
    "        root_output_dir.mkdir()\n",
    "\n",
    "    dataset = cfg.DATASET.DATASET\n",
    "    model = cfg.MODEL.NAME\n",
    "    cfg_name = os.path.basename(cfg_name).split('.')[0]\n",
    "\n",
    "    final_output_dir = root_output_dir / dataset / cfg_name / folder_name\n",
    "\n",
    "    print('=> creating {}'.format(final_output_dir))\n",
    "    final_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    time_str = time.strftime('%Y-%m-%d-%H-%M')\n",
    "    log_file = '{}_{}_{}.log'.format(cfg_name, time_str, phase)\n",
    "    final_log_file = final_output_dir / log_file\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=str(final_log_file),\n",
    "                        format=head)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    console = logging.StreamHandler()\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    tensorboard_log_dir = Path(cfg.LOG_DIR) / dataset / model / \\\n",
    "            (cfg_name + '_' + time_str)\n",
    "    print('=> creating {}'.format(tensorboard_log_dir))\n",
    "    tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return logger, str(final_output_dir), str(tensorboard_log_dir)\n",
    "\n",
    "def get_confusion_matrix(label, pred, size, num_class, ignore=-1):\n",
    "    \"\"\"\n",
    "    Calcute the confusion matrix by given label and pred\n",
    "    \"\"\"\n",
    "    output = pred.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    seg_pred = np.asarray(np.argmax(output, axis=3), dtype=np.uint8)\n",
    "    seg_gt = np.asarray(\n",
    "    label.cpu().numpy()[:, :size[-2], :size[-1]], dtype=int)\n",
    "\n",
    "    ignore_index = seg_gt != ignore\n",
    "    seg_gt = seg_gt[ignore_index]\n",
    "    seg_pred = seg_pred[ignore_index]\n",
    "\n",
    "    index = (seg_gt * num_class + seg_pred).astype('int32')\n",
    "    label_count = np.bincount(index)\n",
    "    confusion_matrix = np.zeros((num_class, num_class))\n",
    "\n",
    "    for i_label in range(num_class):\n",
    "        for i_pred in range(num_class):\n",
    "            cur_index = i_label * num_class + i_pred\n",
    "            if cur_index < len(label_count):\n",
    "                confusion_matrix[i_label,\n",
    "                                 i_pred] = label_count[cur_index]\n",
    "    return confusion_matrix\n",
    "\n",
    "def adjust_learning_rate(optimizer, base_lr, max_iters,\n",
    "        cur_iters, power=0.9, nbb_mult=10):\n",
    "    lr = base_lr*((1-float(cur_iters)/max_iters)**(power))\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    if len(optimizer.param_groups) == 2:\n",
    "        optimizer.param_groups[1]['lr'] = lr * nbb_mult\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703190d5",
   "metadata": {
    "id": "GOsR_t09oO3W",
    "papermill": {
     "duration": 0.008595,
     "end_time": "2025-05-20T21:51:36.439984",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.431389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "classmix.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a03d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.458605Z",
     "iopub.status.busy": "2025-05-20T21:51:36.458354Z",
     "iopub.status.idle": "2025-05-20T21:51:36.483063Z",
     "shell.execute_reply": "2025-05-20T21:51:36.482498Z"
    },
    "id": "ZTvJD1AJiIdu",
    "papermill": {
     "duration": 0.035595,
     "end_time": "2025-05-20T21:51:36.484113",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.448518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def show_mixed_visualization(x_s, y_s, x_t, y_t, x_mixed, y_mixed, bd_mixed, ignore_label=0):\n",
    "    \"\"\"\n",
    "    Displays source, target, mixed images and labels alongside the edge map, \n",
    "    with a legend whose colors exactly match the label images.\n",
    "    \n",
    "    Args:\n",
    "        x_s, x_t, x_mixed: Tensors [1,C,H,W] pre-normalized.\n",
    "        y_s, y_t, y_mixed: Tensors [1,H,W] integer labels.\n",
    "        bd_mixed: Tensor [1,H,W] edge/boundary map.\n",
    "        ignore_label: integer value to ignore in edge_map_vis.\n",
    "        class_names: dict mapping label int -> class name.\n",
    "    \"\"\"\n",
    "    class_names = {\n",
    "        0: \"no-data\",\n",
    "        1: \"background\",\n",
    "        2: \"building\",\n",
    "        3: \"road\",\n",
    "        4: \"water\",\n",
    "        5: \"barren\",\n",
    "        6: \"forest\",\n",
    "        7: \"agriculture\",\n",
    "    }\n",
    "    # Unpack first batch element and move to CPU / numpy\n",
    "    x_s = x_s[0].cpu().clone()\n",
    "    x_t = x_t[0].cpu().clone()\n",
    "    x_mixed = x_mixed[0].cpu().clone()\n",
    "    y_s = y_s[0].cpu().numpy()\n",
    "    y_t = y_t[0].cpu().numpy()\n",
    "    y_mixed = y_mixed[0].cpu().numpy()\n",
    "    edge_map = bd_mixed[0].cpu().numpy()\n",
    "\n",
    "    # Prepare edge‐map visualization\n",
    "    edge_vis = (edge_map != ignore_label).astype(np.uint8) * edge_map\n",
    "    edge_vis = (edge_vis > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Un-normalize images (assumes ImageNet mean/std)\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std  = [0.229, 0.224, 0.225]\n",
    "    for t, m, s in zip(x_s, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "    for t, m, s in zip(x_t, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "    for t, m, s in zip(x_mixed, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "\n",
    "    # H×W×C for imshow\n",
    "    x_s = np.transpose(x_s.numpy(),     (1, 2, 0))\n",
    "    x_t = np.transpose(x_t.numpy(),     (1, 2, 0))\n",
    "    x_mixed = np.transpose(x_mixed.numpy(), (1, 2, 0))\n",
    "\n",
    "    # Create a discrete ListedColormap with exactly len(class_names) colors\n",
    "    num_classes = len(class_names)\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", num_classes)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "    # Row 1: images + edge map\n",
    "    axs[0, 0].imshow(x_s);      axs[0, 0].set_title(\"Source Image\");  axs[0, 0].axis(\"off\")\n",
    "    axs[0, 1].imshow(x_t);      axs[0, 1].set_title(\"Target Image\");  axs[0, 1].axis(\"off\")\n",
    "    axs[0, 2].imshow(x_mixed);  axs[0, 2].set_title(\"Mixed Image\");   axs[0, 2].axis(\"off\")\n",
    "    axs[0, 3].imshow(edge_vis, cmap='gray', vmin=0, vmax=255)\n",
    "    axs[0, 3].set_title(\"Edge Map\"); axs[0, 3].axis(\"off\")\n",
    "\n",
    "    # Row 2: labels using the same cmap with explicit vmin/vmax\n",
    "    axs[1, 0].imshow(y_s,      cmap=cmap, vmin=0, vmax=num_classes-1)\n",
    "    axs[1, 0].set_title(\"Source Label\");  axs[1, 0].axis(\"off\")\n",
    "    axs[1, 1].imshow(y_t,      cmap=cmap, vmin=0, vmax=num_classes-1)\n",
    "    axs[1, 1].set_title(\"Pseudo Label\");  axs[1, 1].axis(\"off\")\n",
    "    axs[1, 2].imshow(y_mixed,  cmap=cmap, vmin=0, vmax=num_classes-1)\n",
    "    axs[1, 2].set_title(\"Mixed Label\");   axs[1, 2].axis(\"off\")\n",
    "\n",
    "    # Legend: one patch per class, using the exact same cmap\n",
    "    handles = [\n",
    "        mpatches.Patch(color=cmap(i), label=class_names[i])\n",
    "        for i in sorted(class_names)\n",
    "    ]\n",
    "    axs[1, 3].legend(handles=handles, loc=\"center\", ncol=2, frameon=False, fontsize=\"small\")\n",
    "    axs[1, 3].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    '''def show_mixed_visualization(x_s, y_s, x_t, y_t, x_mixed, y_mixed, bd_mixed):\n",
    "    # Move tensors to CPU and convert to NumPy\n",
    "    x_s = x_s[0].cpu().clone()\n",
    "    x_t = x_t[0].cpu().clone()\n",
    "    x_mixed = x_mixed[0].cpu().clone()\n",
    "\n",
    "    y_s = y_s[0].cpu().numpy()\n",
    "    y_t = y_t[0].cpu().numpy()\n",
    "    y_mixed = y_mixed[0].cpu().numpy()\n",
    "    edge_map = bd_mixed[0].cpu().numpy()\n",
    "    edge_map_vis = (edge_map != config.TRAIN.IGNORE_LABEL).astype(np.uint8) * edge_map\n",
    "    edge_map_vis = (edge_map_vis > 0).astype(np.uint8) * 255  # Make edges white on black\n",
    "    # If normalized, unnormalize (adjust if you used custom values)\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std = [0.229, 0.224, 0.225]\n",
    "    for t, m, s in zip(x_s, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "    for t, m, s in zip(x_t, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "    for t, m, s in zip(x_mixed, imagenet_mean, imagenet_std):\n",
    "        t.mul_(s).add_(m)\n",
    "\n",
    "    x_s = np.transpose(x_s.numpy(), (1, 2, 0))\n",
    "    x_t = np.transpose(x_t.numpy(), (1, 2, 0))\n",
    "    x_mixed = np.transpose(x_mixed.numpy(), (1, 2, 0))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "    axs[0, 0].imshow(x_s)\n",
    "    axs[0, 0].set_title(\"Source Image\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    axs[0, 1].imshow(x_t)\n",
    "    axs[0, 1].set_title(\"Target Image\")\n",
    "    axs[0, 1].axis(\"off\")\n",
    "\n",
    "    axs[0, 2].imshow(x_mixed)\n",
    "    axs[0, 2].set_title(\"Mixed Image\")\n",
    "    axs[0, 2].axis(\"off\")\n",
    "\n",
    "\n",
    "    axs[0, 3].imshow(edge_map_vis, cmap='gray', vmin=0, vmax=255)\n",
    "    axs[0, 3].set_title(\"Edge Map\")\n",
    "    axs[0, 3].axis(\"off\")\n",
    "\n",
    "    axs[1, 0].imshow(y_s, cmap='tab20')\n",
    "    axs[1, 0].set_title(\"Source Label\")\n",
    "    axs[1, 0].axis(\"off\")\n",
    "\n",
    "    axs[1, 1].imshow(y_t, cmap='tab20')\n",
    "    axs[1, 1].set_title(\"Pseudo Label\")\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    axs[1, 2].imshow(y_mixed, cmap='tab20')\n",
    "    axs[1, 2].set_title(\"Mixed Label\")\n",
    "    axs[1, 2].axis(\"off\")\n",
    "\n",
    "    axs[1, 3].axis(\"off\")  # Can be used for something else if needed\n",
    "\n",
    "\n",
    "    # --- BEGIN LEGEND PATCH ---\n",
    "    import matplotlib.patches as mpatches\n",
    "    class_names = {\n",
    "        0: \"no-data\",\n",
    "        1: \"background\",\n",
    "        2: \"building\",\n",
    "        3: \"road\",\n",
    "        4: \"water\",\n",
    "        5: \"barren\",\n",
    "        6: \"forest\",\n",
    "        7: \"agriculture\",\n",
    "    }\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", len(class_names))\n",
    "    handles = [\n",
    "        mpatches.Patch(color=cmap(i), label=class_names[i])\n",
    "        for i in sorted(class_names)\n",
    "    ]\n",
    "    axs[1, 3].legend(\n",
    "        handles=handles,\n",
    "        loc=\"center\",\n",
    "        ncol=2,\n",
    "        frameon=False,\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "    axs[1, 3].axis(\"off\")\n",
    "    # --- END LEGEND PATCH ---\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()'''\n",
    "\n",
    "\n",
    "\n",
    "def compute_mixing_fraction(mean_iou_history, min_frac=0.3, max_frac=0.8, default_frac=0.5, stagnation_thresh=0.015, window_dim=5):\n",
    "    \"\"\"\n",
    "    Adjust the number of classes to mix based on how the model is performing.\n",
    "    If it's performing well, increase the number of classes to mix, othewise decrease it.\n",
    "    There is a maximum and minimum number of classes to mix, defined by the min_frac and max_frac parameters.\n",
    "    \"\"\"\n",
    "    if len(mean_iou_history) < window_dim:\n",
    "        return default_frac\n",
    "\n",
    "    prev = mean_iou_history[-window_dim]\n",
    "    recent_avg = np.mean(mean_iou_history[-(window_dim-1):])\n",
    "    delta = (recent_avg - prev) / (prev + 1e-6)\n",
    "\n",
    "    # Linear scaling of delta\n",
    "    frac = default_frac + delta  # allows both increase and decrease\n",
    "    frac = max(min(frac, max_frac), min_frac)  # clamp within bounds\n",
    "\n",
    "    # Check if last window_dim values are within ±1%\n",
    "    recent_slice = mean_iou_history[-window_dim:]\n",
    "    stagnated = max(recent_slice) - min(recent_slice) < stagnation_thresh\n",
    "\n",
    "    if stagnated:\n",
    "        frac = max(frac - 0.05, min_frac)\n",
    "    else:\n",
    "        frac = default_frac + delta\n",
    "        frac = max(min(frac, max_frac), min_frac)\n",
    "\n",
    "    return frac\n",
    "\n",
    "\n",
    "\n",
    "def classmix(x1, y1, x2, y2, mean_iou_history, iou_array, verbose=False, deterministic=False, N_WARMUP = 5):\n",
    "    flat_y1 = y1.view(-1)\n",
    "    max_class = max(flat_y1.max().item(), len(iou_array) - 1)\n",
    "    class_counts = torch.bincount(flat_y1, minlength=max_class + 1).float()\n",
    "    valid_mask = class_counts > 0\n",
    "    valid_mask[0] = False  # Exclude background\n",
    "    classes = torch.nonzero(valid_mask).squeeze(1).tolist()\n",
    "\n",
    "    iou_tensor = torch.tensor(iou_array, dtype=torch.float32, device=class_counts.device)\n",
    "    iou_tensor = 1.0 - iou_tensor.clamp(0, 1)\n",
    "    perf_weights = iou_tensor[valid_mask]\n",
    "\n",
    "    current_epoch = len(mean_iou_history)\n",
    "\n",
    "    if current_epoch < N_WARMUP:\n",
    "        selected = random.sample(classes, k=len(classes)//2)\n",
    "    \n",
    "        mask = torch.zeros_like(y1, dtype=torch.bool)\n",
    "        if verbose:\n",
    "            print(f\"Classes from the source domain: {selected}\") \n",
    "        for c in selected:\n",
    "            mask |= (y1 == c)\n",
    "    \n",
    "        mask_3ch = mask.unsqueeze(1).repeat(1, x1.size(1), 1, 1)\n",
    "        x_mix = torch.where(mask_3ch, x1, x2)\n",
    "        y_mix = torch.where(mask, y1, y2)\n",
    "        return x_mix, y_mix, mask, len(selected), selected\n",
    "\n",
    "    if perf_weights.sum() > 0:\n",
    "        combined_weights = perf_weights / perf_weights.sum()\n",
    "    else:\n",
    "        combined_weights = torch.ones_like(perf_weights) / len(perf_weights)\n",
    "\n",
    "    n_classes_total = len(classes)\n",
    "    frac = compute_mixing_fraction(mean_iou_history)\n",
    "    n_select = max(1, int(frac * n_classes_total))\n",
    "\n",
    "    if deterministic:\n",
    "        _, top_indices = torch.topk(combined_weights, k=n_select)\n",
    "    else:\n",
    "        top_indices = torch.multinomial(combined_weights, n_select, replacement=False)\n",
    "\n",
    "    selected = [classes[i] for i in top_indices.tolist()]\n",
    "\n",
    "    selected_tensor = torch.tensor(selected, device=y1.device).view(-1, 1, 1)\n",
    "    batch_size = y1.shape[0]\n",
    "    mask = torch.zeros_like(y1, dtype=torch.bool)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        y1_b = y1[b]\n",
    "        selected_tensor = torch.tensor(selected, device=y1.device).view(-1, 1, 1)\n",
    "        mask[b] = (y1_b.unsqueeze(0) == selected_tensor).any(0)\n",
    "    \n",
    "    mask_3ch = mask.unsqueeze(1).repeat(1, x1.size(1), 1, 1)\n",
    "    x_mix = torch.where(mask_3ch, x1, x2)\n",
    "    y_mix = torch.where(mask, y1, y2)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Selected classes for mixing (n={n_select}): {selected}\")\n",
    "\n",
    "    return x_mix, y_mix, mask, n_select, selected\n",
    "\n",
    "\n",
    "def generate_confident_edge_map(y_mixed, source_mask, confidence_mask, edge_size=4, edge_pad=False, ignore_label=255):\n",
    "    \"\"\"\n",
    "    Build boundary map from y_mixed but only at:\n",
    "     - all source pixels (source_mask==1)\n",
    "     - target pixels with confidence_mask==True\n",
    "    Everything else is set to ignore_label.\n",
    "    \"\"\"\n",
    "    B, H, W = y_mixed.shape\n",
    "    edge_maps = []\n",
    "    kernel = np.ones((edge_size, edge_size), np.uint8)\n",
    "    pad = edge_size  # or whatever padding you want\n",
    "\n",
    "    for i in range(B):\n",
    "        lbl = y_mixed[i].cpu().numpy().astype(np.uint8)\n",
    "        src = source_mask[i].cpu().numpy().astype(bool)\n",
    "        conf = confidence_mask[i].cpu().numpy().astype(bool)\n",
    "\n",
    "        # only keep labels where we trust them\n",
    "        keep = src | conf\n",
    "        lbl_masked = np.where(keep, lbl, 0).astype(np.uint8)\n",
    "\n",
    "        # detect edges\n",
    "        edge = cv2.Canny(lbl_masked, 0.1, 0.2)\n",
    "        if edge_pad:\n",
    "            edge = edge[pad:-pad, pad:-pad]\n",
    "            edge = np.pad(edge, ((pad, pad), (pad, pad)), mode='constant')\n",
    "\n",
    "        # dilate + threshold\n",
    "        edge = (cv2.dilate(edge, kernel, iterations=1) > 50).astype(np.uint8)\n",
    "\n",
    "        # ignore everything outside our keep region\n",
    "        edge[~keep] = ignore_label\n",
    "\n",
    "        edge_maps.append(torch.from_numpy(edge).long().unsqueeze(0))\n",
    "\n",
    "    return torch.cat(edge_maps, dim=0).to(y_mixed.device)\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train segmentation network')\n",
    "    parser.add_argument('--cfg', default=\"configs/loveda/pidnet_small_loveda.yaml\", type=str)\n",
    "    parser.add_argument('--seed', type=int, default=304)\n",
    "    parser.add_argument('opts', default=None, nargs=argparse.REMAINDER)\n",
    "    args = parser.parse_args()\n",
    "    update_config(config, args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b097ec",
   "metadata": {
    "id": "5a9CgnuKo-6G",
    "papermill": {
     "duration": 0.009496,
     "end_time": "2025-05-20T21:51:36.502700",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.493204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73232631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.521753Z",
     "iopub.status.busy": "2025-05-20T21:51:36.521482Z",
     "iopub.status.idle": "2025-05-20T21:51:36.715667Z",
     "shell.execute_reply": "2025-05-20T21:51:36.715082Z"
    },
    "id": "wzdMHgT9htZC",
    "papermill": {
     "duration": 0.205256,
     "end_time": "2025-05-20T21:51:36.717038",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.511782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the transform once (outside the training loop ideally)\n",
    "color_jitter = A.Compose([\n",
    "    A.ColorJitter(\n",
    "        p=0.5\n",
    "    ),\n",
    "])\n",
    "\n",
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "def apply_color_jitter_tensor(img_tensor):\n",
    "    # Move mean and std to same device as img_tensor\n",
    "    mean = IMAGENET_MEAN.to(img_tensor.device)\n",
    "    std = IMAGENET_STD.to(img_tensor.device)\n",
    "\n",
    "    # Denormalize\n",
    "    img_tensor = img_tensor.clone()\n",
    "    img_tensor = img_tensor * std + mean\n",
    "\n",
    "    img_np = img_tensor.cpu().numpy()  # (C, H, W)\n",
    "    img_np = np.transpose(img_np, (1, 2, 0))  # (H, W, C)\n",
    "    img_np = np.clip(img_np * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    augmented = color_jitter(image=img_np)\n",
    "    img_aug = augmented['image'].astype(np.float32) / 255.0\n",
    "    img_aug = np.transpose(img_aug, (2, 0, 1))  # back to (C, H, W)\n",
    "\n",
    "    # Re-normalize (on CPU, then move back to GPU)\n",
    "    img_aug = torch.tensor(img_aug, dtype=torch.float)\n",
    "    img_aug = (img_aug - IMAGENET_MEAN) / IMAGENET_STD  # these are still on CPU\n",
    "    return img_aug.to(img_tensor.device)\n",
    "\n",
    "def update_ema_variables(ema_model, model, alpha_teacher, iteration):\n",
    "    # Use the \"true\" average until the exponential average is more correct\n",
    "    alpha_teacher = min(1 - 1 / (iteration + 1), alpha_teacher)\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        #ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "        ema_param.data[:] = alpha_teacher * ema_param[:].data[:] + (1 - alpha_teacher) * param[:].data[:]\n",
    "    return ema_model\n",
    "\n",
    "\n",
    "def train(config, epoch, num_epoch, epoch_iters, base_lr,\n",
    "          num_iters, trainloader, optimizer, model, writer_dict, mean_iou_history, iou_array, deeplab_model = None, ema_model=None, targetloader=None):\n",
    "    # Training\n",
    "    \n",
    "    model.train()\n",
    "    show_dacs = False\n",
    "    batch_time = AverageMeter()\n",
    "    ave_loss = AverageMeter()\n",
    "    ave_acc  = AverageMeter()\n",
    "    avg_sem_loss = AverageMeter()\n",
    "    avg_bce_loss = AverageMeter()\n",
    "    tic = time.time()\n",
    "    cur_iters = epoch*epoch_iters\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['train_global_steps']\n",
    "    \n",
    "    if targetloader is not None:\n",
    "        target_iter = iter(targetloader)\n",
    "    lambda_weight = 0\n",
    "    for i_iter, batch in enumerate(trainloader, 0):\n",
    "        if config.TRAIN.DACS.ENABLE and epoch > -1:\n",
    "            # DACS\n",
    "\n",
    "            # === SOURCE BATCH ==\n",
    "            x_s, y_s, bd_s, _, _ = batch\n",
    "            \n",
    "            x_s, y_s, bd_s = x_s.cuda(), y_s.long().cuda(), bd_s.float().cuda()\n",
    "\n",
    "            # === TARGET BATCH ===\n",
    "            try:\n",
    "                x_t, y_t, _, _, _ = next(target_iter)\n",
    "            except StopIteration:\n",
    "                target_iter = iter(targetloader)\n",
    "                x_t, y_t, _, _, _ = next(target_iter)\n",
    "            x_t = x_t.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if deeplab_model is not None:\n",
    "                    x_t_resized = torch.nn.functional.interpolate(x_t, size=(224, 224), mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS)\n",
    "                    logits_t = deeplab_model(x_t_resized)\n",
    "                    \n",
    "                elif ema_model is not None:\n",
    "                    logits_t = ema_model.module.model(x_t)[-2]\n",
    "    \n",
    "                else:\n",
    "                    logits_t = model.module.model(x_t)[-2]\n",
    "                    \n",
    "                logits_t = torch.nn.functional.interpolate(\n",
    "                    logits_t, size=x_t.shape[2:], mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "                \n",
    "                pseudo_t = torch.argmax(logits_t, dim=1)\n",
    "                if deeplab_model is not None:\n",
    "                    pseudo_t += 1\n",
    "                conf_t = torch.softmax(logits_t, dim=1).max(dim=1)[0]\n",
    "\n",
    "\n",
    "            # === CONFIDENCE USAGE ==\n",
    "\n",
    "            # Confidence_mask tells the position of the pixel whose pseudo-labels have\n",
    "            # a confidence higher than  the threshold\n",
    "            confidence_mask = conf_t > config.TRAIN.DACS.THRESHOLD \n",
    "\n",
    "\n",
    "            \n",
    "            # Where confidence mask is True put the pixel from pseudo_t, otherwise insert the ignore label (0)\n",
    "            pseudo_t_filtered = torch.where(\n",
    "               confidence_mask,\n",
    "               pseudo_t,\n",
    "               torch.tensor(config.TRAIN.IGNORE_LABEL, device=pseudo_t.device)\n",
    "            )\n",
    "            \n",
    "            # Apply classmix\n",
    "            x_mixed, y_mixed, source_mask, num_selected_classes, selected_classes = classmix(x_s, y_s, x_t, pseudo_t_filtered, mean_iou_history, iou_array)\n",
    "\n",
    "            \n",
    "            # Generate edges from the mixed image\n",
    "            bd_mixed = generate_confident_edge_map(\n",
    "                y_mixed,                       # mixed labels with ignore where conf low\n",
    "                source_mask,                   # source==1, target==0\n",
    "                confidence_mask,               # True where pseudo-label valid\n",
    "                edge_size=3, edge_pad=True,\n",
    "                ignore_label=config.TRAIN.IGNORE_LABEL\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "            # Source images augmentation\n",
    "            x_s.cpu()\n",
    "\n",
    "            # Apply color jitter to batch\n",
    "            x_s = torch.stack([\n",
    "                apply_color_jitter_tensor(img) for img in x_s\n",
    "            ])\n",
    "            \n",
    "            x_s.cuda()\n",
    "\n",
    "            # Mixed images augmentation\n",
    "            # Apply to batch\n",
    "            x_mixed = torch.stack([\n",
    "                apply_color_jitter_tensor(img) for img in x_mixed\n",
    "            ])\n",
    "            \n",
    "            if show_dacs:\n",
    "                show_mixed_visualization(x_s, y_s, x_t, pseudo_t_filtered, x_mixed, y_mixed, bd_mixed)\n",
    "            \n",
    "            x_mixed = x_mixed.cuda()\n",
    "            y_mixed = y_mixed.long().cuda()\n",
    "            bd_mixed = bd_mixed.float().cuda()\n",
    "\n",
    "\n",
    "            \n",
    "            # === FORWARD PASSES ===\n",
    "            losses_src, _, acc_src, loss_list_src = model(x_s, y_s, bd_s)\n",
    "            losses_mix, _, acc_mix, loss_list_mix = model(x_mixed, y_mixed, bd_mixed)\n",
    "            \n",
    "            loss_src = losses_src.mean()\n",
    "            loss_mix = losses_mix.mean()\n",
    "            \n",
    "            # === COMBINE LOSSES ===\n",
    "            # lambda_weight = confidence_mask.float().mean().item()\n",
    "            lambda_weight = (epoch+1) * 0.01\n",
    "            loss = loss_src + lambda_weight * loss_mix # .mean()\n",
    "            acc = (acc_src + acc_mix) / 2\n",
    "            \n",
    "            sem_loss = loss_list_src[0] + lambda_weight * loss_list_mix[0]\n",
    "            bce_loss = loss_list_src[1] + lambda_weight * loss_list_mix[1]\n",
    "        else:\n",
    "            images, labels, bd_gts, _, _ = batch\n",
    "            images = images.cuda()\n",
    "            labels = labels.long().cuda()\n",
    "            bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "\n",
    "            losses, _, acc, loss_list = model(images, labels, bd_gts)\n",
    "            loss = losses.mean()\n",
    "            acc  = acc.mean()\n",
    "            sem_loss = loss_list[0]\n",
    "            bce_loss = loss_list[1]\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if config.TRAIN.DACS.ENABLE and ema_model is not None and epoch > -1:\n",
    "            alpha_teacher = 0.99\n",
    "            ema_model = update_ema_variables(ema_model = ema_model, model = model, alpha_teacher=alpha_teacher, iteration=i_iter+cur_iters)\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - tic)\n",
    "        tic = time.time()\n",
    "\n",
    "        # update average loss\n",
    "        ave_loss.update(loss.item())\n",
    "        ave_acc.update(acc.item())\n",
    "        avg_sem_loss.update(sem_loss.mean().item())\n",
    "        avg_bce_loss.update(bce_loss.mean().item())\n",
    "\n",
    "        lr = adjust_learning_rate(optimizer,\n",
    "                                  base_lr,\n",
    "                                  num_iters,\n",
    "                                  i_iter+cur_iters)\n",
    "\n",
    "        if i_iter % config.PRINT_FREQ == 0:\n",
    "            msg = 'Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, ' \\\n",
    "                  'lr: {}, Loss: {:.6f}, Lambda: {:.2f}, Acc:{:.6f}, Semantic loss: {:.6f}, BCE loss: {:.6f}, SB loss: {:.6f}' .format(\n",
    "                      epoch, num_epoch, i_iter, epoch_iters,\n",
    "                      batch_time.average(), [x['lr'] for x in optimizer.param_groups], ave_loss.average(), lambda_weight,\n",
    "                      ave_acc.average(), avg_sem_loss.average(), avg_bce_loss.average(),ave_loss.average()-avg_sem_loss.average()-avg_bce_loss.average())\n",
    "            logging.info(msg)\n",
    "\n",
    "    writer.add_scalar('train_loss', ave_loss.average(), global_steps)\n",
    "    writer_dict['train_global_steps'] = global_steps + 1\n",
    "\n",
    "    # Ritorna la loss media per l'epoca\n",
    "    return ave_loss.average(), num_selected_classes, selected_classes\n",
    "\n",
    "def validate(config, testloader, model, writer_dict):\n",
    "    model.eval()\n",
    "    ave_loss = AverageMeter()\n",
    "    nums = config.MODEL.NUM_OUTPUTS\n",
    "    confusion_matrix = np.zeros(\n",
    "        (config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES, nums))\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testloader):\n",
    "            image, label, bd_gts, _, _ = batch\n",
    "            size = label.size()\n",
    "            image = image.cuda()\n",
    "            label = label.long().cuda()\n",
    "            bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "            losses, pred, _, _ = model(image, label, bd_gts)\n",
    "            if not isinstance(pred, (list, tuple)):\n",
    "                pred = [pred]\n",
    "            for i, x in enumerate(pred):\n",
    "                x = F.interpolate(\n",
    "                    input=x, size=size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "                confusion_matrix[..., i] += get_confusion_matrix(\n",
    "                    label,\n",
    "                    x,\n",
    "                    size,\n",
    "                    config.DATASET.NUM_CLASSES,\n",
    "                    config.TRAIN.IGNORE_LABEL\n",
    "                )\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            loss = losses.mean()\n",
    "            ave_loss.update(loss.item())\n",
    "\n",
    "    for i in range(nums):\n",
    "        pos = confusion_matrix[..., i].sum(1)\n",
    "        res = confusion_matrix[..., i].sum(0)\n",
    "        tp = np.diag(confusion_matrix[..., i])\n",
    "        IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "        mean_IoU = IoU_array.mean()\n",
    "\n",
    "        logging.info('{} {} {}'.format(i, IoU_array, mean_IoU))\n",
    "\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['valid_global_steps']\n",
    "    writer.add_scalar('valid_loss', ave_loss.average(), global_steps)\n",
    "    writer.add_scalar('valid_mIoU', mean_IoU, global_steps)\n",
    "    writer_dict['valid_global_steps'] = global_steps + 1\n",
    "    return ave_loss.average(), mean_IoU, IoU_array\n",
    "\n",
    "\n",
    "def testval(config, test_dataset, testloader, model,\n",
    "            sv_dir='./', sv_pred=False):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((config.DATASET.NUM_CLASSES, config.DATASET.NUM_CLASSES))\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(tqdm(testloader)):\n",
    "            image, label, _, _, name = batch\n",
    "            size = label.size()\n",
    "            pred = test_dataset.single_scale_inference(config, model, image.cuda())\n",
    "\n",
    "            if pred.size()[-2] != size[-2] or pred.size()[-1] != size[-1]:\n",
    "                pred = F.interpolate(\n",
    "                    pred, size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "            confusion_matrix += get_confusion_matrix(\n",
    "                label,\n",
    "                pred,\n",
    "                size,\n",
    "                config.DATASET.NUM_CLASSES,\n",
    "                config.TRAIN.IGNORE_LABEL)\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir, 'val_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                test_dataset.save_pred(pred, sv_path, name)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                logging.info('processing: %d images' % index)\n",
    "                pos = confusion_matrix.sum(1)\n",
    "                res = confusion_matrix.sum(0)\n",
    "                tp = np.diag(confusion_matrix)\n",
    "                IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "                mean_IoU = IoU_array.mean()\n",
    "                logging.info('mIoU: %.4f' % (mean_IoU))\n",
    "\n",
    "    pos = confusion_matrix.sum(1)\n",
    "    res = confusion_matrix.sum(0)\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    pixel_acc = tp.sum()/pos.sum()\n",
    "    mean_acc = (tp/np.maximum(1.0, pos)).mean()\n",
    "    IoU_array = (tp / np.maximum(1.0, pos + res - tp))\n",
    "    mean_IoU = IoU_array.mean()\n",
    "\n",
    "    return mean_IoU, IoU_array, pixel_acc, mean_acc\n",
    "\n",
    "\n",
    "def test(config, test_dataset, testloader, model,\n",
    "         sv_dir='./', sv_pred=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(tqdm(testloader)):\n",
    "            image, size, name = batch\n",
    "            size = size[0]\n",
    "            pred = test_dataset.single_scale_inference(\n",
    "                config,\n",
    "                model,\n",
    "                image.cuda())\n",
    "\n",
    "            if pred.size()[-2] != size[0] or pred.size()[-1] != size[1]:\n",
    "                pred = F.interpolate(\n",
    "                    pred, size[-2:],\n",
    "                    mode='bilinear', align_corners=config.MODEL.ALIGN_CORNERS\n",
    "                )\n",
    "\n",
    "            if sv_pred:\n",
    "                sv_path = os.path.join(sv_dir,'test_results')\n",
    "                if not os.path.exists(sv_path):\n",
    "                    os.mkdir(sv_path)\n",
    "                test_dataset.save_pred(pred, sv_path, name)\n",
    "\n",
    "def train_adv(config, epoch, num_epoch, epoch_iters, base_lr,\n",
    "          num_iters, trainloader, targetloader, optimizer_G, optimizer_D,\n",
    "          model, discriminator, writer_dict, lambda_adv=0.001, iter_size=4):\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    ave_loss = AverageMeter()\n",
    "    ave_acc = AverageMeter()\n",
    "    avg_sem_loss = AverageMeter()\n",
    "    avg_bce_loss = AverageMeter()\n",
    "\n",
    "    tic = time.time()\n",
    "    cur_iters = epoch * epoch_iters\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['train_global_steps']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    for i_iter, (batch_source, batch_target) in enumerate(zip(trainloader, targetloader)):\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        cumulative_loss_G = 0.0\n",
    "        cumulative_loss_D = 0.0\n",
    "\n",
    "        for sub_iter in range(iter_size): #to make the batch size bigger\n",
    "\n",
    "            #Train G\n",
    "            # don't accumulate grads in D\n",
    "            for param in discriminator.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "            images_source, labels, bd_gts, _, _ = batch_source\n",
    "            images_target, _, _, _, _ = batch_target\n",
    "\n",
    "            images_source = images_source.to(device)\n",
    "            images_target = images_target.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            bd_gts = bd_gts.float().to(device)\n",
    "\n",
    "            # Checks\n",
    "            #print(f\"Labels dtype: {labels.dtype}, shape: {labels.shape}, unique values: {torch.unique(labels)}\")\n",
    "            #assert labels.dtype == torch.long, \"Labels devono essere di tipo torch.LongTensor\"\n",
    "            #assert labels.min() >= 0, f\"Labels contengono valori negativi: {labels.min()}\"\n",
    "            #assert labels.max() < 8, f\"Labels contengono valori >= n_classes: {labels.max()}\"\n",
    "\n",
    "\n",
    "\n",
    "            # 1. Forward seg net per dominio sorgente (supervisionato)\n",
    "            loss_seg1, output_source, _, _ = model(images_source, labels, bd_gts)\n",
    "            loss_seg1 = loss_seg1.squeeze().mean()\n",
    "            loss_seg1 = loss_seg1 / iter_size\n",
    "            cumulative_loss_G += loss_seg1.item()\n",
    "            loss_seg1.backward()\n",
    "\n",
    "            # Forward pass per il dominio target (adversarial)\n",
    "            output_target = model(images_target, labels, bd_gts)[1]\n",
    "            fake_preds = discriminator(F.softmax(output_target[-2], dim=1))\n",
    "            loss_adv = nn.BCEWithLogitsLoss()(fake_preds, torch.ones_like(fake_preds))\n",
    "            loss_adv = (loss_adv * lambda_adv) / iter_size  # Normalizza la loss\n",
    "            cumulative_loss_G += loss_adv.item()\n",
    "            loss_adv.backward()\n",
    "\n",
    "\n",
    "            output_source = [t.detach() for t in output_source]\n",
    "            output_target = [t.detach() for t in output_target]\n",
    "\n",
    "            for param in discriminator.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            # Aggiorna il discriminatore\n",
    "            real_preds = discriminator(F.softmax(output_source[-2], dim=1)) #TODO: check -2\n",
    "            fake_preds = discriminator(F.softmax(output_target[-2], dim=1))\n",
    "            loss_D_real = nn.BCEWithLogitsLoss()(real_preds, torch.ones_like(real_preds))\n",
    "            loss_D_fake = nn.BCEWithLogitsLoss()(fake_preds, torch.zeros_like(fake_preds))\n",
    "            loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "            loss_D = loss_D / iter_size  # Normalizza la loss\n",
    "            cumulative_loss_D += loss_D.item()\n",
    "            loss_D.backward()\n",
    "\n",
    "        # Aggiorna i pesi dopo tutte le sub-iterazioni\n",
    "        optimizer_G.step()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Log\n",
    "        batch_time.update(time.time() - tic)\n",
    "        tic = time.time()\n",
    "\n",
    "        ave_loss.update(cumulative_loss_G)\n",
    "        ave_acc.update(0)\n",
    "        avg_sem_loss.update(0)\n",
    "        avg_bce_loss.update(0)\n",
    "\n",
    "        lr = adjust_learning_rate(optimizer_G, base_lr, num_iters, i_iter + cur_iters)\n",
    "\n",
    "        if i_iter % config.PRINT_FREQ == 0:\n",
    "            msg = ('Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, lr: {}, '\n",
    "                   'Loss_G: {:.6f}, Loss_D: {:.6f}, Acc: {:.6f}, Semantic Loss: {:.6f}, BCE Loss: {:.6f}').format(\n",
    "                      epoch, num_epoch, i_iter, epoch_iters, batch_time.average(),\n",
    "                      [x['lr'] for x in optimizer_G.param_groups], ave_loss.average(), cumulative_loss_D,\n",
    "                      ave_acc.average(), avg_sem_loss.average(), avg_bce_loss.average()\n",
    "                  )\n",
    "            logging.info(msg)\n",
    "\n",
    "    writer.add_scalar('train_loss_G', ave_loss.average(), global_steps)\n",
    "    writer.add_scalar('train_loss_D', cumulative_loss_D, global_steps)\n",
    "    writer_dict['train_global_steps'] = global_steps + 1\n",
    "\n",
    "def train_adv_multi(config, epoch, num_epoch, epoch_iters, base_lr,\n",
    "                    num_iters, trainloader, targetloader, optimizer_G,\n",
    "                    optimizer_D1, optimizer_D2, model, discriminator1, discriminator2,\n",
    "                    writer_dict, lambda_adv1=0.001, lambda_adv2=0.0005, iter_size=4):\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    discriminator1.train()\n",
    "    discriminator2.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    ave_loss = AverageMeter()\n",
    "    ave_acc = AverageMeter()\n",
    "    avg_sem_loss = AverageMeter()\n",
    "    avg_bce_loss = AverageMeter()\n",
    "\n",
    "    tic = time.time()\n",
    "    cur_iters = epoch * epoch_iters\n",
    "    writer = writer_dict['writer']\n",
    "    global_steps = writer_dict['train_global_steps']\n",
    "\n",
    "    # Iteratore per il targetloader\n",
    "    target_iter = iter(targetloader)\n",
    "\n",
    "    for i_iter, batch_source in enumerate(trainloader):\n",
    "        optimizer_G.zero_grad()\n",
    "        optimizer_D1.zero_grad()\n",
    "        optimizer_D2.zero_grad()\n",
    "\n",
    "        cumulative_loss_G = 0.0\n",
    "        cumulative_loss_D1 = 0.0\n",
    "        cumulative_loss_D2 = 0.0\n",
    "\n",
    "        for sub_iter in range(iter_size):  # Accumula i gradienti su più sotto-iterazioni\n",
    "            # Ottieni il batch target\n",
    "            try:\n",
    "                batch_target = next(target_iter)\n",
    "            except StopIteration:\n",
    "                target_iter = iter(targetloader)\n",
    "                batch_target = next(target_iter)\n",
    "\n",
    "            # Estrai i dati dal batch\n",
    "            images_source, labels, bd_gts, _, _ = batch_source\n",
    "            images_target, _, _, _, _ = batch_target\n",
    "\n",
    "            images_source = images_source.cuda()\n",
    "            images_target = images_target.cuda()\n",
    "            labels = labels.long().cuda()\n",
    "            bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "            # ------------------ TRAINING DEL GENERATORE ------------------\n",
    "            # Forward pass della rete di segmentazione (Supervisionato su sorgente)\n",
    "            losses, output_source_final, output_source_intermediate, acc, loss_list = model(images_source, labels, bd_gts)\n",
    "            loss_seg = losses.mean()\n",
    "\n",
    "            # Forward pass della rete di segmentazione su target (Non supervisionato)\n",
    "            output_target_final, output_target_intermediate = model(images_target)\n",
    "\n",
    "            # Calcola la loss adversarial per il generatore\n",
    "            fake_preds1 = discriminator1(output_target_final)\n",
    "            fake_preds2 = discriminator2(output_target_intermediate)\n",
    "\n",
    "            loss_adv1 = nn.BCEWithLogitsLoss()(fake_preds1, torch.ones_like(fake_preds1))\n",
    "            loss_adv2 = nn.BCEWithLogitsLoss()(fake_preds2, torch.ones_like(fake_preds2))\n",
    "\n",
    "            loss_G = (loss_seg + lambda_adv1 * loss_adv1 + lambda_adv2 * loss_adv2) / iter_size\n",
    "            cumulative_loss_G += loss_G.item()\n",
    "            loss_G.backward()\n",
    "\n",
    "            # ------------------ TRAINING DEL DISCRIMINATORE 1 ------------------\n",
    "            real_preds1 = discriminator1(output_source_final.detach())\n",
    "            fake_preds1 = discriminator1(output_target_final.detach())\n",
    "\n",
    "            loss_D1_real = nn.BCEWithLogitsLoss()(real_preds1, torch.ones_like(real_preds1))\n",
    "            loss_D1_fake = nn.BCEWithLogitsLoss()(fake_preds1, torch.zeros_like(fake_preds1))\n",
    "            loss_D1 = (loss_D1_real + loss_D1_fake) / 2 / iter_size\n",
    "            cumulative_loss_D1 += loss_D1.item()\n",
    "            loss_D1.backward()\n",
    "\n",
    "            # ------------------ TRAINING DEL DISCRIMINATORE 2 ------------------\n",
    "            real_preds2 = discriminator2(output_source_intermediate.detach())\n",
    "            fake_preds2 = discriminator2(output_target_intermediate.detach())\n",
    "\n",
    "            loss_D2_real = nn.BCEWithLogitsLoss()(real_preds2, torch.ones_like(real_preds2))\n",
    "            loss_D2_fake = nn.BCEWithLogitsLoss()(fake_preds2, torch.zeros_like(fake_preds2))\n",
    "            loss_D2 = (loss_D2_real + loss_D2_fake) / 2 / iter_size\n",
    "            cumulative_loss_D2 += loss_D2.item()\n",
    "            loss_D2.backward()\n",
    "\n",
    "        # Aggiorna i pesi dopo tutte le sotto-iterazioni\n",
    "        optimizer_G.step()\n",
    "        optimizer_D1.step()\n",
    "        optimizer_D2.step()\n",
    "\n",
    "        # Log\n",
    "        batch_time.update(time.time() - tic)\n",
    "        tic = time.time()\n",
    "\n",
    "        ave_loss.update(cumulative_loss_G)\n",
    "        ave_acc.update(acc.mean().item())\n",
    "        avg_sem_loss.update(loss_list[0].mean().item())\n",
    "        avg_bce_loss.update(loss_list[1].mean().item())\n",
    "\n",
    "        lr = adjust_learning_rate(optimizer_G, base_lr, num_iters, i_iter + cur_iters)\n",
    "\n",
    "        if i_iter % config.PRINT_FREQ == 0:\n",
    "            msg = ('Epoch: [{}/{}] Iter:[{}/{}], Time: {:.2f}, lr: {}, '\n",
    "                   'Loss_G: {:.6f}, Loss_D1: {:.6f}, Loss_D2: {:.6f}, Acc: {:.6f}, Semantic Loss: {:.6f}, BCE Loss: {:.6f}').format(\n",
    "                      epoch, num_epoch, i_iter, epoch_iters, batch_time.average(),\n",
    "                      [x['lr'] for x in optimizer_G.param_groups], ave_loss.average(), cumulative_loss_D1,\n",
    "                      cumulative_loss_D2, ave_acc.average(), avg_sem_loss.average(), avg_bce_loss.average()\n",
    "                  )\n",
    "            logging.info(msg)\n",
    "\n",
    "    writer.add_scalar('train_loss_G', ave_loss.average(), global_steps)\n",
    "    writer.add_scalar('train_loss_D1', cumulative_loss_D1, global_steps)\n",
    "    writer.add_scalar('train_loss_D2', cumulative_loss_D2, global_steps)\n",
    "    writer_dict['train_global_steps'] = global_steps + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7ff5e",
   "metadata": {
    "papermill": {
     "duration": 0.008512,
     "end_time": "2025-05-20T21:51:36.734749",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.726237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Main\n",
    "Here the training loop is executed, then the validation phase is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5356e926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:36.753551Z",
     "iopub.status.busy": "2025-05-20T21:51:36.753325Z",
     "iopub.status.idle": "2025-05-20T21:51:52.178860Z",
     "shell.execute_reply": "2025-05-20T21:51:52.178284Z"
    },
    "id": "fhmkK1Xpg8Uk",
    "outputId": "070b97ec-3dfc-4042-d058-9ead37ba2cad",
    "papermill": {
     "duration": 15.436707,
     "end_time": "2025-05-20T21:51:52.180189",
     "exception": false,
     "start_time": "2025-05-20T21:51:36.743482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from re import L\n",
    "# ------------------------------------------------------------------------------\n",
    "# Modified based on https://github.com/HRNet/HRNet-Semantic-Segmentation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import albumentations as A\n",
    "import logging\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "import sys\n",
    "\n",
    "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\"\n",
    "\n",
    "class_names = {\n",
    "    0: 'no-data',\n",
    "    1: 'background',\n",
    "    2: 'building',\n",
    "    3: 'road',\n",
    "    4: 'water',\n",
    "    5: 'barren',\n",
    "    6: 'forest',\n",
    "    7: 'agriculture'\n",
    "}\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train segmentation network')\n",
    "\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        default=\"configs/loveda/pidnet_small_loveda.yaml\", #file di configurazione da usare\n",
    "                        type=str)\n",
    "    parser.add_argument('--seed', type=int, default=304)\n",
    "    parser.add_argument('--opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=[],\n",
    "                        nargs=argparse.REMAINDER)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    update_config(config, args) #aggiorna config con tutti i parametri trovati nel file di configurazione\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_pidnet_model(config):\n",
    "    class_weights_pidnet = torch.tensor([0.000000, 0.116411, 0.266041, 0.607794, 1.511413, 0.745507, 0.712438, 3.040396])\n",
    "    # criterion\n",
    "    if config.LOSS.USE_OHEM:\n",
    "        sem_criterion = OhemCrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                        thres=config.LOSS.OHEMTHRES,\n",
    "                                        min_kept=config.LOSS.OHEMKEEP,\n",
    "                                        weight=class_weights_pidnet)\n",
    "    else:\n",
    "        sem_criterion = CrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                     weight=class_weights_pidnet)\n",
    "\n",
    "    imgnet = 'imagenet' in config.MODEL.PRETRAINED\n",
    "    model = get_seg_model(config, imgnet_pretrained=imgnet)\n",
    "    bd_criterion = BondaryLoss()\n",
    "    \n",
    "    model = FullModel(model, sem_criterion, bd_criterion)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_ema_model(model, config, gpus):\n",
    "    \"\"\"\n",
    "    The name ema_model literally stands for Exponential Moving Average model. \n",
    "    In the DACS code you’ll see that after each gradient update to your student network, they do:\n",
    "    \n",
    "    #for each pair of parameters (ema_param, param)\n",
    "    ema_param.data = alpha * ema_param.data + (1 - alpha) * param.data\n",
    "        \n",
    "    that’s exactly the EMA update rule. By keeping a separate copy of the network whose weights \n",
    "    are the exponential moving average of the student’s weights, you get a “smoothed,” more stable\n",
    "    model to generate pseudo-labels from. Hence the second network is called ema_model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ema_model = get_pidnet_model(config)\n",
    "    \n",
    "    for param in ema_model.parameters():\n",
    "        param.detach_()\n",
    "    mp = list(model.parameters())\n",
    "    mcp = list(ema_model.parameters())\n",
    "    n = len(mp)\n",
    "    for i in range(0, n):\n",
    "        mcp[i].data[:] = mp[i].data[:].clone()\n",
    "    ema_model = nn.DataParallel(ema_model, device_ids=gpus).cuda()\n",
    "    return ema_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.seed > 0:\n",
    "        import random\n",
    "        print('Seeding with', args.seed)\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "\n",
    "    logger, final_output_dir, tb_log_dir = create_logger(config, args.cfg, 'train')\n",
    "    logger.info(pprint.pformat(args))\n",
    "    logger.info(config)\n",
    "\n",
    "    writer_dict = {\n",
    "        'writer': SummaryWriter(tb_log_dir),\n",
    "        'train_global_steps': 0,\n",
    "        'valid_global_steps': 0,\n",
    "    }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # cudnn related setting\n",
    "        cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "        cudnn.deterministic = config.CUDNN.DETERMINISTIC\n",
    "        cudnn.enabled = config.CUDNN.ENABLED\n",
    "        gpus = list(config.GPUS)\n",
    "        if torch.cuda.device_count() != len(gpus):\n",
    "            print(\"The gpu numbers do not match!\")\n",
    "            return 0\n",
    "    gpus = list(config.GPUS)\n",
    "\n",
    "    imgnet = 'imagenet' in config.MODEL.PRETRAINED\n",
    "    model = get_seg_model(config, imgnet_pretrained=imgnet)\n",
    "    \n",
    "    batch_size = config.TRAIN.BATCH_SIZE_PER_GPU * len(gpus)\n",
    "    # prepare data\n",
    "    #crop_size = (config.TRAIN.IMAGE_SIZE[1], config.TRAIN.IMAGE_SIZE[0])\n",
    "    crop_size = (512, 512)\n",
    "\n",
    "    train_trasform = None\n",
    "\n",
    "    if config.TRAIN.AUGMENTATION.ENABLE:\n",
    "        list_augmentations = []\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP:\n",
    "            list_augmentations.append(A.RandomResizedCrop(1024, 1024, p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP:\n",
    "            list_augmentations.append(A.HorizontalFlip(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.COLOR_JITTER:\n",
    "            list_augmentations.append(A.ColorJitter(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR:\n",
    "            list_augmentations.append(A.GaussianBlur(p=0.5))\n",
    "        if config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_NOISE:\n",
    "            list_augmentations.append(A.GaussNoise(std_range=(0.2, 0.3), p=0.5))\n",
    "        if len(list_augmentations) != 0:\n",
    "            train_trasform = A.Compose(list_augmentations)\n",
    "\n",
    "    #The eval() function evaluates the specified expression, if the expression is a legal Python statement, it will be executed.\n",
    "    train_dataset = LoveDA(\n",
    "                        root=config.DATASET.ROOT,\n",
    "                        list_path=config.DATASET.TRAIN_SET,\n",
    "                        num_classes=config.DATASET.NUM_CLASSES,\n",
    "                        multi_scale=config.TRAIN.MULTI_SCALE,\n",
    "                        flip=config.TRAIN.FLIP,\n",
    "                        enable_augmentation=True,\n",
    "                        ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                        base_size=config.TRAIN.BASE_SIZE,\n",
    "                        crop_size=crop_size,\n",
    "                        scale_factor=config.TRAIN.SCALE_FACTOR,\n",
    "                        horizontal_flip=config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP,\n",
    "                        gaussian_blur=config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR,\n",
    "                        transform=None)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=config.TRAIN.SHUFFLE,\n",
    "        num_workers=config.WORKERS,\n",
    "        pin_memory=False,\n",
    "        drop_last=True)\n",
    "\n",
    "\n",
    "    targetloader = None\n",
    "    if config.TRAIN.DACS.ENABLE or config.TRAIN.GAN.ENABLE:\n",
    "        target_dataset = LoveDA(\n",
    "        root=config.DATASET.ROOT,\n",
    "        list_path=config.DATASET.TARGET_SET,\n",
    "        num_classes=config.DATASET.NUM_CLASSES,\n",
    "        multi_scale=config.TRAIN.MULTI_SCALE,\n",
    "        flip=config.TRAIN.FLIP,\n",
    "        enable_augmentation=True,\n",
    "        ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "        base_size=config.TRAIN.BASE_SIZE,\n",
    "        crop_size=crop_size,\n",
    "        scale_factor=config.TRAIN.SCALE_FACTOR,\n",
    "        horizontal_flip=config.TRAIN.AUGMENTATION.TECHNIQUES.HORIZONTAL_FLIP,\n",
    "        gaussian_blur=config.TRAIN.AUGMENTATION.TECHNIQUES.GAUSSIAN_BLUR,\n",
    "        random_crop=config.TRAIN.AUGMENTATION.TECHNIQUES.RANDOM_CROP,\n",
    "        transform=None)\n",
    "\n",
    "        targetloader = torch.utils.data.DataLoader(\n",
    "            target_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=config.TRAIN.SHUFFLE,\n",
    "            num_workers=config.WORKERS,\n",
    "            pin_memory=False,\n",
    "            drop_last=True)\n",
    "\n",
    "\n",
    "    test_size = (config.TEST.IMAGE_SIZE[1], config.TEST.IMAGE_SIZE[0])\n",
    "    test_dataset = LoveDA(\n",
    "                        root=config.DATASET.ROOT,\n",
    "                        list_path=config.DATASET.TEST_SET,\n",
    "                        num_classes=config.DATASET.NUM_CLASSES,\n",
    "                        multi_scale=False,\n",
    "                        flip=False,\n",
    "                        ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                        base_size=config.TEST.BASE_SIZE,\n",
    "                        crop_size=test_size,\n",
    "                        weighted=False)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.TEST.BATCH_SIZE_PER_GPU * len(gpus),\n",
    "        shuffle=False,\n",
    "        num_workers=config.WORKERS,\n",
    "        pin_memory=False)\n",
    "\n",
    "    # criterion\n",
    "    if config.LOSS.USE_OHEM:\n",
    "        sem_criterion = OhemCrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                        thres=config.LOSS.OHEMTHRES,\n",
    "                                        min_kept=config.LOSS.OHEMKEEP,\n",
    "                                        weight=train_dataset.class_weights)\n",
    "    else:\n",
    "        sem_criterion = CrossEntropy(ignore_label=config.TRAIN.IGNORE_LABEL,\n",
    "                                    weight=train_dataset.class_weights)\n",
    "\n",
    "    bd_criterion = BondaryLoss()\n",
    "\n",
    "    \n",
    "    model = FullModel(model, sem_criterion, bd_criterion)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = nn.DataParallel(model, device_ids=gpus).cuda() #per noi inutile\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    if config.TRAIN.OPTIMIZER == 'sgd':\n",
    "        params_dict = dict(model.named_parameters())\n",
    "        params = [{'params': list(params_dict.values()), 'lr': config.TRAIN.LR}]\n",
    "\n",
    "        optimizer = torch.optim.SGD(params,\n",
    "                                lr=config.TRAIN.LR,\n",
    "                                momentum=config.TRAIN.MOMENTUM,\n",
    "                                weight_decay=config.TRAIN.WD,\n",
    "                                nesterov=config.TRAIN.NESTEROV,\n",
    "                                )\n",
    "    else:\n",
    "        raise ValueError('Only Support SGD optimizer')\n",
    "\n",
    "    epoch_iters = int(train_dataset.__len__() / config.TRAIN.BATCH_SIZE_PER_GPU / len(gpus))\n",
    "\n",
    "    best_mIoU = 0\n",
    "    last_epoch = 0\n",
    "    flag_rm = config.TRAIN.RESUME\n",
    "    if config.TRAIN.RESUME:\n",
    "        model_state_file = os.path.join(final_output_dir, 'checkpoint.pth.tar')\n",
    "        if os.path.isfile(model_state_file):\n",
    "            print('-'*60)\n",
    "            checkpoint = torch.load(model_state_file, map_location={'cuda:0': 'cpu'})\n",
    "            best_mIoU = checkpoint['best_mIoU']\n",
    "            last_epoch = checkpoint['epoch']\n",
    "            dct = checkpoint['state_dict']\n",
    "\n",
    "            model.module.model.load_state_dict({k.replace('model.', ''): v for k, v in dct.items() if k.startswith('model.')})\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            logger.info(\"=> loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    end_epoch = config.TRAIN.END_EPOCH\n",
    "    num_iters = config.TRAIN.END_EPOCH * epoch_iters\n",
    "    real_end = 120+1 if 'camvid' in config.DATASET.TRAIN_SET else end_epoch\n",
    "\n",
    "    # grafici\n",
    "    #plt.ion()  # Modalità interattiva\n",
    "    #fig, ax = plt.subplots(2, 1, figsize=(10, 8))  # Due grafici: uno per le loss, uno per la mean IoU\n",
    "    train_loss_history = []\n",
    "    eval_loss_history = []\n",
    "    mean_iou_history = []\n",
    "    initial_epoch_iou = [0.5] * config.DATASET.NUM_CLASSES  # Neutral starting point\n",
    "    IoU_array_history = [initial_epoch_iou]\n",
    "\n",
    "    activate_ema_model = True\n",
    "    ema_model = None\n",
    "    deeplab_model = None\n",
    "    # deeplab_model.load_state_dict(torch.load(\"/kaggle/input/deeplab-pretrained/deeplabv2_loveda_best.pth\"))\n",
    "    # deeplab_model.to(device)\n",
    "    # deeplab_model.eval()\n",
    "    for epoch in range(last_epoch, real_end):\n",
    "\n",
    "        # --- EMA model creation---\n",
    "        if config.TRAIN.DACS.ENABLE and activate_ema_model and epoch > -1:\n",
    "            ema_model = create_ema_model(model, config, gpus)\n",
    "            activate_ema_model = False\n",
    "        # --- EMA model creation---\n",
    "    \n",
    "\n",
    "        current_trainloader = trainloader\n",
    "        if current_trainloader.sampler is not None and hasattr(current_trainloader.sampler, 'set_epoch'):\n",
    "            current_trainloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        if config.TRAIN.GAN.ENABLE:\n",
    "\n",
    "            discriminator = FCDiscriminator(num_classes=8).to(device)\n",
    "            #optimizer_G = optim.SGD(model.parameters(), lr=2.5e-4, momentum=0.9, weight_decay=1e-4) paper infos, but our net is different\n",
    "            optimizer_G = optimizer\n",
    "            optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.9, 0.99)) #given by the paper\n",
    "\n",
    "            if config.TRAIN.GAN.MULTI_LEVEL:\n",
    "                train_adv_multi(config, epoch, config.TRAIN.END_EPOCH, epoch_iters, config.TRAIN.LR, num_iters, trainloader, targetloader, optimizer_G, optimizer_D, model, discriminator,discriminator, writer_dict)\n",
    "            else:\n",
    "                train_adv(config, epoch, config.TRAIN.END_EPOCH, epoch_iters, config.TRAIN.LR, num_iters, trainloader, targetloader, optimizer_G, optimizer_D, model, discriminator, writer_dict)\n",
    "        \n",
    "        elif config.TRAIN.DACS.ENABLE:\n",
    "            train_loss, num_selected_classes, selected_classes = train(config, epoch, config.TRAIN.END_EPOCH,\n",
    "                  epoch_iters, config.TRAIN.LR, num_iters,\n",
    "                  trainloader, optimizer, model, writer_dict, mean_iou_history, IoU_array_history[-1], deeplab_model=deeplab_model, ema_model=ema_model, targetloader=targetloader)\n",
    "        else:\n",
    "            \n",
    "            train_loss = train(config, epoch, config.TRAIN.END_EPOCH,\n",
    "                  epoch_iters, config.TRAIN.LR, num_iters,\n",
    "                  trainloader, optimizer, model, writer_dict, targetloader=targetloader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        if flag_rm == 1 or (epoch % 5 == 0 and epoch < real_end - 100) or (epoch >= real_end - 100):\n",
    "            valid_loss, mean_IoU, IoU_array = validate(config, testloader, model, writer_dict)\n",
    "            eval_loss_history.append(valid_loss)\n",
    "            mean_iou_history.append(mean_IoU)\n",
    "            IoU_array_history.append(IoU_array)\n",
    "\n",
    "        if flag_rm == 1:\n",
    "            flag_rm = 0\n",
    "        logger.info('=> saving checkpoint to {}'.format(\n",
    "            final_output_dir + 'checkpoint.pth.tar'))\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'best_mIoU': best_mIoU,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
    "        if mean_IoU > best_mIoU:\n",
    "            best_mIoU = mean_IoU\n",
    "            torch.save(model.module.state_dict(),\n",
    "                    os.path.join(final_output_dir, 'best.pt'))\n",
    "        if config.TRAIN.DACS.ENABLE:\n",
    "            # Format selected class names\n",
    "            selected_class_names = [class_names[cid] for cid in selected_classes]\n",
    "            selected_classes_str = \", \".join(f\"{name} (class {cid})\" for cid, name in zip(selected_classes, selected_class_names))\n",
    "            \n",
    "            # Create per-class IoU details only for selected classes\n",
    "            iou_details = \"\\n\".join(\n",
    "                f\"  - {class_names[class_id]} (class {class_id}): IoU = {IoU_array[class_id]:.4f}\"\n",
    "                for class_id in selected_classes\n",
    "                if class_id < len(IoU_array)\n",
    "            )\n",
    "            \n",
    "            # Compose the message\n",
    "            msg = (\n",
    "                \"-----------------------------------------------------------------------------------------------\\n\"\n",
    "                \"Number of selected classes: {}\\n\"\n",
    "                \"Selected classes: {}\\n\"\n",
    "                \"Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f}\\n\"\n",
    "                \"Per-class IoUs:\\n{}\"\n",
    "                \"\\n-----------------------------------------------------------------------------------------------\"\n",
    "            ).format(len(selected_classes), selected_classes_str, valid_loss, mean_IoU, best_mIoU, iou_details)\n",
    "\n",
    "        else:\n",
    "            msg = 'Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f}'.format(\n",
    "                    valid_loss, mean_IoU, best_mIoU)\n",
    "        logging.info(msg)\n",
    "        logging.info(IoU_array)\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(model.module.state_dict(),\n",
    "            os.path.join(final_output_dir, 'final_state.pt'))\n",
    "\n",
    "    writer_dict['writer'].close()\n",
    "    end = timeit.default_timer()\n",
    "    logger.info('Hours: %d' % int((end-start)/3600))\n",
    "    logger.info('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a26d93",
   "metadata": {
    "papermill": {
     "duration": 0.008431,
     "end_time": "2025-05-20T21:51:52.197725",
     "exception": false,
     "start_time": "2025-05-20T21:51:52.189294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Clear existing loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f133bc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:52.215823Z",
     "iopub.status.busy": "2025-05-20T21:51:52.215386Z",
     "iopub.status.idle": "2025-05-20T21:51:52.218933Z",
     "shell.execute_reply": "2025-05-20T21:51:52.218447Z"
    },
    "papermill": {
     "duration": 0.013747,
     "end_time": "2025-05-20T21:51:52.219966",
     "exception": false,
     "start_time": "2025-05-20T21:51:52.206219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()  # ✅ Clear all existing handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "763ce00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:51:52.238054Z",
     "iopub.status.busy": "2025-05-20T21:51:52.237561Z",
     "iopub.status.idle": "2025-05-21T00:44:41.268180Z",
     "shell.execute_reply": "2025-05-21T00:44:41.267313Z"
    },
    "papermill": {
     "duration": 10369.041195,
     "end_time": "2025-05-21T00:44:41.269767",
     "exception": false,
     "start_time": "2025-05-20T21:51:52.228572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/loveda/pidnet_small_loveda.yaml', seed=304, opts=[])\n",
      "AUTO_RESUME: False\n",
      "CUDNN:\n",
      "  BENCHMARK: True\n",
      "  DETERMINISTIC: False\n",
      "  ENABLED: True\n",
      "DATASET:\n",
      "  DATASET: loveda\n",
      "  EXTRA_TRAIN_SET: \n",
      "  NUM_CLASSES: 8\n",
      "  ROOT: data/\n",
      "  TARGET_SET: list/loveda/rural/train.lst\n",
      "  TEST_SET: list/loveda/urban_rural/val.lst\n",
      "  TRAIN_SET: list/loveda/urban_rural/train.lst\n",
      "GPUS: (0,)\n",
      "LOG_DIR: log\n",
      "LOSS:\n",
      "  BALANCE_WEIGHTS: [0.4, 1.0]\n",
      "  CLASS_BALANCE: False\n",
      "  OHEMKEEP: 131072\n",
      "  OHEMTHRES: 0.9\n",
      "  SB_WEIGHTS: 1.0\n",
      "  USE_OHEM: True\n",
      "MODEL:\n",
      "  ALIGN_CORNERS: True\n",
      "  NAME: pidnet_small\n",
      "  NUM_OUTPUTS: 2\n",
      "  PRETRAINED: pretrained_models/imagenet/PIDNet_S_ImageNet.pth.tar\n",
      "OUTPUT_DIR: output\n",
      "PIN_MEMORY: True\n",
      "PRINT_FREQ: 10\n",
      "TEST:\n",
      "  BASE_SIZE: 2048\n",
      "  BATCH_SIZE_PER_GPU: 6\n",
      "  FLIP_TEST: False\n",
      "  IMAGE_SIZE: [2048, 1024]\n",
      "  MODEL_FILE: output/loveda/pidnet_small_loveda/final_state.pt\n",
      "  MULTI_SCALE: False\n",
      "  OUTPUT_INDEX: 1\n",
      "TRAIN:\n",
      "  AUGMENTATION:\n",
      "    ENABLE: True\n",
      "    PROBABILITY: 0.5\n",
      "    TECHNIQUES:\n",
      "      COLOR_JITTER: False\n",
      "      GAUSSIAN_BLUR: False\n",
      "      GAUSSIAN_NOISE: False\n",
      "      HORIZONTAL_FLIP: False\n",
      "      RANDOM_CROP: False\n",
      "  BASE_SIZE: 2048\n",
      "  BATCH_SIZE_PER_GPU: 6\n",
      "  BEGIN_EPOCH: 0\n",
      "  DACS:\n",
      "    ENABLE: True\n",
      "    THRESHOLD: 0.968\n",
      "  END_EPOCH: 20\n",
      "  EXTRA_EPOCH: 0\n",
      "  EXTRA_LR: 0.001\n",
      "  FLIP: False\n",
      "  GAN:\n",
      "    ENABLE: False\n",
      "    MULTI_LEVEL: False\n",
      "  IGNORE_LABEL: 0\n",
      "  IMAGE_SIZE: [1024, 1024]\n",
      "  LR: 0.01\n",
      "  MOMENTUM: 0.7\n",
      "  MULTI_SCALE: False\n",
      "  NESTEROV: False\n",
      "  OPTIMIZER: sgd\n",
      "  RESUME: False\n",
      "  SCALE_FACTOR: 16\n",
      "  SHUFFLE: True\n",
      "  WD: 0.0005\n",
      "WORKERS: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding with 304\n",
      "=> creating output\n",
      "=> creating output/loveda/pidnet_small_loveda/dacs\n",
      "=> creating log/loveda/pidnet_small/pidnet_small_loveda_2025-05-20-21-51\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention!!!\n",
      "Loaded 302 parameters!\n",
      "Over!!!\n",
      "Attention!!!\n",
      "Loaded 302 parameters!\n",
      "Over!!!\n",
      "Epoch: [0/20] Iter:[0/192], Time: 15.85, lr: [0.01], Loss: 9.879162, Lambda: 0.01, Acc:0.130505, Semantic loss: 2.392974, BCE loss: 5.100695, SB loss: 2.385493\n",
      "Epoch: [0/20] Iter:[10/192], Time: 2.97, lr: [0.009976559445324192], Loss: 6.448111, Lambda: 0.01, Acc:0.184198, Semantic loss: 2.107907, BCE loss: 3.007983, SB loss: 1.332221\n",
      "Epoch: [0/20] Iter:[20/192], Time: 2.34, lr: [0.009953112769592761], Loss: 5.683660, Lambda: 0.01, Acc:0.183311, Semantic loss: 1.859925, BCE loss: 2.683695, SB loss: 1.140040\n",
      "Epoch: [0/20] Iter:[30/192], Time: 2.10, lr: [0.009929659955177281], Loss: 5.117840, Lambda: 0.01, Acc:0.192401, Semantic loss: 1.744198, BCE loss: 2.354251, SB loss: 1.019391\n",
      "Epoch: [0/20] Iter:[40/192], Time: 1.98, lr: [0.009906200984352154], Loss: 4.699099, Lambda: 0.01, Acc:0.197059, Semantic loss: 1.590945, BCE loss: 2.187167, SB loss: 0.920988\n",
      "Epoch: [0/20] Iter:[50/192], Time: 1.91, lr: [0.009882735839293803], Loss: 4.507642, Lambda: 0.01, Acc:0.189978, Semantic loss: 1.551784, BCE loss: 2.058111, SB loss: 0.897746\n",
      "Epoch: [0/20] Iter:[60/192], Time: 1.86, lr: [0.00985926450207989], Loss: 4.332739, Lambda: 0.01, Acc:0.186853, Semantic loss: 1.478120, BCE loss: 2.007012, SB loss: 0.847607\n",
      "Epoch: [0/20] Iter:[70/192], Time: 1.82, lr: [0.009835786954688485], Loss: 4.174676, Lambda: 0.01, Acc:0.191554, Semantic loss: 1.417967, BCE loss: 1.946788, SB loss: 0.809921\n",
      "Epoch: [0/20] Iter:[80/192], Time: 1.80, lr: [0.00981230317899726], Loss: 4.044108, Lambda: 0.01, Acc:0.191306, Semantic loss: 1.370354, BCE loss: 1.910050, SB loss: 0.763704\n",
      "Epoch: [0/20] Iter:[90/192], Time: 1.78, lr: [0.009788813156782662], Loss: 3.933925, Lambda: 0.01, Acc:0.194904, Semantic loss: 1.317969, BCE loss: 1.879949, SB loss: 0.736008\n",
      "Epoch: [0/20] Iter:[100/192], Time: 1.77, lr: [0.009765316869719067], Loss: 3.844838, Lambda: 0.01, Acc:0.197437, Semantic loss: 1.287657, BCE loss: 1.842524, SB loss: 0.714656\n",
      "Epoch: [0/20] Iter:[110/192], Time: 1.76, lr: [0.009741814299377942], Loss: 3.796046, Lambda: 0.01, Acc:0.197784, Semantic loss: 1.259503, BCE loss: 1.827184, SB loss: 0.709358\n",
      "Epoch: [0/20] Iter:[120/192], Time: 1.75, lr: [0.009718305427226986], Loss: 3.702042, Lambda: 0.01, Acc:0.201448, Semantic loss: 1.228061, BCE loss: 1.787126, SB loss: 0.686855\n",
      "Epoch: [0/20] Iter:[130/192], Time: 1.73, lr: [0.009694790234629266], Loss: 3.634619, Lambda: 0.01, Acc:0.207197, Semantic loss: 1.193069, BCE loss: 1.774763, SB loss: 0.666787\n",
      "Epoch: [0/20] Iter:[140/192], Time: 1.73, lr: [0.009671268702842338], Loss: 3.614328, Lambda: 0.01, Acc:0.209768, Semantic loss: 1.180104, BCE loss: 1.759259, SB loss: 0.674965\n",
      "Epoch: [0/20] Iter:[150/192], Time: 1.72, lr: [0.009647740813017376], Loss: 3.562376, Lambda: 0.01, Acc:0.209849, Semantic loss: 1.151829, BCE loss: 1.750338, SB loss: 0.660209\n",
      "Epoch: [0/20] Iter:[160/192], Time: 1.71, lr: [0.009624206546198262], Loss: 3.566559, Lambda: 0.01, Acc:0.211193, Semantic loss: 1.145774, BCE loss: 1.745129, SB loss: 0.675655\n",
      "Epoch: [0/20] Iter:[170/192], Time: 1.71, lr: [0.009600665883320689], Loss: 3.541763, Lambda: 0.01, Acc:0.212219, Semantic loss: 1.141106, BCE loss: 1.730799, SB loss: 0.669858\n",
      "Epoch: [0/20] Iter:[180/192], Time: 1.70, lr: [0.009577118805211254], Loss: 3.506050, Lambda: 0.01, Acc:0.212463, Semantic loss: 1.124282, BCE loss: 1.726375, SB loss: 0.655394\n",
      "Epoch: [0/20] Iter:[190/192], Time: 1.69, lr: [0.009553565292586523], Loss: 3.458687, Lambda: 0.01, Acc:0.215104, Semantic loss: 1.103257, BCE loss: 1.715855, SB loss: 0.639576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.23630431 0.16874843 0.06736603 0.20420113 0.06207027\n",
      " 0.1056217  0.21959842] 0.1329887866333348\n",
      "1 [0.         0.26806929 0.2341031  0.12110271 0.19176493 0.06264244\n",
      " 0.11178752 0.32225813] 0.16396601468651628\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: water (class 4), agriculture (class 7), barren (class 5)\n",
      "Loss: 5.689, MeanIU:  0.1640, Best_mIoU:  0.1640\n",
      "Per-class IoUs:\n",
      "  - water (class 4): IoU = 0.1918\n",
      "  - agriculture (class 7): IoU = 0.3223\n",
      "  - barren (class 5): IoU = 0.0626\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.26806929 0.2341031  0.12110271 0.19176493 0.06264244\n",
      " 0.11178752 0.32225813]\n",
      "Epoch: [1/20] Iter:[0/192], Time: 6.69, lr: [0.009548853816214998], Loss: 2.160395, Lambda: 0.02, Acc:0.220046, Semantic loss: 0.644571, BCE loss: 1.127091, SB loss: 0.388733\n",
      "Epoch: [1/20] Iter:[10/192], Time: 2.09, lr: [0.009525292556561479], Loss: 2.602839, Lambda: 0.02, Acc:0.246648, Semantic loss: 0.747330, BCE loss: 1.484797, SB loss: 0.370712\n",
      "Epoch: [1/20] Iter:[20/192], Time: 1.88, lr: [0.00950172481957719], Loss: 2.708557, Lambda: 0.02, Acc:0.259524, Semantic loss: 0.776550, BCE loss: 1.561715, SB loss: 0.370292\n",
      "Epoch: [1/20] Iter:[30/192], Time: 1.77, lr: [0.009478150585620286], Loss: 2.685486, Lambda: 0.02, Acc:0.263533, Semantic loss: 0.761272, BCE loss: 1.548472, SB loss: 0.375741\n",
      "Epoch: [1/20] Iter:[40/192], Time: 1.74, lr: [0.009454569834934885], Loss: 2.664114, Lambda: 0.02, Acc:0.263365, Semantic loss: 0.756918, BCE loss: 1.537336, SB loss: 0.369860\n",
      "Epoch: [1/20] Iter:[50/192], Time: 1.71, lr: [0.009430982547650114], Loss: 2.667725, Lambda: 0.02, Acc:0.267947, Semantic loss: 0.764170, BCE loss: 1.532559, SB loss: 0.370996\n",
      "Epoch: [1/20] Iter:[60/192], Time: 1.69, lr: [0.009407388703779091], Loss: 2.693263, Lambda: 0.02, Acc:0.274681, Semantic loss: 0.777867, BCE loss: 1.536002, SB loss: 0.379394\n",
      "Epoch: [1/20] Iter:[70/192], Time: 1.68, lr: [0.009383788283217955], Loss: 2.725284, Lambda: 0.02, Acc:0.272637, Semantic loss: 0.779767, BCE loss: 1.552032, SB loss: 0.393485\n",
      "Epoch: [1/20] Iter:[80/192], Time: 1.68, lr: [0.00936018126574482], Loss: 2.741162, Lambda: 0.02, Acc:0.270816, Semantic loss: 0.789220, BCE loss: 1.547665, SB loss: 0.404277\n",
      "Epoch: [1/20] Iter:[90/192], Time: 1.66, lr: [0.009336567631018769], Loss: 2.731842, Lambda: 0.02, Acc:0.275932, Semantic loss: 0.788379, BCE loss: 1.535105, SB loss: 0.408358\n",
      "Epoch: [1/20] Iter:[100/192], Time: 1.67, lr: [0.009312947358578814], Loss: 2.719026, Lambda: 0.02, Acc:0.273365, Semantic loss: 0.782168, BCE loss: 1.530334, SB loss: 0.406524\n",
      "Epoch: [1/20] Iter:[110/192], Time: 1.66, lr: [0.009289320427842841], Loss: 2.711640, Lambda: 0.02, Acc:0.274083, Semantic loss: 0.778534, BCE loss: 1.530715, SB loss: 0.402391\n",
      "Epoch: [1/20] Iter:[120/192], Time: 1.66, lr: [0.009265686818106552], Loss: 2.695428, Lambda: 0.02, Acc:0.272221, Semantic loss: 0.769659, BCE loss: 1.523413, SB loss: 0.402357\n",
      "Epoch: [1/20] Iter:[130/192], Time: 1.65, lr: [0.009242046508542393], Loss: 2.680178, Lambda: 0.02, Acc:0.273346, Semantic loss: 0.765036, BCE loss: 1.515469, SB loss: 0.399673\n",
      "Epoch: [1/20] Iter:[140/192], Time: 1.65, lr: [0.009218399478198466], Loss: 2.671372, Lambda: 0.02, Acc:0.276807, Semantic loss: 0.757194, BCE loss: 1.517125, SB loss: 0.397054\n",
      "Epoch: [1/20] Iter:[150/192], Time: 1.65, lr: [0.009194745705997428], Loss: 2.675336, Lambda: 0.02, Acc:0.275951, Semantic loss: 0.757127, BCE loss: 1.505799, SB loss: 0.412410\n",
      "Epoch: [1/20] Iter:[160/192], Time: 1.64, lr: [0.00917108517073538], Loss: 2.668334, Lambda: 0.02, Acc:0.275571, Semantic loss: 0.751328, BCE loss: 1.504152, SB loss: 0.412854\n",
      "Epoch: [1/20] Iter:[170/192], Time: 1.64, lr: [0.00914741785108075], Loss: 2.662047, Lambda: 0.02, Acc:0.274577, Semantic loss: 0.744969, BCE loss: 1.507027, SB loss: 0.410051\n",
      "Epoch: [1/20] Iter:[180/192], Time: 1.64, lr: [0.00912374372557314], Loss: 2.653709, Lambda: 0.02, Acc:0.276064, Semantic loss: 0.738956, BCE loss: 1.508237, SB loss: 0.406516\n",
      "Epoch: [1/20] Iter:[190/192], Time: 1.63, lr: [0.009100062772622186], Loss: 2.649584, Lambda: 0.02, Acc:0.276829, Semantic loss: 0.740497, BCE loss: 1.501439, SB loss: 0.407648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.31173658 0.17717253 0.09126455 0.23842159 0.07819628\n",
      " 0.1191372  0.21255282] 0.15356019431196735\n",
      "1 [0.         0.25503625 0.19755227 0.16080689 0.27522509 0.02456232\n",
      " 0.14009231 0.44537238] 0.18733093985584465\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: agriculture (class 7), building (class 2), road (class 3)\n",
      "Loss: 5.776, MeanIU:  0.1873, Best_mIoU:  0.1873\n",
      "Per-class IoUs:\n",
      "  - agriculture (class 7): IoU = 0.4454\n",
      "  - building (class 2): IoU = 0.1976\n",
      "  - road (class 3): IoU = 0.1608\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.25503625 0.19755227 0.16080689 0.27522509 0.02456232\n",
      " 0.14009231 0.44537238]\n",
      "Epoch: [2/20] Iter:[0/192], Time: 7.12, lr: [0.009095325760829623], Loss: 3.214322, Lambda: 0.03, Acc:0.348064, Semantic loss: 1.084594, BCE loss: 1.517843, SB loss: 0.611885\n",
      "Epoch: [2/20] Iter:[10/192], Time: 2.15, lr: [0.009071636586262652], Loss: 2.598315, Lambda: 0.03, Acc:0.261967, Semantic loss: 0.702613, BCE loss: 1.523466, SB loss: 0.372236\n",
      "Epoch: [2/20] Iter:[20/192], Time: 1.91, lr: [0.009047940536290279], Loss: 2.567928, Lambda: 0.03, Acc:0.286956, Semantic loss: 0.703506, BCE loss: 1.506555, SB loss: 0.357867\n",
      "Epoch: [2/20] Iter:[30/192], Time: 1.82, lr: [0.009024237588898336], Loss: 2.562588, Lambda: 0.03, Acc:0.285922, Semantic loss: 0.695719, BCE loss: 1.486207, SB loss: 0.380662\n",
      "Epoch: [2/20] Iter:[40/192], Time: 1.76, lr: [0.009000527721937697], Loss: 2.588410, Lambda: 0.03, Acc:0.286470, Semantic loss: 0.687876, BCE loss: 1.503793, SB loss: 0.396741\n",
      "Epoch: [2/20] Iter:[50/192], Time: 1.73, lr: [0.008976810913123051], Loss: 2.551824, Lambda: 0.03, Acc:0.287283, Semantic loss: 0.666321, BCE loss: 1.499570, SB loss: 0.385932\n",
      "Epoch: [2/20] Iter:[60/192], Time: 1.72, lr: [0.008953087140031669], Loss: 2.557983, Lambda: 0.03, Acc:0.288687, Semantic loss: 0.675910, BCE loss: 1.497163, SB loss: 0.384909\n",
      "Epoch: [2/20] Iter:[70/192], Time: 1.70, lr: [0.008929356380102142], Loss: 2.547787, Lambda: 0.03, Acc:0.290594, Semantic loss: 0.673344, BCE loss: 1.502693, SB loss: 0.371749\n",
      "Epoch: [2/20] Iter:[80/192], Time: 1.69, lr: [0.008905618610633112], Loss: 2.537217, Lambda: 0.03, Acc:0.291025, Semantic loss: 0.669970, BCE loss: 1.505127, SB loss: 0.362121\n",
      "Epoch: [2/20] Iter:[90/192], Time: 1.68, lr: [0.008881873808781991], Loss: 2.524462, Lambda: 0.03, Acc:0.290416, Semantic loss: 0.680115, BCE loss: 1.482136, SB loss: 0.362212\n",
      "Epoch: [2/20] Iter:[100/192], Time: 1.67, lr: [0.008858121951563658], Loss: 2.511324, Lambda: 0.03, Acc:0.290247, Semantic loss: 0.685662, BCE loss: 1.462690, SB loss: 0.362972\n",
      "Epoch: [2/20] Iter:[110/192], Time: 1.66, lr: [0.008834363015849136], Loss: 2.497785, Lambda: 0.03, Acc:0.293475, Semantic loss: 0.677748, BCE loss: 1.462715, SB loss: 0.357322\n",
      "Epoch: [2/20] Iter:[120/192], Time: 1.66, lr: [0.008810596978364274], Loss: 2.512666, Lambda: 0.03, Acc:0.294151, Semantic loss: 0.689491, BCE loss: 1.465655, SB loss: 0.357520\n",
      "Epoch: [2/20] Iter:[130/192], Time: 1.65, lr: [0.008786823815688379], Loss: 2.512617, Lambda: 0.03, Acc:0.293859, Semantic loss: 0.688431, BCE loss: 1.466966, SB loss: 0.357220\n",
      "Epoch: [2/20] Iter:[140/192], Time: 1.65, lr: [0.008763043504252865], Loss: 2.506045, Lambda: 0.03, Acc:0.295350, Semantic loss: 0.680558, BCE loss: 1.469749, SB loss: 0.355738\n",
      "Epoch: [2/20] Iter:[150/192], Time: 1.65, lr: [0.008739256020339866], Loss: 2.518327, Lambda: 0.03, Acc:0.295288, Semantic loss: 0.676365, BCE loss: 1.483203, SB loss: 0.358759\n",
      "Epoch: [2/20] Iter:[160/192], Time: 1.65, lr: [0.00871546134008083], Loss: 2.534984, Lambda: 0.03, Acc:0.295906, Semantic loss: 0.679977, BCE loss: 1.487647, SB loss: 0.367361\n",
      "Epoch: [2/20] Iter:[170/192], Time: 1.64, lr: [0.008691659439455107], Loss: 2.533238, Lambda: 0.03, Acc:0.296777, Semantic loss: 0.678713, BCE loss: 1.485753, SB loss: 0.368772\n",
      "Epoch: [2/20] Iter:[180/192], Time: 1.64, lr: [0.008667850294288517], Loss: 2.523877, Lambda: 0.03, Acc:0.297402, Semantic loss: 0.673700, BCE loss: 1.484502, SB loss: 0.365675\n",
      "Epoch: [2/20] Iter:[190/192], Time: 1.64, lr: [0.008644033880251888], Loss: 2.519989, Lambda: 0.03, Acc:0.298055, Semantic loss: 0.670757, BCE loss: 1.484178, SB loss: 0.365055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.25050605 0.21521186 0.1116372  0.22938661 0.11081598\n",
      " 0.10438016 0.24657401] 0.1585639848644642\n",
      "1 [0.         0.11655117 0.33467086 0.22808898 0.2421754  0.05168421\n",
      " 0.13459191 0.45276811] 0.1950663303126314\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: background (class 1), barren (class 5), water (class 4)\n",
      "Loss: 5.137, MeanIU:  0.1951, Best_mIoU:  0.1951\n",
      "Per-class IoUs:\n",
      "  - background (class 1): IoU = 0.1166\n",
      "  - barren (class 5): IoU = 0.0517\n",
      "  - water (class 4): IoU = 0.2422\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.11655117 0.33467086 0.22808898 0.2421754  0.05168421\n",
      " 0.13459191 0.45276811]\n",
      "Epoch: [3/20] Iter:[0/192], Time: 6.77, lr: [0.008639269723028191], Loss: 2.097963, Lambda: 0.04, Acc:0.313542, Semantic loss: 0.607046, BCE loss: 1.134246, SB loss: 0.356671\n",
      "Epoch: [3/20] Iter:[10/192], Time: 2.20, lr: [0.008615444554012613], Loss: 2.407676, Lambda: 0.04, Acc:0.312858, Semantic loss: 0.656281, BCE loss: 1.430880, SB loss: 0.320514\n",
      "Epoch: [3/20] Iter:[20/192], Time: 1.93, lr: [0.008591612062049989], Loss: 2.343316, Lambda: 0.04, Acc:0.323520, Semantic loss: 0.612894, BCE loss: 1.397958, SB loss: 0.332464\n",
      "Epoch: [3/20] Iter:[30/192], Time: 1.83, lr: [0.008567772222305215], Loss: 2.371539, Lambda: 0.04, Acc:0.319678, Semantic loss: 0.608763, BCE loss: 1.429408, SB loss: 0.333367\n",
      "Epoch: [3/20] Iter:[40/192], Time: 1.78, lr: [0.008543925009781886], Loss: 2.374390, Lambda: 0.04, Acc:0.322284, Semantic loss: 0.597390, BCE loss: 1.447340, SB loss: 0.329660\n",
      "Epoch: [3/20] Iter:[50/192], Time: 1.75, lr: [0.00852007039932076], Loss: 2.360589, Lambda: 0.04, Acc:0.329247, Semantic loss: 0.591974, BCE loss: 1.437433, SB loss: 0.331182\n",
      "Epoch: [3/20] Iter:[60/192], Time: 1.73, lr: [0.00849620836559818], Loss: 2.387742, Lambda: 0.04, Acc:0.331130, Semantic loss: 0.583546, BCE loss: 1.475907, SB loss: 0.328289\n",
      "Epoch: [3/20] Iter:[70/192], Time: 1.73, lr: [0.008472338883124477], Loss: 2.395547, Lambda: 0.04, Acc:0.329162, Semantic loss: 0.603091, BCE loss: 1.456812, SB loss: 0.335644\n",
      "Epoch: [3/20] Iter:[80/192], Time: 1.71, lr: [0.008448461926242374], Loss: 2.415193, Lambda: 0.04, Acc:0.324945, Semantic loss: 0.611959, BCE loss: 1.461909, SB loss: 0.341326\n",
      "Epoch: [3/20] Iter:[90/192], Time: 1.70, lr: [0.008424577469125337], Loss: 2.402393, Lambda: 0.04, Acc:0.321691, Semantic loss: 0.617296, BCE loss: 1.442167, SB loss: 0.342930\n",
      "Epoch: [3/20] Iter:[100/192], Time: 1.69, lr: [0.008400685485775935], Loss: 2.409204, Lambda: 0.04, Acc:0.320255, Semantic loss: 0.623287, BCE loss: 1.439385, SB loss: 0.346532\n",
      "Epoch: [3/20] Iter:[110/192], Time: 1.69, lr: [0.008376785950024154], Loss: 2.392057, Lambda: 0.04, Acc:0.319306, Semantic loss: 0.616514, BCE loss: 1.433007, SB loss: 0.342536\n",
      "Epoch: [3/20] Iter:[120/192], Time: 1.68, lr: [0.00835287883552571], Loss: 2.386513, Lambda: 0.04, Acc:0.320783, Semantic loss: 0.613804, BCE loss: 1.428918, SB loss: 0.343791\n",
      "Epoch: [3/20] Iter:[130/192], Time: 1.68, lr: [0.008328964115760324], Loss: 2.389403, Lambda: 0.04, Acc:0.322246, Semantic loss: 0.616110, BCE loss: 1.430347, SB loss: 0.342946\n",
      "Epoch: [3/20] Iter:[140/192], Time: 1.67, lr: [0.008305041764029988], Loss: 2.411093, Lambda: 0.04, Acc:0.320848, Semantic loss: 0.621805, BCE loss: 1.438890, SB loss: 0.350398\n",
      "Epoch: [3/20] Iter:[150/192], Time: 1.67, lr: [0.008281111753457188], Loss: 2.416119, Lambda: 0.04, Acc:0.321746, Semantic loss: 0.618186, BCE loss: 1.448972, SB loss: 0.348961\n",
      "Epoch: [3/20] Iter:[160/192], Time: 1.67, lr: [0.008257174056983133], Loss: 2.426081, Lambda: 0.04, Acc:0.320616, Semantic loss: 0.624536, BCE loss: 1.452026, SB loss: 0.349519\n",
      "Epoch: [3/20] Iter:[170/192], Time: 1.67, lr: [0.00823322864736593], Loss: 2.428775, Lambda: 0.04, Acc:0.320339, Semantic loss: 0.626037, BCE loss: 1.450391, SB loss: 0.352347\n",
      "Epoch: [3/20] Iter:[180/192], Time: 1.67, lr: [0.008209275497178764], Loss: 2.434786, Lambda: 0.04, Acc:0.320706, Semantic loss: 0.626992, BCE loss: 1.454123, SB loss: 0.353670\n",
      "Epoch: [3/20] Iter:[190/192], Time: 1.66, lr: [0.008185314578808021], Loss: 2.433906, Lambda: 0.04, Acc:0.320397, Semantic loss: 0.624581, BCE loss: 1.456989, SB loss: 0.352336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.26001138 0.2286098  0.10131904 0.28113155 0.10739107\n",
      " 0.10909267 0.27030428] 0.16973247384249263\n",
      "1 [0.         0.18903691 0.30751022 0.16230885 0.34474726 0.05516377\n",
      " 0.14118961 0.41944583] 0.20242530467194558\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: barren (class 5), building (class 2), water (class 4)\n",
      "Loss: 5.006, MeanIU:  0.2024, Best_mIoU:  0.2024\n",
      "Per-class IoUs:\n",
      "  - barren (class 5): IoU = 0.0552\n",
      "  - building (class 2): IoU = 0.3075\n",
      "  - water (class 4): IoU = 0.3447\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.18903691 0.30751022 0.16230885 0.34474726 0.05516377\n",
      " 0.14118961 0.41944583]\n",
      "Epoch: [4/20] Iter:[0/192], Time: 6.45, lr: [0.008180521460508584], Loss: 2.205338, Lambda: 0.05, Acc:0.331193, Semantic loss: 0.477063, BCE loss: 1.420236, SB loss: 0.308039\n",
      "Epoch: [4/20] Iter:[10/192], Time: 2.08, lr: [0.008156551183601795], Loss: 2.523327, Lambda: 0.05, Acc:0.301117, Semantic loss: 0.612435, BCE loss: 1.531350, SB loss: 0.379542\n",
      "Epoch: [4/20] Iter:[20/192], Time: 1.87, lr: [0.008132573077094668], Loss: 2.390544, Lambda: 0.05, Acc:0.304958, Semantic loss: 0.614703, BCE loss: 1.417168, SB loss: 0.358672\n",
      "Epoch: [4/20] Iter:[30/192], Time: 1.79, lr: [0.008108587112763079], Loss: 2.460239, Lambda: 0.05, Acc:0.310577, Semantic loss: 0.636830, BCE loss: 1.432544, SB loss: 0.390864\n",
      "Epoch: [4/20] Iter:[40/192], Time: 1.76, lr: [0.008084593262188028], Loss: 2.415958, Lambda: 0.05, Acc:0.312482, Semantic loss: 0.629082, BCE loss: 1.413619, SB loss: 0.373257\n",
      "Epoch: [4/20] Iter:[50/192], Time: 1.73, lr: [0.008060591496753653], Loss: 2.442359, Lambda: 0.05, Acc:0.309602, Semantic loss: 0.635108, BCE loss: 1.433009, SB loss: 0.374243\n",
      "Epoch: [4/20] Iter:[60/192], Time: 1.72, lr: [0.008036581787645204], Loss: 2.403354, Lambda: 0.05, Acc:0.312041, Semantic loss: 0.615849, BCE loss: 1.421661, SB loss: 0.365844\n",
      "Epoch: [4/20] Iter:[70/192], Time: 1.71, lr: [0.008012564105846994], Loss: 2.436173, Lambda: 0.05, Acc:0.315104, Semantic loss: 0.642450, BCE loss: 1.423807, SB loss: 0.369916\n",
      "Epoch: [4/20] Iter:[80/192], Time: 1.70, lr: [0.007988538422140333], Loss: 2.450282, Lambda: 0.05, Acc:0.317484, Semantic loss: 0.642581, BCE loss: 1.437498, SB loss: 0.370203\n",
      "Epoch: [4/20] Iter:[90/192], Time: 1.68, lr: [0.007964504707101411], Loss: 2.463283, Lambda: 0.05, Acc:0.317044, Semantic loss: 0.637800, BCE loss: 1.454744, SB loss: 0.370739\n",
      "Epoch: [4/20] Iter:[100/192], Time: 1.67, lr: [0.007940462931099176], Loss: 2.455190, Lambda: 0.05, Acc:0.315607, Semantic loss: 0.633430, BCE loss: 1.455031, SB loss: 0.366729\n",
      "Epoch: [4/20] Iter:[110/192], Time: 1.66, lr: [0.007916413064293163], Loss: 2.452761, Lambda: 0.05, Acc:0.317327, Semantic loss: 0.632685, BCE loss: 1.457145, SB loss: 0.362931\n",
      "Epoch: [4/20] Iter:[120/192], Time: 1.65, lr: [0.007892355076631318], Loss: 2.449880, Lambda: 0.05, Acc:0.318021, Semantic loss: 0.631077, BCE loss: 1.458064, SB loss: 0.360738\n",
      "Epoch: [4/20] Iter:[130/192], Time: 1.65, lr: [0.007868288937847752], Loss: 2.450130, Lambda: 0.05, Acc:0.319345, Semantic loss: 0.628503, BCE loss: 1.463434, SB loss: 0.358194\n",
      "Epoch: [4/20] Iter:[140/192], Time: 1.64, lr: [0.007844214617460508], Loss: 2.452730, Lambda: 0.05, Acc:0.319781, Semantic loss: 0.629418, BCE loss: 1.467722, SB loss: 0.355590\n",
      "Epoch: [4/20] Iter:[150/192], Time: 1.64, lr: [0.007820132084769268], Loss: 2.458636, Lambda: 0.05, Acc:0.320230, Semantic loss: 0.635247, BCE loss: 1.461654, SB loss: 0.361735\n",
      "Epoch: [4/20] Iter:[160/192], Time: 1.64, lr: [0.00779604130885303], Loss: 2.450835, Lambda: 0.05, Acc:0.318335, Semantic loss: 0.631979, BCE loss: 1.458797, SB loss: 0.360059\n",
      "Epoch: [4/20] Iter:[170/192], Time: 1.63, lr: [0.007771942258567773], Loss: 2.451438, Lambda: 0.05, Acc:0.318880, Semantic loss: 0.630641, BCE loss: 1.458198, SB loss: 0.362599\n",
      "Epoch: [4/20] Iter:[180/192], Time: 1.63, lr: [0.007747834902544056], Loss: 2.449333, Lambda: 0.05, Acc:0.321281, Semantic loss: 0.626851, BCE loss: 1.460765, SB loss: 0.361716\n",
      "Epoch: [4/20] Iter:[190/192], Time: 1.62, lr: [0.0077237192091846206], Loss: 2.448117, Lambda: 0.05, Acc:0.321515, Semantic loss: 0.625630, BCE loss: 1.462206, SB loss: 0.360281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.35111407 0.22227051 0.10196262 0.29072394 0.12252538\n",
      " 0.10804339 0.28468707] 0.18516587203503676\n",
      "1 [0.         0.31346029 0.28914445 0.21485418 0.3263551  0.04649909\n",
      " 0.12453234 0.43241369] 0.21840739269757417\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: water (class 4), agriculture (class 7), road (class 3)\n",
      "Loss: 6.192, MeanIU:  0.2184, Best_mIoU:  0.2184\n",
      "Per-class IoUs:\n",
      "  - water (class 4): IoU = 0.3264\n",
      "  - agriculture (class 7): IoU = 0.4324\n",
      "  - road (class 3): IoU = 0.2149\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.31346029 0.28914445 0.21485418 0.3263551  0.04649909\n",
      " 0.12453234 0.43241369]\n",
      "Epoch: [5/20] Iter:[0/192], Time: 7.86, lr: [0.007718895067235705], Loss: 2.637778, Lambda: 0.06, Acc:0.332495, Semantic loss: 0.465497, BCE loss: 1.887144, SB loss: 0.285137\n",
      "Epoch: [5/20] Iter:[10/192], Time: 2.16, lr: [0.007694769327040611], Loss: 2.357514, Lambda: 0.06, Acc:0.377236, Semantic loss: 0.583011, BCE loss: 1.445530, SB loss: 0.328974\n",
      "Epoch: [5/20] Iter:[20/192], Time: 1.87, lr: [0.00767063517918174], Loss: 2.301361, Lambda: 0.06, Acc:0.384485, Semantic loss: 0.568546, BCE loss: 1.410083, SB loss: 0.322732\n",
      "Epoch: [5/20] Iter:[30/192], Time: 1.78, lr: [0.007646492591316132], Loss: 2.328449, Lambda: 0.06, Acc:0.383442, Semantic loss: 0.597024, BCE loss: 1.395050, SB loss: 0.336375\n",
      "Epoch: [5/20] Iter:[40/192], Time: 1.74, lr: [0.007622341530862476], Loss: 2.349763, Lambda: 0.06, Acc:0.396198, Semantic loss: 0.605391, BCE loss: 1.406909, SB loss: 0.337464\n",
      "Epoch: [5/20] Iter:[50/192], Time: 1.71, lr: [0.0075981819649984985], Loss: 2.366427, Lambda: 0.06, Acc:0.399293, Semantic loss: 0.595801, BCE loss: 1.434618, SB loss: 0.336008\n",
      "Epoch: [5/20] Iter:[60/192], Time: 1.68, lr: [0.007574013860658317], Loss: 2.397937, Lambda: 0.06, Acc:0.399644, Semantic loss: 0.592988, BCE loss: 1.474661, SB loss: 0.330287\n",
      "Epoch: [5/20] Iter:[70/192], Time: 1.67, lr: [0.007549837184529776], Loss: 2.399098, Lambda: 0.06, Acc:0.401690, Semantic loss: 0.590791, BCE loss: 1.479899, SB loss: 0.328408\n",
      "Epoch: [5/20] Iter:[80/192], Time: 1.66, lr: [0.0075256519030517215], Loss: 2.392655, Lambda: 0.06, Acc:0.398206, Semantic loss: 0.587666, BCE loss: 1.476632, SB loss: 0.328357\n",
      "Epoch: [5/20] Iter:[90/192], Time: 1.65, lr: [0.007501457982411236], Loss: 2.374250, Lambda: 0.06, Acc:0.394190, Semantic loss: 0.589070, BCE loss: 1.454334, SB loss: 0.330846\n",
      "Epoch: [5/20] Iter:[100/192], Time: 1.65, lr: [0.0074772553885408604], Loss: 2.374497, Lambda: 0.06, Acc:0.394578, Semantic loss: 0.589044, BCE loss: 1.455944, SB loss: 0.329508\n",
      "Epoch: [5/20] Iter:[110/192], Time: 1.64, lr: [0.007453044087115737], Loss: 2.382713, Lambda: 0.06, Acc:0.396165, Semantic loss: 0.587111, BCE loss: 1.463211, SB loss: 0.332391\n",
      "Epoch: [5/20] Iter:[120/192], Time: 1.63, lr: [0.007428824043550734], Loss: 2.383442, Lambda: 0.06, Acc:0.397276, Semantic loss: 0.584619, BCE loss: 1.467308, SB loss: 0.331515\n",
      "Epoch: [5/20] Iter:[130/192], Time: 1.63, lr: [0.007404595222997526], Loss: 2.364175, Lambda: 0.06, Acc:0.398064, Semantic loss: 0.580164, BCE loss: 1.454499, SB loss: 0.329512\n",
      "Epoch: [5/20] Iter:[140/192], Time: 1.63, lr: [0.007380357590341623], Loss: 2.357247, Lambda: 0.06, Acc:0.396703, Semantic loss: 0.574875, BCE loss: 1.453481, SB loss: 0.328891\n",
      "Epoch: [5/20] Iter:[150/192], Time: 1.63, lr: [0.007356111110199354], Loss: 2.366304, Lambda: 0.06, Acc:0.395924, Semantic loss: 0.573830, BCE loss: 1.459947, SB loss: 0.332527\n",
      "Epoch: [5/20] Iter:[160/192], Time: 1.63, lr: [0.00733185574691482], Loss: 2.372602, Lambda: 0.06, Acc:0.397125, Semantic loss: 0.574090, BCE loss: 1.465929, SB loss: 0.332583\n",
      "Epoch: [5/20] Iter:[170/192], Time: 1.62, lr: [0.007307591464556783], Loss: 2.380117, Lambda: 0.06, Acc:0.396882, Semantic loss: 0.576756, BCE loss: 1.469982, SB loss: 0.333379\n",
      "Epoch: [5/20] Iter:[180/192], Time: 1.62, lr: [0.007283318226915514], Loss: 2.378438, Lambda: 0.06, Acc:0.399024, Semantic loss: 0.575564, BCE loss: 1.469404, SB loss: 0.333471\n",
      "Epoch: [5/20] Iter:[190/192], Time: 1.61, lr: [0.007259035997499604], Loss: 2.379304, Lambda: 0.06, Acc:0.399361, Semantic loss: 0.577476, BCE loss: 1.467505, SB loss: 0.334323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.23123025 0.23247137 0.13093429 0.23479527 0.12340072\n",
      " 0.09454293 0.28244779] 0.1662278276246682\n",
      "1 [0.         0.14089937 0.33015988 0.31841467 0.23699074 0.03435847\n",
      " 0.13385197 0.45890838] 0.20669793605884978\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: background (class 1), road (class 3), water (class 4), forest (class 6)\n",
      "Loss: 6.459, MeanIU:  0.2067, Best_mIoU:  0.2184\n",
      "Per-class IoUs:\n",
      "  - background (class 1): IoU = 0.1409\n",
      "  - road (class 3): IoU = 0.3184\n",
      "  - water (class 4): IoU = 0.2370\n",
      "  - forest (class 6): IoU = 0.1339\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.14089937 0.33015988 0.31841467 0.23699074 0.03435847\n",
      " 0.13385197 0.45890838]\n",
      "Epoch: [6/20] Iter:[0/192], Time: 7.47, lr: [0.007254178469372199], Loss: 2.172410, Lambda: 0.07, Acc:0.327184, Semantic loss: 0.542242, BCE loss: 1.325667, SB loss: 0.304501\n",
      "Epoch: [6/20] Iter:[10/192], Time: 2.10, lr: [0.007229885401256642], Loss: 2.310906, Lambda: 0.07, Acc:0.355481, Semantic loss: 0.563392, BCE loss: 1.402253, SB loss: 0.345261\n",
      "Epoch: [6/20] Iter:[20/192], Time: 1.81, lr: [0.0072055832600777334], Loss: 2.354925, Lambda: 0.07, Acc:0.351625, Semantic loss: 0.601581, BCE loss: 1.389056, SB loss: 0.364288\n",
      "Epoch: [6/20] Iter:[30/192], Time: 1.74, lr: [0.007181272008420604], Loss: 2.377025, Lambda: 0.07, Acc:0.350288, Semantic loss: 0.596225, BCE loss: 1.399872, SB loss: 0.380928\n",
      "Epoch: [6/20] Iter:[40/192], Time: 1.69, lr: [0.007156951608574727], Loss: 2.367262, Lambda: 0.07, Acc:0.358413, Semantic loss: 0.591857, BCE loss: 1.394805, SB loss: 0.380600\n",
      "Epoch: [6/20] Iter:[50/192], Time: 1.67, lr: [0.007132622022530447], Loss: 2.374561, Lambda: 0.07, Acc:0.355772, Semantic loss: 0.583573, BCE loss: 1.416219, SB loss: 0.374769\n",
      "Epoch: [6/20] Iter:[60/192], Time: 1.64, lr: [0.007108283211975477], Loss: 2.362126, Lambda: 0.07, Acc:0.354830, Semantic loss: 0.584901, BCE loss: 1.411069, SB loss: 0.366156\n",
      "Epoch: [6/20] Iter:[70/192], Time: 1.64, lr: [0.007083935138291319], Loss: 2.371626, Lambda: 0.07, Acc:0.358168, Semantic loss: 0.579659, BCE loss: 1.429014, SB loss: 0.362953\n",
      "Epoch: [6/20] Iter:[80/192], Time: 1.63, lr: [0.007059577762549636], Loss: 2.388961, Lambda: 0.07, Acc:0.359649, Semantic loss: 0.579280, BCE loss: 1.450393, SB loss: 0.359288\n",
      "Epoch: [6/20] Iter:[90/192], Time: 1.62, lr: [0.007035211045508576], Loss: 2.371150, Lambda: 0.07, Acc:0.359920, Semantic loss: 0.571902, BCE loss: 1.445436, SB loss: 0.353813\n",
      "Epoch: [6/20] Iter:[100/192], Time: 1.62, lr: [0.0070108349476090265], Loss: 2.367987, Lambda: 0.07, Acc:0.360171, Semantic loss: 0.570445, BCE loss: 1.447940, SB loss: 0.349601\n",
      "Epoch: [6/20] Iter:[110/192], Time: 1.61, lr: [0.00698644942897081], Loss: 2.370106, Lambda: 0.07, Acc:0.362602, Semantic loss: 0.573317, BCE loss: 1.445189, SB loss: 0.351599\n",
      "Epoch: [6/20] Iter:[120/192], Time: 1.61, lr: [0.006962054449388827], Loss: 2.384388, Lambda: 0.07, Acc:0.363531, Semantic loss: 0.575789, BCE loss: 1.457752, SB loss: 0.350847\n",
      "Epoch: [6/20] Iter:[130/192], Time: 1.61, lr: [0.006937649968329135], Loss: 2.378981, Lambda: 0.07, Acc:0.361473, Semantic loss: 0.577732, BCE loss: 1.450548, SB loss: 0.350700\n",
      "Epoch: [6/20] Iter:[140/192], Time: 1.61, lr: [0.006913235944924954], Loss: 2.370013, Lambda: 0.07, Acc:0.362735, Semantic loss: 0.576620, BCE loss: 1.445468, SB loss: 0.347925\n",
      "Epoch: [6/20] Iter:[150/192], Time: 1.61, lr: [0.006888812337972621], Loss: 2.372880, Lambda: 0.07, Acc:0.362201, Semantic loss: 0.576520, BCE loss: 1.447958, SB loss: 0.348402\n",
      "Epoch: [6/20] Iter:[160/192], Time: 1.61, lr: [0.00686437910592748], Loss: 2.368620, Lambda: 0.07, Acc:0.363967, Semantic loss: 0.572106, BCE loss: 1.451281, SB loss: 0.345232\n",
      "Epoch: [6/20] Iter:[170/192], Time: 1.60, lr: [0.00683993620689969], Loss: 2.371416, Lambda: 0.07, Acc:0.365167, Semantic loss: 0.567160, BCE loss: 1.460175, SB loss: 0.344082\n",
      "Epoch: [6/20] Iter:[180/192], Time: 1.60, lr: [0.0068154835986499775], Loss: 2.363586, Lambda: 0.07, Acc:0.364424, Semantic loss: 0.565644, BCE loss: 1.456394, SB loss: 0.341547\n",
      "Epoch: [6/20] Iter:[190/192], Time: 1.60, lr: [0.006791021238585323], Loss: 2.362582, Lambda: 0.07, Acc:0.365102, Semantic loss: 0.562742, BCE loss: 1.458757, SB loss: 0.341084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.28620601 0.2379471  0.12906605 0.28425671 0.10553994\n",
      " 0.10900423 0.32180176] 0.1842277252742639\n",
      "1 [0.         0.21625436 0.30093031 0.31384786 0.27109128 0.03197119\n",
      " 0.16149472 0.46448889] 0.220009827409817\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: forest (class 6), background (class 1), road (class 3), agriculture (class 7)\n",
      "Loss: 6.365, MeanIU:  0.2200, Best_mIoU:  0.2200\n",
      "Per-class IoUs:\n",
      "  - forest (class 6): IoU = 0.1615\n",
      "  - background (class 1): IoU = 0.2163\n",
      "  - road (class 3): IoU = 0.3138\n",
      "  - agriculture (class 7): IoU = 0.4645\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.21625436 0.30093031 0.31384786 0.27109128 0.03197119\n",
      " 0.16149472 0.46448889]\n",
      "Epoch: [7/20] Iter:[0/192], Time: 6.80, lr: [0.006786127592581251], Loss: 2.308677, Lambda: 0.08, Acc:0.351746, Semantic loss: 0.450072, BCE loss: 1.616953, SB loss: 0.241652\n",
      "Epoch: [7/20] Iter:[10/192], Time: 2.08, lr: [0.006761653473611295], Loss: 2.228637, Lambda: 0.08, Acc:0.384205, Semantic loss: 0.498507, BCE loss: 1.462217, SB loss: 0.267913\n",
      "Epoch: [7/20] Iter:[20/192], Time: 1.84, lr: [0.006737169507854796], Loss: 2.195579, Lambda: 0.08, Acc:0.384231, Semantic loss: 0.494513, BCE loss: 1.413724, SB loss: 0.287343\n",
      "Epoch: [7/20] Iter:[30/192], Time: 1.78, lr: [0.006712675651556858], Loss: 2.195619, Lambda: 0.08, Acc:0.370123, Semantic loss: 0.523517, BCE loss: 1.358737, SB loss: 0.313365\n",
      "Epoch: [7/20] Iter:[40/192], Time: 1.73, lr: [0.006688171860589905], Loss: 2.213158, Lambda: 0.08, Acc:0.372795, Semantic loss: 0.533027, BCE loss: 1.365172, SB loss: 0.314958\n",
      "Epoch: [7/20] Iter:[50/192], Time: 1.71, lr: [0.0066636580904489585], Loss: 2.237988, Lambda: 0.08, Acc:0.379266, Semantic loss: 0.533227, BCE loss: 1.389770, SB loss: 0.314990\n",
      "Epoch: [7/20] Iter:[60/192], Time: 1.69, lr: [0.006639134296246874], Loss: 2.262307, Lambda: 0.08, Acc:0.376365, Semantic loss: 0.530134, BCE loss: 1.413107, SB loss: 0.319066\n",
      "Epoch: [7/20] Iter:[70/192], Time: 1.67, lr: [0.0066146004327094585], Loss: 2.285425, Lambda: 0.08, Acc:0.369273, Semantic loss: 0.536541, BCE loss: 1.426209, SB loss: 0.322674\n",
      "Epoch: [7/20] Iter:[80/192], Time: 1.66, lr: [0.006590056454170537], Loss: 2.305718, Lambda: 0.08, Acc:0.370462, Semantic loss: 0.537451, BCE loss: 1.446370, SB loss: 0.321897\n",
      "Epoch: [7/20] Iter:[90/192], Time: 1.66, lr: [0.006565502314566912], Loss: 2.303674, Lambda: 0.08, Acc:0.374248, Semantic loss: 0.534441, BCE loss: 1.448132, SB loss: 0.321102\n",
      "Epoch: [7/20] Iter:[100/192], Time: 1.65, lr: [0.006540937967433255], Loss: 2.319027, Lambda: 0.08, Acc:0.376583, Semantic loss: 0.532602, BCE loss: 1.464875, SB loss: 0.321550\n",
      "Epoch: [7/20] Iter:[110/192], Time: 1.65, lr: [0.006516363365896894], Loss: 2.321252, Lambda: 0.08, Acc:0.375285, Semantic loss: 0.537442, BCE loss: 1.463151, SB loss: 0.320659\n",
      "Epoch: [7/20] Iter:[120/192], Time: 1.64, lr: [0.006491778462672531], Loss: 2.313188, Lambda: 0.08, Acc:0.373745, Semantic loss: 0.539925, BCE loss: 1.451999, SB loss: 0.321264\n",
      "Epoch: [7/20] Iter:[130/192], Time: 1.63, lr: [0.006467183210056843], Loss: 2.318270, Lambda: 0.08, Acc:0.374143, Semantic loss: 0.545132, BCE loss: 1.450822, SB loss: 0.322315\n",
      "Epoch: [7/20] Iter:[140/192], Time: 1.63, lr: [0.006442577559923017], Loss: 2.321950, Lambda: 0.08, Acc:0.373065, Semantic loss: 0.549521, BCE loss: 1.452150, SB loss: 0.320280\n",
      "Epoch: [7/20] Iter:[150/192], Time: 1.63, lr: [0.006417961463715172], Loss: 2.333628, Lambda: 0.08, Acc:0.375340, Semantic loss: 0.549103, BCE loss: 1.461757, SB loss: 0.322769\n",
      "Epoch: [7/20] Iter:[160/192], Time: 1.62, lr: [0.006393334872442681], Loss: 2.329942, Lambda: 0.08, Acc:0.374286, Semantic loss: 0.549296, BCE loss: 1.456359, SB loss: 0.324287\n",
      "Epoch: [7/20] Iter:[170/192], Time: 1.62, lr: [0.006368697736674411], Loss: 2.339378, Lambda: 0.08, Acc:0.373311, Semantic loss: 0.548103, BCE loss: 1.466353, SB loss: 0.324922\n",
      "Epoch: [7/20] Iter:[180/192], Time: 1.62, lr: [0.006344050006532848], Loss: 2.350710, Lambda: 0.08, Acc:0.375885, Semantic loss: 0.552171, BCE loss: 1.467039, SB loss: 0.331500\n",
      "Epoch: [7/20] Iter:[190/192], Time: 1.61, lr: [0.006319391631688114], Loss: 2.336550, Lambda: 0.08, Acc:0.376109, Semantic loss: 0.550591, BCE loss: 1.457916, SB loss: 0.328043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.32711942 0.21899845 0.12747384 0.30603059 0.12305499\n",
      " 0.09942641 0.27754422] 0.18495599049967062\n",
      "1 [0.         0.34234728 0.29259618 0.27997259 0.34926819 0.04919593\n",
      " 0.15175716 0.44614678] 0.23891051445734912\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: agriculture (class 7), forest (class 6), water (class 4), building (class 2)\n",
      "Loss: 6.018, MeanIU:  0.2389, Best_mIoU:  0.2389\n",
      "Per-class IoUs:\n",
      "  - agriculture (class 7): IoU = 0.4461\n",
      "  - forest (class 6): IoU = 0.1518\n",
      "  - water (class 4): IoU = 0.3493\n",
      "  - building (class 2): IoU = 0.2926\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.34234728 0.29259618 0.27997259 0.34926819 0.04919593\n",
      " 0.15175716 0.44614678]\n",
      "Epoch: [8/20] Iter:[0/192], Time: 6.92, lr: [0.006314458674893553], Loss: 2.357290, Lambda: 0.09, Acc:0.349503, Semantic loss: 0.466410, BCE loss: 1.635670, SB loss: 0.255210\n",
      "Epoch: [8/20] Iter:[10/192], Time: 2.10, lr: [0.006289787459323657], Loss: 2.328232, Lambda: 0.09, Acc:0.376668, Semantic loss: 0.546079, BCE loss: 1.484172, SB loss: 0.297981\n",
      "Epoch: [8/20] Iter:[20/192], Time: 1.85, lr: [0.006265105486702424], Loss: 2.347597, Lambda: 0.09, Acc:0.386304, Semantic loss: 0.550584, BCE loss: 1.483449, SB loss: 0.313565\n",
      "Epoch: [8/20] Iter:[30/192], Time: 1.76, lr: [0.006240412705211017], Loss: 2.302335, Lambda: 0.09, Acc:0.394739, Semantic loss: 0.535679, BCE loss: 1.466465, SB loss: 0.300191\n",
      "Epoch: [8/20] Iter:[40/192], Time: 1.73, lr: [0.006215709062551949], Loss: 2.326403, Lambda: 0.09, Acc:0.386801, Semantic loss: 0.537165, BCE loss: 1.490046, SB loss: 0.299191\n",
      "Epoch: [8/20] Iter:[50/192], Time: 1.70, lr: [0.006190994505942529], Loss: 2.335171, Lambda: 0.09, Acc:0.383480, Semantic loss: 0.545854, BCE loss: 1.487987, SB loss: 0.301330\n",
      "Epoch: [8/20] Iter:[60/192], Time: 1.68, lr: [0.006166268982108192], Loss: 2.334570, Lambda: 0.09, Acc:0.377002, Semantic loss: 0.545426, BCE loss: 1.481392, SB loss: 0.307753\n",
      "Epoch: [8/20] Iter:[70/192], Time: 1.66, lr: [0.006141532437275693], Loss: 2.351878, Lambda: 0.09, Acc:0.376977, Semantic loss: 0.551717, BCE loss: 1.488930, SB loss: 0.311230\n",
      "Epoch: [8/20] Iter:[80/192], Time: 1.65, lr: [0.006116784817166194], Loss: 2.372587, Lambda: 0.09, Acc:0.377311, Semantic loss: 0.560868, BCE loss: 1.494766, SB loss: 0.316954\n",
      "Epoch: [8/20] Iter:[90/192], Time: 1.65, lr: [0.006092026066988214], Loss: 2.377306, Lambda: 0.09, Acc:0.372923, Semantic loss: 0.562312, BCE loss: 1.493634, SB loss: 0.321360\n",
      "Epoch: [8/20] Iter:[100/192], Time: 1.64, lr: [0.006067256131430442], Loss: 2.347508, Lambda: 0.09, Acc:0.372392, Semantic loss: 0.560035, BCE loss: 1.469022, SB loss: 0.318451\n",
      "Epoch: [8/20] Iter:[110/192], Time: 1.63, lr: [0.00604247495465443], Loss: 2.341811, Lambda: 0.09, Acc:0.375092, Semantic loss: 0.561083, BCE loss: 1.459487, SB loss: 0.321240\n",
      "Epoch: [8/20] Iter:[120/192], Time: 1.63, lr: [0.006017682480287143], Loss: 2.361666, Lambda: 0.09, Acc:0.374668, Semantic loss: 0.558024, BCE loss: 1.482761, SB loss: 0.320880\n",
      "Epoch: [8/20] Iter:[130/192], Time: 1.62, lr: [0.00599287865141337], Loss: 2.355467, Lambda: 0.09, Acc:0.373490, Semantic loss: 0.552946, BCE loss: 1.481981, SB loss: 0.320540\n",
      "Epoch: [8/20] Iter:[140/192], Time: 1.62, lr: [0.005968063410567983], Loss: 2.348527, Lambda: 0.09, Acc:0.373183, Semantic loss: 0.546504, BCE loss: 1.481904, SB loss: 0.320119\n",
      "Epoch: [8/20] Iter:[150/192], Time: 1.62, lr: [0.00594323669972807], Loss: 2.354306, Lambda: 0.09, Acc:0.375026, Semantic loss: 0.555544, BCE loss: 1.475873, SB loss: 0.322889\n",
      "Epoch: [8/20] Iter:[160/192], Time: 1.61, lr: [0.005918398460304892], Loss: 2.343747, Lambda: 0.09, Acc:0.375299, Semantic loss: 0.557846, BCE loss: 1.462497, SB loss: 0.323403\n",
      "Epoch: [8/20] Iter:[170/192], Time: 1.61, lr: [0.0058935486331357125], Loss: 2.341738, Lambda: 0.09, Acc:0.374775, Semantic loss: 0.559370, BCE loss: 1.457931, SB loss: 0.324438\n",
      "Epoch: [8/20] Iter:[180/192], Time: 1.61, lr: [0.005868687158475447], Loss: 2.337011, Lambda: 0.09, Acc:0.375297, Semantic loss: 0.560086, BCE loss: 1.453785, SB loss: 0.323141\n",
      "Epoch: [8/20] Iter:[190/192], Time: 1.60, lr: [0.005843813975988169], Loss: 2.335749, Lambda: 0.09, Acc:0.374393, Semantic loss: 0.558298, BCE loss: 1.452197, SB loss: 0.325254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.29114038 0.23837477 0.13706638 0.30900309 0.13350833\n",
      " 0.09957828 0.2840454 ] 0.1865895791824335\n",
      "1 [0.         0.25894441 0.31568245 0.26953015 0.45863041 0.07363205\n",
      " 0.12377445 0.41539123] 0.2394481438301525\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: forest (class 6), barren (class 5), agriculture (class 7), background (class 1)\n",
      "Loss: 6.485, MeanIU:  0.2394, Best_mIoU:  0.2394\n",
      "Per-class IoUs:\n",
      "  - forest (class 6): IoU = 0.1238\n",
      "  - barren (class 5): IoU = 0.0736\n",
      "  - agriculture (class 7): IoU = 0.4154\n",
      "  - background (class 1): IoU = 0.2589\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.25894441 0.31568245 0.26953015 0.45863041 0.07363205\n",
      " 0.12377445 0.41539123]\n",
      "Epoch: [9/20] Iter:[0/192], Time: 6.80, lr: [0.0058388379291998025], Loss: 1.906012, Lambda: 0.10, Acc:0.279027, Semantic loss: 0.414228, BCE loss: 1.236348, SB loss: 0.255436\n",
      "Epoch: [9/20] Iter:[10/192], Time: 2.03, lr: [0.0058139506168319475], Loss: 2.250929, Lambda: 0.10, Acc:0.311503, Semantic loss: 0.472931, BCE loss: 1.495816, SB loss: 0.282181\n",
      "Epoch: [9/20] Iter:[20/192], Time: 1.80, lr: [0.005789051461775303], Loss: 2.257737, Lambda: 0.10, Acc:0.343882, Semantic loss: 0.511437, BCE loss: 1.454585, SB loss: 0.291715\n",
      "Epoch: [9/20] Iter:[30/192], Time: 1.70, lr: [0.005764140401744157], Loss: 2.279729, Lambda: 0.10, Acc:0.355087, Semantic loss: 0.525886, BCE loss: 1.458811, SB loss: 0.295032\n",
      "Epoch: [9/20] Iter:[40/192], Time: 1.67, lr: [0.005739217373824397], Loss: 2.351700, Lambda: 0.10, Acc:0.358345, Semantic loss: 0.534502, BCE loss: 1.504247, SB loss: 0.312951\n",
      "Epoch: [9/20] Iter:[50/192], Time: 1.64, lr: [0.005714282314464109], Loss: 2.347818, Lambda: 0.10, Acc:0.354904, Semantic loss: 0.551395, BCE loss: 1.474695, SB loss: 0.321728\n",
      "Epoch: [9/20] Iter:[60/192], Time: 1.63, lr: [0.005689335159463984], Loss: 2.329245, Lambda: 0.10, Acc:0.347721, Semantic loss: 0.546698, BCE loss: 1.460855, SB loss: 0.321692\n",
      "Epoch: [9/20] Iter:[70/192], Time: 1.62, lr: [0.0056643758439675305], Loss: 2.320944, Lambda: 0.10, Acc:0.351345, Semantic loss: 0.551578, BCE loss: 1.441649, SB loss: 0.327717\n",
      "Epoch: [9/20] Iter:[80/192], Time: 1.62, lr: [0.005639404302451105], Loss: 2.316482, Lambda: 0.10, Acc:0.352972, Semantic loss: 0.546850, BCE loss: 1.443744, SB loss: 0.325888\n",
      "Epoch: [9/20] Iter:[90/192], Time: 1.61, lr: [0.005614420468713722], Loss: 2.315538, Lambda: 0.10, Acc:0.352701, Semantic loss: 0.545303, BCE loss: 1.441641, SB loss: 0.328594\n",
      "Epoch: [9/20] Iter:[100/192], Time: 1.61, lr: [0.005589424275866668], Loss: 2.318168, Lambda: 0.10, Acc:0.351182, Semantic loss: 0.544322, BCE loss: 1.446707, SB loss: 0.327140\n",
      "Epoch: [9/20] Iter:[110/192], Time: 1.61, lr: [0.005564415656322913], Loss: 2.309703, Lambda: 0.10, Acc:0.351647, Semantic loss: 0.542517, BCE loss: 1.440551, SB loss: 0.326634\n",
      "Epoch: [9/20] Iter:[120/192], Time: 1.61, lr: [0.00553939454178628], Loss: 2.313742, Lambda: 0.10, Acc:0.352384, Semantic loss: 0.544404, BCE loss: 1.441348, SB loss: 0.327990\n",
      "Epoch: [9/20] Iter:[130/192], Time: 1.61, lr: [0.005514360863240413], Loss: 2.311532, Lambda: 0.10, Acc:0.353797, Semantic loss: 0.542597, BCE loss: 1.439534, SB loss: 0.329401\n",
      "Epoch: [9/20] Iter:[140/192], Time: 1.60, lr: [0.005489314550937511], Loss: 2.314728, Lambda: 0.10, Acc:0.354703, Semantic loss: 0.542639, BCE loss: 1.443048, SB loss: 0.329042\n",
      "Epoch: [9/20] Iter:[150/192], Time: 1.60, lr: [0.005464255534386825], Loss: 2.323094, Lambda: 0.10, Acc:0.353452, Semantic loss: 0.548725, BCE loss: 1.441457, SB loss: 0.332913\n",
      "Epoch: [9/20] Iter:[160/192], Time: 1.60, lr: [0.005439183742342914], Loss: 2.323340, Lambda: 0.10, Acc:0.354884, Semantic loss: 0.546946, BCE loss: 1.443563, SB loss: 0.332831\n",
      "Epoch: [9/20] Iter:[170/192], Time: 1.59, lr: [0.00541409910279366], Loss: 2.330623, Lambda: 0.10, Acc:0.353374, Semantic loss: 0.553443, BCE loss: 1.442127, SB loss: 0.335053\n",
      "Epoch: [9/20] Iter:[180/192], Time: 1.59, lr: [0.005389001542948025], Loss: 2.334701, Lambda: 0.10, Acc:0.354945, Semantic loss: 0.554442, BCE loss: 1.443531, SB loss: 0.336727\n",
      "Epoch: [9/20] Iter:[190/192], Time: 1.59, lr: [0.005363890989223547], Loss: 2.331405, Lambda: 0.10, Acc:0.356453, Semantic loss: 0.551027, BCE loss: 1.444716, SB loss: 0.335661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.26803211 0.25641175 0.13883664 0.30683738 0.10521279\n",
      " 0.09810074 0.30583528] 0.18490833699835185\n",
      "1 [0.         0.23621568 0.32429774 0.26712413 0.47631423 0.03803373\n",
      " 0.13676752 0.40545545] 0.23552605838598584\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: barren (class 5), background (class 1), forest (class 6)\n",
      "Loss: 6.064, MeanIU:  0.2355, Best_mIoU:  0.2394\n",
      "Per-class IoUs:\n",
      "  - barren (class 5): IoU = 0.0380\n",
      "  - background (class 1): IoU = 0.2362\n",
      "  - forest (class 6): IoU = 0.1368\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.23621568 0.32429774 0.26712413 0.47631423 0.03803373\n",
      " 0.13676752 0.40545545]\n",
      "Epoch: [10/20] Iter:[0/192], Time: 7.21, lr: [0.005358867312681466], Loss: 2.852760, Lambda: 0.11, Acc:0.436622, Semantic loss: 0.666716, BCE loss: 1.886043, SB loss: 0.300001\n",
      "Epoch: [10/20] Iter:[10/192], Time: 2.12, lr: [0.005333741068040314], Loss: 2.542599, Lambda: 0.11, Acc:0.405183, Semantic loss: 0.574787, BCE loss: 1.663626, SB loss: 0.304186\n",
      "Epoch: [10/20] Iter:[20/192], Time: 1.84, lr: [0.0053086016647897714], Loss: 2.402160, Lambda: 0.11, Acc:0.397238, Semantic loss: 0.523650, BCE loss: 1.591504, SB loss: 0.287006\n",
      "Epoch: [10/20] Iter:[30/192], Time: 1.76, lr: [0.005283449026727663], Loss: 2.344854, Lambda: 0.11, Acc:0.403518, Semantic loss: 0.512170, BCE loss: 1.543103, SB loss: 0.289580\n",
      "Epoch: [10/20] Iter:[40/192], Time: 1.71, lr: [0.005258283076804885], Loss: 2.292338, Lambda: 0.11, Acc:0.402061, Semantic loss: 0.512589, BCE loss: 1.494931, SB loss: 0.284819\n",
      "Epoch: [10/20] Iter:[50/192], Time: 1.70, lr: [0.00523310373711144], Loss: 2.267816, Lambda: 0.11, Acc:0.401959, Semantic loss: 0.503873, BCE loss: 1.478037, SB loss: 0.285905\n",
      "Epoch: [10/20] Iter:[60/192], Time: 1.67, lr: [0.005207910928862159], Loss: 2.279686, Lambda: 0.11, Acc:0.402353, Semantic loss: 0.508193, BCE loss: 1.478146, SB loss: 0.293347\n",
      "Epoch: [10/20] Iter:[70/192], Time: 1.66, lr: [0.005182704572382109], Loss: 2.273613, Lambda: 0.11, Acc:0.400150, Semantic loss: 0.514634, BCE loss: 1.458776, SB loss: 0.300203\n",
      "Epoch: [10/20] Iter:[80/192], Time: 1.66, lr: [0.005157484587091684], Loss: 2.264756, Lambda: 0.11, Acc:0.397331, Semantic loss: 0.518597, BCE loss: 1.445493, SB loss: 0.300666\n",
      "Epoch: [10/20] Iter:[90/192], Time: 1.65, lr: [0.005132250891491357], Loss: 2.275859, Lambda: 0.11, Acc:0.405432, Semantic loss: 0.516464, BCE loss: 1.458056, SB loss: 0.301338\n",
      "Epoch: [10/20] Iter:[100/192], Time: 1.64, lr: [0.005107003403146087], Loss: 2.284107, Lambda: 0.11, Acc:0.403852, Semantic loss: 0.519906, BCE loss: 1.459989, SB loss: 0.304212\n",
      "Epoch: [10/20] Iter:[110/192], Time: 1.63, lr: [0.005081742038669388], Loss: 2.277150, Lambda: 0.11, Acc:0.401707, Semantic loss: 0.515990, BCE loss: 1.458432, SB loss: 0.302728\n",
      "Epoch: [10/20] Iter:[120/192], Time: 1.63, lr: [0.005056466713707024], Loss: 2.278203, Lambda: 0.11, Acc:0.401927, Semantic loss: 0.518877, BCE loss: 1.456820, SB loss: 0.302506\n",
      "Epoch: [10/20] Iter:[130/192], Time: 1.63, lr: [0.005031177342920337], Loss: 2.279953, Lambda: 0.11, Acc:0.398616, Semantic loss: 0.517130, BCE loss: 1.458319, SB loss: 0.304504\n",
      "Epoch: [10/20] Iter:[140/192], Time: 1.62, lr: [0.005005873839969192], Loss: 2.286917, Lambda: 0.11, Acc:0.399856, Semantic loss: 0.517630, BCE loss: 1.464517, SB loss: 0.304770\n",
      "Epoch: [10/20] Iter:[150/192], Time: 1.62, lr: [0.00498055611749454], Loss: 2.288035, Lambda: 0.11, Acc:0.400326, Semantic loss: 0.518889, BCE loss: 1.465090, SB loss: 0.304057\n",
      "Epoch: [10/20] Iter:[160/192], Time: 1.62, lr: [0.004955224087100552], Loss: 2.284465, Lambda: 0.11, Acc:0.400903, Semantic loss: 0.521531, BCE loss: 1.458576, SB loss: 0.304358\n",
      "Epoch: [10/20] Iter:[170/192], Time: 1.61, lr: [0.004929877659336362], Loss: 2.284653, Lambda: 0.11, Acc:0.400690, Semantic loss: 0.520815, BCE loss: 1.460884, SB loss: 0.302954\n",
      "Epoch: [10/20] Iter:[180/192], Time: 1.61, lr: [0.004904516743677371], Loss: 2.290635, Lambda: 0.11, Acc:0.401533, Semantic loss: 0.524971, BCE loss: 1.460607, SB loss: 0.305056\n",
      "Epoch: [10/20] Iter:[190/192], Time: 1.61, lr: [0.00487914124850611], Loss: 2.294533, Lambda: 0.11, Acc:0.399318, Semantic loss: 0.525939, BCE loss: 1.462325, SB loss: 0.306269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.377055   0.23172622 0.12689984 0.32730049 0.1228494\n",
      " 0.10733581 0.28919688] 0.19779545469977278\n",
      "1 [0.         0.43775102 0.24879782 0.24483361 0.44841691 0.04953551\n",
      " 0.18292066 0.40088724] 0.25164284657903324\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: water (class 4), barren (class 5), background (class 1), forest (class 6)\n",
      "Loss: 6.321, MeanIU:  0.2516, Best_mIoU:  0.2516\n",
      "Per-class IoUs:\n",
      "  - water (class 4): IoU = 0.4484\n",
      "  - barren (class 5): IoU = 0.0495\n",
      "  - background (class 1): IoU = 0.4378\n",
      "  - forest (class 6): IoU = 0.1829\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.43775102 0.24879782 0.24483361 0.44841691 0.04953551\n",
      " 0.18292066 0.40088724]\n",
      "Epoch: [11/20] Iter:[0/192], Time: 7.22, lr: [0.004874064391789954], Loss: 2.396089, Lambda: 0.12, Acc:0.525367, Semantic loss: 0.797258, BCE loss: 1.221654, SB loss: 0.377177\n",
      "Epoch: [11/20] Iter:[10/192], Time: 2.10, lr: [0.004848671278701159], Loss: 2.383046, Lambda: 0.12, Acc:0.364037, Semantic loss: 0.506451, BCE loss: 1.575533, SB loss: 0.301063\n",
      "Epoch: [11/20] Iter:[20/192], Time: 1.83, lr: [0.0048232633805975296], Loss: 2.232187, Lambda: 0.12, Acc:0.357499, Semantic loss: 0.488134, BCE loss: 1.444831, SB loss: 0.299223\n",
      "Epoch: [11/20] Iter:[30/192], Time: 1.77, lr: [0.00479784060223045], Loss: 2.305390, Lambda: 0.12, Acc:0.373554, Semantic loss: 0.515561, BCE loss: 1.475624, SB loss: 0.314205\n",
      "Epoch: [11/20] Iter:[40/192], Time: 1.72, lr: [0.004772402847172951], Loss: 2.275961, Lambda: 0.12, Acc:0.379897, Semantic loss: 0.522864, BCE loss: 1.433147, SB loss: 0.319950\n",
      "Epoch: [11/20] Iter:[50/192], Time: 1.70, lr: [0.004746950017798064], Loss: 2.278611, Lambda: 0.12, Acc:0.380446, Semantic loss: 0.520718, BCE loss: 1.442120, SB loss: 0.315773\n",
      "Epoch: [11/20] Iter:[60/192], Time: 1.68, lr: [0.004721482015256639], Loss: 2.273992, Lambda: 0.12, Acc:0.382627, Semantic loss: 0.520639, BCE loss: 1.444420, SB loss: 0.308933\n",
      "Epoch: [11/20] Iter:[70/192], Time: 1.66, lr: [0.004695998739454633], Loss: 2.288108, Lambda: 0.12, Acc:0.387574, Semantic loss: 0.530945, BCE loss: 1.449272, SB loss: 0.307892\n",
      "Epoch: [11/20] Iter:[80/192], Time: 1.65, lr: [0.004670500089029817], Loss: 2.288848, Lambda: 0.12, Acc:0.389049, Semantic loss: 0.529412, BCE loss: 1.447904, SB loss: 0.311532\n",
      "Epoch: [11/20] Iter:[90/192], Time: 1.64, lr: [0.004644985961327915], Loss: 2.273107, Lambda: 0.12, Acc:0.389414, Semantic loss: 0.527586, BCE loss: 1.438215, SB loss: 0.307306\n",
      "Epoch: [11/20] Iter:[100/192], Time: 1.63, lr: [0.004619456252378151], Loss: 2.282912, Lambda: 0.12, Acc:0.388113, Semantic loss: 0.523991, BCE loss: 1.451981, SB loss: 0.306940\n",
      "Epoch: [11/20] Iter:[110/192], Time: 1.63, lr: [0.004593910856868159], Loss: 2.269714, Lambda: 0.12, Acc:0.388325, Semantic loss: 0.522787, BCE loss: 1.442594, SB loss: 0.304333\n",
      "Epoch: [11/20] Iter:[120/192], Time: 1.63, lr: [0.004568349668118281], Loss: 2.264826, Lambda: 0.12, Acc:0.390331, Semantic loss: 0.522285, BCE loss: 1.437460, SB loss: 0.305081\n",
      "Epoch: [11/20] Iter:[130/192], Time: 1.63, lr: [0.004542772578055196], Loss: 2.263544, Lambda: 0.12, Acc:0.388518, Semantic loss: 0.524461, BCE loss: 1.431767, SB loss: 0.307316\n",
      "Epoch: [11/20] Iter:[140/192], Time: 1.62, lr: [0.00451717947718487], Loss: 2.276535, Lambda: 0.12, Acc:0.391171, Semantic loss: 0.522426, BCE loss: 1.448039, SB loss: 0.306071\n",
      "Epoch: [11/20] Iter:[150/192], Time: 1.62, lr: [0.004491570254564817], Loss: 2.293764, Lambda: 0.12, Acc:0.390436, Semantic loss: 0.525036, BCE loss: 1.461757, SB loss: 0.306971\n",
      "Epoch: [11/20] Iter:[160/192], Time: 1.62, lr: [0.004465944797775636], Loss: 2.308051, Lambda: 0.12, Acc:0.392709, Semantic loss: 0.529326, BCE loss: 1.470935, SB loss: 0.307790\n",
      "Epoch: [11/20] Iter:[170/192], Time: 1.61, lr: [0.004440302992891796], Loss: 2.299209, Lambda: 0.12, Acc:0.394973, Semantic loss: 0.525874, BCE loss: 1.465731, SB loss: 0.307605\n",
      "Epoch: [11/20] Iter:[180/192], Time: 1.61, lr: [0.004414644724451659], Loss: 2.294686, Lambda: 0.12, Acc:0.395460, Semantic loss: 0.527009, BCE loss: 1.458983, SB loss: 0.308694\n",
      "Epoch: [11/20] Iter:[190/192], Time: 1.60, lr: [0.004388969875426714], Loss: 2.308074, Lambda: 0.12, Acc:0.395235, Semantic loss: 0.532722, BCE loss: 1.464683, SB loss: 0.310669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.37835714 0.23706386 0.1261536  0.30238663 0.13651339\n",
      " 0.10089213 0.27981236] 0.19514738815287475\n",
      "1 [0.         0.49597065 0.24402604 0.23918296 0.43181164 0.08868706\n",
      " 0.14557901 0.37094453] 0.25202523722492526\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: building (class 2), water (class 4), forest (class 6)\n",
      "Loss: 6.072, MeanIU:  0.2520, Best_mIoU:  0.2520\n",
      "Per-class IoUs:\n",
      "  - building (class 2): IoU = 0.2440\n",
      "  - water (class 4): IoU = 0.4318\n",
      "  - forest (class 6): IoU = 0.1456\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.49597065 0.24402604 0.23918296 0.43181164 0.08868706\n",
      " 0.14557901 0.37094453]\n",
      "Epoch: [12/20] Iter:[0/192], Time: 6.47, lr: [0.0043838329055408696], Loss: 2.687834, Lambda: 0.13, Acc:0.350910, Semantic loss: 0.507260, BCE loss: 1.824873, SB loss: 0.355701\n",
      "Epoch: [12/20] Iter:[10/192], Time: 2.08, lr: [0.004358138003083593], Loss: 2.384751, Lambda: 0.13, Acc:0.354195, Semantic loss: 0.540255, BCE loss: 1.506987, SB loss: 0.337509\n",
      "Epoch: [12/20] Iter:[20/192], Time: 1.85, lr: [0.0043324262569064236], Loss: 2.359158, Lambda: 0.13, Acc:0.373002, Semantic loss: 0.554809, BCE loss: 1.474632, SB loss: 0.329717\n",
      "Epoch: [12/20] Iter:[30/192], Time: 1.76, lr: [0.0043066975447503065], Loss: 2.357063, Lambda: 0.13, Acc:0.367806, Semantic loss: 0.546646, BCE loss: 1.467626, SB loss: 0.342792\n",
      "Epoch: [12/20] Iter:[40/192], Time: 1.71, lr: [0.00428095174265078], Loss: 2.379020, Lambda: 0.13, Acc:0.367239, Semantic loss: 0.558445, BCE loss: 1.474758, SB loss: 0.345817\n",
      "Epoch: [12/20] Iter:[50/192], Time: 1.70, lr: [0.004255188724902623], Loss: 2.404540, Lambda: 0.13, Acc:0.363506, Semantic loss: 0.554904, BCE loss: 1.509582, SB loss: 0.340053\n",
      "Epoch: [12/20] Iter:[60/192], Time: 1.67, lr: [0.004229408364023519], Loss: 2.372277, Lambda: 0.13, Acc:0.365334, Semantic loss: 0.547448, BCE loss: 1.492468, SB loss: 0.332361\n",
      "Epoch: [12/20] Iter:[70/192], Time: 1.66, lr: [0.004203610530716726], Loss: 2.369359, Lambda: 0.13, Acc:0.365446, Semantic loss: 0.544812, BCE loss: 1.496956, SB loss: 0.327591\n",
      "Epoch: [12/20] Iter:[80/192], Time: 1.64, lr: [0.004177795093832693], Loss: 2.341656, Lambda: 0.13, Acc:0.367793, Semantic loss: 0.540183, BCE loss: 1.477893, SB loss: 0.323580\n",
      "Epoch: [12/20] Iter:[90/192], Time: 1.63, lr: [0.004151961920329593], Loss: 2.337751, Lambda: 0.13, Acc:0.364643, Semantic loss: 0.541633, BCE loss: 1.468014, SB loss: 0.328104\n",
      "Epoch: [12/20] Iter:[100/192], Time: 1.63, lr: [0.004126110875232744], Loss: 2.330308, Lambda: 0.13, Acc:0.365289, Semantic loss: 0.534757, BCE loss: 1.470121, SB loss: 0.325430\n",
      "Epoch: [12/20] Iter:[110/192], Time: 1.62, lr: [0.004100241821592866], Loss: 2.327078, Lambda: 0.13, Acc:0.365684, Semantic loss: 0.537899, BCE loss: 1.461133, SB loss: 0.328046\n",
      "Epoch: [12/20] Iter:[120/192], Time: 1.62, lr: [0.00407435462044314], Loss: 2.319309, Lambda: 0.13, Acc:0.368998, Semantic loss: 0.540901, BCE loss: 1.451726, SB loss: 0.326682\n",
      "Epoch: [12/20] Iter:[130/192], Time: 1.62, lr: [0.004048449130755016], Loss: 2.323269, Lambda: 0.13, Acc:0.371856, Semantic loss: 0.541127, BCE loss: 1.454242, SB loss: 0.327899\n",
      "Epoch: [12/20] Iter:[140/192], Time: 1.62, lr: [0.004022525209392749], Loss: 2.320385, Lambda: 0.13, Acc:0.370606, Semantic loss: 0.540392, BCE loss: 1.450266, SB loss: 0.329726\n",
      "Epoch: [12/20] Iter:[150/192], Time: 1.62, lr: [0.003996582711066572], Loss: 2.317915, Lambda: 0.13, Acc:0.371591, Semantic loss: 0.540805, BCE loss: 1.448368, SB loss: 0.328742\n",
      "Epoch: [12/20] Iter:[160/192], Time: 1.61, lr: [0.003970621488284514], Loss: 2.321097, Lambda: 0.13, Acc:0.374200, Semantic loss: 0.541385, BCE loss: 1.452254, SB loss: 0.327458\n",
      "Epoch: [12/20] Iter:[170/192], Time: 1.61, lr: [0.003944641391302759], Loss: 2.325141, Lambda: 0.13, Acc:0.373044, Semantic loss: 0.541434, BCE loss: 1.456338, SB loss: 0.327370\n",
      "Epoch: [12/20] Iter:[180/192], Time: 1.61, lr: [0.003918642268074522], Loss: 2.322353, Lambda: 0.13, Acc:0.373239, Semantic loss: 0.543952, BCE loss: 1.449349, SB loss: 0.329052\n",
      "Epoch: [12/20] Iter:[190/192], Time: 1.60, lr: [0.003892623964197378], Loss: 2.315946, Lambda: 0.13, Acc:0.375574, Semantic loss: 0.540268, BCE loss: 1.448411, SB loss: 0.327267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.29448414 0.27108494 0.15713863 0.31584041 0.14345716\n",
      " 0.09177662 0.3115229 ] 0.19816309790767195\n",
      "1 [0.         0.48227488 0.26929203 0.31616372 0.5136159  0.11016473\n",
      " 0.11425207 0.42861312] 0.2792970569033399\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: water (class 4), building (class 2), road (class 3)\n",
      "Loss: 6.246, MeanIU:  0.2793, Best_mIoU:  0.2793\n",
      "Per-class IoUs:\n",
      "  - water (class 4): IoU = 0.5136\n",
      "  - building (class 2): IoU = 0.2693\n",
      "  - road (class 3): IoU = 0.3162\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.48227488 0.26929203 0.31616372 0.5136159  0.11016473\n",
      " 0.11425207 0.42861312]\n",
      "Epoch: [13/20] Iter:[0/192], Time: 7.12, lr: [0.0038874179879876346], Loss: 2.307279, Lambda: 0.14, Acc:0.461842, Semantic loss: 0.547704, BCE loss: 1.383177, SB loss: 0.376399\n",
      "Epoch: [13/20] Iter:[10/192], Time: 2.11, lr: [0.003861376460123532], Loss: 2.251761, Lambda: 0.14, Acc:0.405249, Semantic loss: 0.458637, BCE loss: 1.507232, SB loss: 0.285892\n",
      "Epoch: [13/20] Iter:[20/192], Time: 1.89, lr: [0.003835315403363414], Loss: 2.358599, Lambda: 0.14, Acc:0.390629, Semantic loss: 0.502963, BCE loss: 1.561513, SB loss: 0.294124\n",
      "Epoch: [13/20] Iter:[30/192], Time: 1.78, lr: [0.00380923465539378], Loss: 2.350530, Lambda: 0.14, Acc:0.390505, Semantic loss: 0.515899, BCE loss: 1.536955, SB loss: 0.297676\n",
      "Epoch: [13/20] Iter:[40/192], Time: 1.72, lr: [0.0037831340513060203], Loss: 2.332743, Lambda: 0.14, Acc:0.385936, Semantic loss: 0.508629, BCE loss: 1.522051, SB loss: 0.302063\n",
      "Epoch: [13/20] Iter:[50/192], Time: 1.68, lr: [0.003757013423534689], Loss: 2.311086, Lambda: 0.14, Acc:0.379273, Semantic loss: 0.507403, BCE loss: 1.498956, SB loss: 0.304727\n",
      "Epoch: [13/20] Iter:[60/192], Time: 1.67, lr: [0.003730872601793835], Loss: 2.303510, Lambda: 0.14, Acc:0.382122, Semantic loss: 0.508261, BCE loss: 1.489021, SB loss: 0.306228\n",
      "Epoch: [13/20] Iter:[70/192], Time: 1.66, lr: [0.0037047114130112895], Loss: 2.311796, Lambda: 0.14, Acc:0.385397, Semantic loss: 0.512570, BCE loss: 1.486039, SB loss: 0.313187\n",
      "Epoch: [13/20] Iter:[80/192], Time: 1.65, lr: [0.0036785296812608405], Loss: 2.318192, Lambda: 0.14, Acc:0.382812, Semantic loss: 0.510083, BCE loss: 1.496095, SB loss: 0.312014\n",
      "Epoch: [13/20] Iter:[90/192], Time: 1.64, lr: [0.003652327227692201], Loss: 2.318280, Lambda: 0.14, Acc:0.379643, Semantic loss: 0.519493, BCE loss: 1.487529, SB loss: 0.311258\n",
      "Epoch: [13/20] Iter:[100/192], Time: 1.63, lr: [0.0036261038704587037], Loss: 2.309447, Lambda: 0.14, Acc:0.379966, Semantic loss: 0.521299, BCE loss: 1.474892, SB loss: 0.313256\n",
      "Epoch: [13/20] Iter:[110/192], Time: 1.63, lr: [0.003599859424642584], Loss: 2.306855, Lambda: 0.14, Acc:0.382432, Semantic loss: 0.519358, BCE loss: 1.473226, SB loss: 0.314271\n",
      "Epoch: [13/20] Iter:[120/192], Time: 1.62, lr: [0.0035735937021778063], Loss: 2.313342, Lambda: 0.14, Acc:0.381265, Semantic loss: 0.521221, BCE loss: 1.475911, SB loss: 0.316210\n",
      "Epoch: [13/20] Iter:[130/192], Time: 1.62, lr: [0.0035473065117702885], Loss: 2.310909, Lambda: 0.14, Acc:0.381998, Semantic loss: 0.519477, BCE loss: 1.476191, SB loss: 0.315241\n",
      "Epoch: [13/20] Iter:[140/192], Time: 1.61, lr: [0.003520997658815433], Loss: 2.302837, Lambda: 0.14, Acc:0.381591, Semantic loss: 0.519397, BCE loss: 1.467229, SB loss: 0.316212\n",
      "Epoch: [13/20] Iter:[150/192], Time: 1.61, lr: [0.003494666945312851], Loss: 2.308780, Lambda: 0.14, Acc:0.382244, Semantic loss: 0.521514, BCE loss: 1.470620, SB loss: 0.316646\n",
      "Epoch: [13/20] Iter:[160/192], Time: 1.61, lr: [0.00346831416977816], Loss: 2.309472, Lambda: 0.14, Acc:0.381886, Semantic loss: 0.523317, BCE loss: 1.467367, SB loss: 0.318789\n",
      "Epoch: [13/20] Iter:[170/192], Time: 1.61, lr: [0.003441939127151716], Loss: 2.302314, Lambda: 0.14, Acc:0.380885, Semantic loss: 0.527378, BCE loss: 1.454759, SB loss: 0.320177\n",
      "Epoch: [13/20] Iter:[180/192], Time: 1.61, lr: [0.0034155416087041646], Loss: 2.309366, Lambda: 0.14, Acc:0.380272, Semantic loss: 0.530668, BCE loss: 1.456168, SB loss: 0.322529\n",
      "Epoch: [13/20] Iter:[190/192], Time: 1.60, lr: [0.0033891214019386652], Loss: 2.308775, Lambda: 0.14, Acc:0.381047, Semantic loss: 0.534858, BCE loss: 1.449754, SB loss: 0.324163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.31699385 0.28442114 0.1541779  0.31912245 0.11883265\n",
      " 0.09639398 0.30647425] 0.1995520286465553\n",
      "1 [0.         0.47598485 0.34743552 0.25835029 0.49950307 0.06017222\n",
      " 0.10618635 0.41949803] 0.27089129208504437\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: road (class 3), forest (class 6), building (class 2)\n",
      "Loss: 6.420, MeanIU:  0.2709, Best_mIoU:  0.2793\n",
      "Per-class IoUs:\n",
      "  - road (class 3): IoU = 0.2584\n",
      "  - forest (class 6): IoU = 0.1062\n",
      "  - building (class 2): IoU = 0.3474\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.47598485 0.34743552 0.25835029 0.49950307 0.06017222\n",
      " 0.10618635 0.41949803]\n",
      "Epoch: [14/20] Iter:[0/192], Time: 6.82, lr: [0.0033838346190164987], Loss: 1.967713, Lambda: 0.15, Acc:0.393735, Semantic loss: 0.468927, BCE loss: 1.167320, SB loss: 0.331466\n",
      "Epoch: [14/20] Iter:[10/192], Time: 2.11, lr: [0.0033573869003190927], Loss: 2.107591, Lambda: 0.15, Acc:0.407448, Semantic loss: 0.531361, BCE loss: 1.260918, SB loss: 0.315312\n",
      "Epoch: [14/20] Iter:[20/192], Time: 1.82, lr: [0.0033309160120447595], Loss: 2.238278, Lambda: 0.15, Acc:0.416105, Semantic loss: 0.522195, BCE loss: 1.405990, SB loss: 0.310093\n",
      "Epoch: [14/20] Iter:[30/192], Time: 1.75, lr: [0.0033044217289421207], Loss: 2.286531, Lambda: 0.15, Acc:0.413226, Semantic loss: 0.540329, BCE loss: 1.422854, SB loss: 0.323348\n",
      "Epoch: [14/20] Iter:[40/192], Time: 1.71, lr: [0.0032779038215418194], Loss: 2.263808, Lambda: 0.15, Acc:0.409272, Semantic loss: 0.527201, BCE loss: 1.418024, SB loss: 0.318584\n",
      "Epoch: [14/20] Iter:[50/192], Time: 1.70, lr: [0.0032513620560388795], Loss: 2.273299, Lambda: 0.15, Acc:0.404196, Semantic loss: 0.524330, BCE loss: 1.423361, SB loss: 0.325607\n",
      "Epoch: [14/20] Iter:[60/192], Time: 1.68, lr: [0.003224796194170671], Loss: 2.297807, Lambda: 0.15, Acc:0.408400, Semantic loss: 0.519875, BCE loss: 1.452244, SB loss: 0.325689\n",
      "Epoch: [14/20] Iter:[70/192], Time: 1.66, lr: [0.003198205993090303], Loss: 2.308259, Lambda: 0.15, Acc:0.410158, Semantic loss: 0.533556, BCE loss: 1.446538, SB loss: 0.328164\n",
      "Epoch: [14/20] Iter:[80/192], Time: 1.65, lr: [0.0031715912052352204], Loss: 2.314052, Lambda: 0.15, Acc:0.404974, Semantic loss: 0.532214, BCE loss: 1.448460, SB loss: 0.333379\n",
      "Epoch: [14/20] Iter:[90/192], Time: 1.65, lr: [0.0031449515781907557], Loss: 2.307599, Lambda: 0.15, Acc:0.403975, Semantic loss: 0.531728, BCE loss: 1.443992, SB loss: 0.331880\n",
      "Epoch: [14/20] Iter:[100/192], Time: 1.64, lr: [0.003118286854548424], Loss: 2.298855, Lambda: 0.15, Acc:0.400464, Semantic loss: 0.531220, BCE loss: 1.436396, SB loss: 0.331239\n",
      "Epoch: [14/20] Iter:[110/192], Time: 1.64, lr: [0.003091596771758693], Loss: 2.285631, Lambda: 0.15, Acc:0.402855, Semantic loss: 0.525701, BCE loss: 1.434003, SB loss: 0.325928\n",
      "Epoch: [14/20] Iter:[120/192], Time: 1.63, lr: [0.0030648810619779434], Loss: 2.287302, Lambda: 0.15, Acc:0.402114, Semantic loss: 0.527525, BCE loss: 1.433563, SB loss: 0.326214\n",
      "Epoch: [14/20] Iter:[130/192], Time: 1.63, lr: [0.0030381394519093602], Loss: 2.292989, Lambda: 0.15, Acc:0.401815, Semantic loss: 0.528511, BCE loss: 1.440815, SB loss: 0.323664\n",
      "Epoch: [14/20] Iter:[140/192], Time: 1.63, lr: [0.0030113716626374316], Loss: 2.299042, Lambda: 0.15, Acc:0.402760, Semantic loss: 0.527650, BCE loss: 1.449665, SB loss: 0.321727\n",
      "Epoch: [14/20] Iter:[150/192], Time: 1.62, lr: [0.0029845774094557345], Loss: 2.296462, Lambda: 0.15, Acc:0.403304, Semantic loss: 0.523458, BCE loss: 1.453326, SB loss: 0.319679\n",
      "Epoch: [14/20] Iter:[160/192], Time: 1.62, lr: [0.002957756401687678], Loss: 2.297868, Lambda: 0.15, Acc:0.404731, Semantic loss: 0.521257, BCE loss: 1.458279, SB loss: 0.318331\n",
      "Epoch: [14/20] Iter:[170/192], Time: 1.62, lr: [0.002930908342499829], Loss: 2.303708, Lambda: 0.15, Acc:0.404001, Semantic loss: 0.526990, BCE loss: 1.457349, SB loss: 0.319370\n",
      "Epoch: [14/20] Iter:[180/192], Time: 1.62, lr: [0.002904032928707437], Loss: 2.301008, Lambda: 0.15, Acc:0.402711, Semantic loss: 0.526719, BCE loss: 1.455912, SB loss: 0.318377\n",
      "Epoch: [14/20] Iter:[190/192], Time: 1.61, lr: [0.0028771298505717554], Loss: 2.311233, Lambda: 0.15, Acc:0.402753, Semantic loss: 0.527614, BCE loss: 1.464446, SB loss: 0.319172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.31229405 0.28611563 0.15560014 0.30927499 0.14014337\n",
      " 0.09366085 0.31909855] 0.202023446427881\n",
      "1 [0.         0.49847783 0.29032194 0.26082027 0.50351326 0.09876618\n",
      " 0.08732063 0.40962778] 0.26860598600158503\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: barren (class 5), background (class 1), water (class 4)\n",
      "Loss: 6.658, MeanIU:  0.2686, Best_mIoU:  0.2793\n",
      "Per-class IoUs:\n",
      "  - barren (class 5): IoU = 0.0988\n",
      "  - background (class 1): IoU = 0.4985\n",
      "  - water (class 4): IoU = 0.5035\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.49847783 0.29032194 0.26082027 0.50351326 0.09876618\n",
      " 0.08732063 0.40962778]\n",
      "Epoch: [15/20] Iter:[0/192], Time: 6.95, lr: [0.0028717458874925874], Loss: 2.225503, Lambda: 0.16, Acc:0.401911, Semantic loss: 0.559561, BCE loss: 1.345059, SB loss: 0.320883\n",
      "Epoch: [15/20] Iter:[10/192], Time: 2.07, lr: [0.0028448091937488323], Loss: 2.368187, Lambda: 0.16, Acc:0.401620, Semantic loss: 0.560437, BCE loss: 1.447956, SB loss: 0.359794\n",
      "Epoch: [15/20] Iter:[20/192], Time: 1.81, lr: [0.002817844130111582], Loss: 2.392508, Lambda: 0.16, Acc:0.371261, Semantic loss: 0.560537, BCE loss: 1.483773, SB loss: 0.348198\n",
      "Epoch: [15/20] Iter:[30/192], Time: 1.75, lr: [0.0027908503644035994], Loss: 2.356152, Lambda: 0.16, Acc:0.373822, Semantic loss: 0.565795, BCE loss: 1.438024, SB loss: 0.352333\n",
      "Epoch: [15/20] Iter:[40/192], Time: 1.71, lr: [0.0027638275569424097], Loss: 2.367888, Lambda: 0.16, Acc:0.381218, Semantic loss: 0.561219, BCE loss: 1.459339, SB loss: 0.347331\n",
      "Epoch: [15/20] Iter:[50/192], Time: 1.70, lr: [0.002736775360287257], Loss: 2.376432, Lambda: 0.16, Acc:0.374945, Semantic loss: 0.567856, BCE loss: 1.462899, SB loss: 0.345677\n",
      "Epoch: [15/20] Iter:[60/192], Time: 1.67, lr: [0.002709693418974644], Loss: 2.355464, Lambda: 0.16, Acc:0.370835, Semantic loss: 0.560649, BCE loss: 1.453175, SB loss: 0.341640\n",
      "Epoch: [15/20] Iter:[70/192], Time: 1.66, lr: [0.0026825813692418162], Loss: 2.335762, Lambda: 0.16, Acc:0.373454, Semantic loss: 0.558646, BCE loss: 1.441894, SB loss: 0.335223\n",
      "Epoch: [15/20] Iter:[80/192], Time: 1.65, lr: [0.0026554388387375], Loss: 2.361366, Lambda: 0.16, Acc:0.374215, Semantic loss: 0.578154, BCE loss: 1.444085, SB loss: 0.339127\n",
      "Epoch: [15/20] Iter:[90/192], Time: 1.64, lr: [0.002628265446219161], Loss: 2.356550, Lambda: 0.16, Acc:0.374569, Semantic loss: 0.567670, BCE loss: 1.454084, SB loss: 0.334795\n",
      "Epoch: [15/20] Iter:[100/192], Time: 1.63, lr: [0.002601060801235972], Loss: 2.356997, Lambda: 0.16, Acc:0.376127, Semantic loss: 0.572483, BCE loss: 1.446051, SB loss: 0.338462\n",
      "Epoch: [15/20] Iter:[110/192], Time: 1.63, lr: [0.002573824503796671], Loss: 2.364764, Lambda: 0.16, Acc:0.375162, Semantic loss: 0.565261, BCE loss: 1.464148, SB loss: 0.335356\n",
      "Epoch: [15/20] Iter:[120/192], Time: 1.63, lr: [0.00254655614402138], Loss: 2.365997, Lambda: 0.16, Acc:0.374849, Semantic loss: 0.562792, BCE loss: 1.466606, SB loss: 0.336600\n",
      "Epoch: [15/20] Iter:[130/192], Time: 1.62, lr: [0.0025192553017764118], Loss: 2.363315, Lambda: 0.16, Acc:0.376225, Semantic loss: 0.563692, BCE loss: 1.463075, SB loss: 0.336548\n",
      "Epoch: [15/20] Iter:[140/192], Time: 1.62, lr: [0.002491921546291034], Loss: 2.363467, Lambda: 0.16, Acc:0.375369, Semantic loss: 0.562686, BCE loss: 1.464274, SB loss: 0.336507\n",
      "Epoch: [15/20] Iter:[150/192], Time: 1.61, lr: [0.0024645544357550573], Loss: 2.356571, Lambda: 0.16, Acc:0.376845, Semantic loss: 0.560269, BCE loss: 1.461012, SB loss: 0.335291\n",
      "Epoch: [15/20] Iter:[160/192], Time: 1.61, lr: [0.002437153516896028], Loss: 2.358335, Lambda: 0.16, Acc:0.376961, Semantic loss: 0.559975, BCE loss: 1.461965, SB loss: 0.336395\n",
      "Epoch: [15/20] Iter:[170/192], Time: 1.61, lr: [0.0024097183245347467], Loss: 2.353645, Lambda: 0.16, Acc:0.377422, Semantic loss: 0.558855, BCE loss: 1.460804, SB loss: 0.333986\n",
      "Epoch: [15/20] Iter:[180/192], Time: 1.61, lr: [0.0023822483811177], Loss: 2.349710, Lambda: 0.16, Acc:0.377412, Semantic loss: 0.556905, BCE loss: 1.458519, SB loss: 0.334286\n",
      "Epoch: [15/20] Iter:[190/192], Time: 1.60, lr: [0.002354743196224891], Loss: 2.349226, Lambda: 0.16, Acc:0.376817, Semantic loss: 0.559331, BCE loss: 1.455775, SB loss: 0.334120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.32535229 0.24088166 0.13356862 0.32647612 0.14909433\n",
      " 0.0919959  0.27110548] 0.192309300807612\n",
      "1 [0.         0.49898695 0.24205354 0.25970441 0.50072159 0.11076059\n",
      " 0.08153086 0.40531265] 0.26238382578481073\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: barren (class 5), background (class 1), water (class 4)\n",
      "Loss: 6.829, MeanIU:  0.2624, Best_mIoU:  0.2793\n",
      "Per-class IoUs:\n",
      "  - barren (class 5): IoU = 0.1108\n",
      "  - background (class 1): IoU = 0.4990\n",
      "  - water (class 4): IoU = 0.5007\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.49898695 0.24205354 0.25970441 0.50072159 0.11076059\n",
      " 0.08153086 0.40531265]\n",
      "Epoch: [16/20] Iter:[0/192], Time: 6.88, lr: [0.0023492378861760376], Loss: 2.429875, Lambda: 0.17, Acc:0.363690, Semantic loss: 0.685231, BCE loss: 1.380483, SB loss: 0.364161\n",
      "Epoch: [16/20] Iter:[10/192], Time: 2.08, lr: [0.0023216897452738748], Loss: 2.388637, Lambda: 0.17, Acc:0.384462, Semantic loss: 0.575615, BCE loss: 1.484845, SB loss: 0.328177\n",
      "Epoch: [16/20] Iter:[20/192], Time: 1.85, lr: [0.0022941052360858027], Loss: 2.335989, Lambda: 0.17, Acc:0.401095, Semantic loss: 0.566927, BCE loss: 1.435484, SB loss: 0.333577\n",
      "Epoch: [16/20] Iter:[30/192], Time: 1.76, lr: [0.0022664838233947228], Loss: 2.353371, Lambda: 0.17, Acc:0.403421, Semantic loss: 0.550437, BCE loss: 1.474318, SB loss: 0.328615\n",
      "Epoch: [16/20] Iter:[40/192], Time: 1.72, lr: [0.0022388249567421017], Loss: 2.322405, Lambda: 0.17, Acc:0.400787, Semantic loss: 0.556833, BCE loss: 1.428193, SB loss: 0.337379\n",
      "Epoch: [16/20] Iter:[50/192], Time: 1.69, lr: [0.002211128069778427], Loss: 2.324008, Lambda: 0.17, Acc:0.396672, Semantic loss: 0.555891, BCE loss: 1.431449, SB loss: 0.336668\n",
      "Epoch: [16/20] Iter:[60/192], Time: 1.67, lr: [0.0021833925795765436], Loss: 2.311724, Lambda: 0.17, Acc:0.404741, Semantic loss: 0.548647, BCE loss: 1.433204, SB loss: 0.329873\n",
      "Epoch: [16/20] Iter:[70/192], Time: 1.65, lr: [0.0021556178859051967], Loss: 2.331936, Lambda: 0.17, Acc:0.404355, Semantic loss: 0.549814, BCE loss: 1.453721, SB loss: 0.328402\n",
      "Epoch: [16/20] Iter:[80/192], Time: 1.65, lr: [0.002127803370459852], Loss: 2.329048, Lambda: 0.17, Acc:0.406733, Semantic loss: 0.547914, BCE loss: 1.451518, SB loss: 0.329616\n",
      "Epoch: [16/20] Iter:[90/192], Time: 1.64, lr: [0.0020999483960476508], Loss: 2.347892, Lambda: 0.17, Acc:0.408254, Semantic loss: 0.551563, BCE loss: 1.464396, SB loss: 0.331933\n",
      "Epoch: [16/20] Iter:[100/192], Time: 1.63, lr: [0.0020720523057230294], Loss: 2.355808, Lambda: 0.17, Acc:0.408481, Semantic loss: 0.548449, BCE loss: 1.472503, SB loss: 0.334856\n",
      "Epoch: [16/20] Iter:[110/192], Time: 1.63, lr: [0.002044114421870228], Loss: 2.354047, Lambda: 0.17, Acc:0.408036, Semantic loss: 0.543290, BCE loss: 1.479153, SB loss: 0.331604\n",
      "Epoch: [16/20] Iter:[120/192], Time: 1.63, lr: [0.0020161340452285867], Loss: 2.353382, Lambda: 0.17, Acc:0.409178, Semantic loss: 0.545789, BCE loss: 1.475370, SB loss: 0.332223\n",
      "Epoch: [16/20] Iter:[130/192], Time: 1.63, lr: [0.001988110453856112], Loss: 2.350166, Lambda: 0.17, Acc:0.409118, Semantic loss: 0.539857, BCE loss: 1.481434, SB loss: 0.328875\n",
      "Epoch: [16/20] Iter:[140/192], Time: 1.62, lr: [0.0019600429020263607], Loss: 2.365894, Lambda: 0.17, Acc:0.406511, Semantic loss: 0.545420, BCE loss: 1.490740, SB loss: 0.329733\n",
      "Epoch: [16/20] Iter:[150/192], Time: 1.62, lr: [0.0019319306190532476], Loss: 2.353067, Lambda: 0.17, Acc:0.403387, Semantic loss: 0.545168, BCE loss: 1.479572, SB loss: 0.328327\n",
      "Epoch: [16/20] Iter:[160/192], Time: 1.62, lr: [0.0019037728080378042], Loss: 2.336246, Lambda: 0.17, Acc:0.400974, Semantic loss: 0.541813, BCE loss: 1.469410, SB loss: 0.325023\n",
      "Epoch: [16/20] Iter:[170/192], Time: 1.61, lr: [0.0018755686445303314], Loss: 2.327478, Lambda: 0.17, Acc:0.403430, Semantic loss: 0.540033, BCE loss: 1.463034, SB loss: 0.324410\n",
      "Epoch: [16/20] Iter:[180/192], Time: 1.61, lr: [0.001847317275100738], Loss: 2.328669, Lambda: 0.17, Acc:0.405244, Semantic loss: 0.541021, BCE loss: 1.463908, SB loss: 0.323740\n",
      "Epoch: [16/20] Iter:[190/192], Time: 1.60, lr: [0.0018190178158090872], Loss: 2.335388, Lambda: 0.17, Acc:0.404384, Semantic loss: 0.543341, BCE loss: 1.466935, SB loss: 0.325112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.26951187 0.28101071 0.15586091 0.33065955 0.12824014\n",
      " 0.09271242 0.28496136] 0.19286961938716574\n",
      "1 [0.         0.51348086 0.32725114 0.30736399 0.52961447 0.1134656\n",
      " 0.09633075 0.40654495] 0.28675646947817796\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 4\n",
      "Selected classes: forest (class 6), agriculture (class 7), building (class 2), road (class 3)\n",
      "Loss: 6.482, MeanIU:  0.2868, Best_mIoU:  0.2868\n",
      "Per-class IoUs:\n",
      "  - forest (class 6): IoU = 0.0963\n",
      "  - agriculture (class 7): IoU = 0.4065\n",
      "  - building (class 2): IoU = 0.3273\n",
      "  - road (class 3): IoU = 0.3074\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.51348086 0.32725114 0.30736399 0.52961447 0.1134656\n",
      " 0.09633075 0.40654495]\n",
      "Epoch: [17/20] Iter:[0/192], Time: 7.43, lr: [0.0018133520731367456], Loss: 2.391932, Lambda: 0.18, Acc:0.406499, Semantic loss: 0.515607, BCE loss: 1.480942, SB loss: 0.395384\n",
      "Epoch: [17/20] Iter:[10/192], Time: 2.08, lr: [0.001784993693823396], Loss: 2.217003, Lambda: 0.18, Acc:0.367122, Semantic loss: 0.527135, BCE loss: 1.358640, SB loss: 0.331227\n",
      "Epoch: [17/20] Iter:[20/192], Time: 1.82, lr: [0.0017565851643374117], Loss: 2.281071, Lambda: 0.18, Acc:0.376638, Semantic loss: 0.530468, BCE loss: 1.421971, SB loss: 0.328631\n",
      "Epoch: [17/20] Iter:[30/192], Time: 1.73, lr: [0.0017281254915000803], Loss: 2.327125, Lambda: 0.18, Acc:0.374611, Semantic loss: 0.538319, BCE loss: 1.453542, SB loss: 0.335264\n",
      "Epoch: [17/20] Iter:[40/192], Time: 1.70, lr: [0.0016996136438923032], Loss: 2.331273, Lambda: 0.18, Acc:0.380656, Semantic loss: 0.520440, BCE loss: 1.475509, SB loss: 0.335323\n",
      "Epoch: [17/20] Iter:[50/192], Time: 1.67, lr: [0.0016710485496403851], Loss: 2.327103, Lambda: 0.18, Acc:0.383044, Semantic loss: 0.521589, BCE loss: 1.469009, SB loss: 0.336505\n",
      "Epoch: [17/20] Iter:[60/192], Time: 1.65, lr: [0.0016424290940290059], Loss: 2.312225, Lambda: 0.18, Acc:0.379246, Semantic loss: 0.520073, BCE loss: 1.458185, SB loss: 0.333967\n",
      "Epoch: [17/20] Iter:[70/192], Time: 1.63, lr: [0.0016137541169242962], Loss: 2.333504, Lambda: 0.18, Acc:0.374315, Semantic loss: 0.536271, BCE loss: 1.454398, SB loss: 0.342836\n",
      "Epoch: [17/20] Iter:[80/192], Time: 1.62, lr: [0.0015850224099878446], Loss: 2.341200, Lambda: 0.18, Acc:0.372276, Semantic loss: 0.538165, BCE loss: 1.461791, SB loss: 0.341244\n",
      "Epoch: [17/20] Iter:[90/192], Time: 1.61, lr: [0.001556232713660091], Loss: 2.335027, Lambda: 0.18, Acc:0.370272, Semantic loss: 0.539118, BCE loss: 1.459758, SB loss: 0.336151\n",
      "Epoch: [17/20] Iter:[100/192], Time: 1.61, lr: [0.0015273837138888994], Loss: 2.339216, Lambda: 0.18, Acc:0.373800, Semantic loss: 0.546659, BCE loss: 1.449241, SB loss: 0.343316\n",
      "Epoch: [17/20] Iter:[110/192], Time: 1.60, lr: [0.0014984740385759552], Loss: 2.329440, Lambda: 0.18, Acc:0.374575, Semantic loss: 0.546378, BCE loss: 1.444309, SB loss: 0.338754\n",
      "Epoch: [17/20] Iter:[120/192], Time: 1.60, lr: [0.0014695022537100475], Loss: 2.337150, Lambda: 0.18, Acc:0.376466, Semantic loss: 0.543251, BCE loss: 1.457965, SB loss: 0.335934\n",
      "Epoch: [17/20] Iter:[130/192], Time: 1.59, lr: [0.0014404668591521846], Loss: 2.337120, Lambda: 0.18, Acc:0.375101, Semantic loss: 0.542595, BCE loss: 1.458427, SB loss: 0.336098\n",
      "Epoch: [17/20] Iter:[140/192], Time: 1.59, lr: [0.0014113662840326588], Loss: 2.335686, Lambda: 0.18, Acc:0.374653, Semantic loss: 0.542464, BCE loss: 1.458273, SB loss: 0.334949\n",
      "Epoch: [17/20] Iter:[150/192], Time: 1.59, lr: [0.0013821988817145786], Loss: 2.320326, Lambda: 0.18, Acc:0.374381, Semantic loss: 0.537345, BCE loss: 1.449474, SB loss: 0.333506\n",
      "Epoch: [17/20] Iter:[160/192], Time: 1.58, lr: [0.0013529629242719093], Loss: 2.327301, Lambda: 0.18, Acc:0.372964, Semantic loss: 0.538046, BCE loss: 1.455920, SB loss: 0.333335\n",
      "Epoch: [17/20] Iter:[170/192], Time: 1.58, lr: [0.0013236565964223801], Loss: 2.330687, Lambda: 0.18, Acc:0.372620, Semantic loss: 0.537945, BCE loss: 1.459409, SB loss: 0.333333\n",
      "Epoch: [17/20] Iter:[180/192], Time: 1.57, lr: [0.0012942779888466518], Loss: 2.325304, Lambda: 0.18, Acc:0.374064, Semantic loss: 0.539362, BCE loss: 1.453490, SB loss: 0.332453\n",
      "Epoch: [17/20] Iter:[190/192], Time: 1.57, lr: [0.0012648250908145803], Loss: 2.327937, Lambda: 0.18, Acc:0.372510, Semantic loss: 0.539531, BCE loss: 1.455048, SB loss: 0.333358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.31714916 0.27919845 0.14231219 0.33673402 0.1261112\n",
      " 0.09540063 0.28441126] 0.19766461334979074\n",
      "1 [0.         0.51448739 0.34096981 0.26571629 0.52283776 0.11102129\n",
      " 0.07431514 0.41835523] 0.2809628644954809\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 2\n",
      "Selected classes: background (class 1), forest (class 6)\n",
      "Loss: 6.070, MeanIU:  0.2810, Best_mIoU:  0.2868\n",
      "Per-class IoUs:\n",
      "  - background (class 1): IoU = 0.5145\n",
      "  - forest (class 6): IoU = 0.0743\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.51448739 0.34096981 0.26571629 0.52283776 0.11102129\n",
      " 0.07431514 0.41835523]\n",
      "Epoch: [18/20] Iter:[0/192], Time: 6.96, lr: [0.001258925411794167], Loss: 2.612722, Lambda: 0.19, Acc:0.498940, Semantic loss: 0.586242, BCE loss: 1.560552, SB loss: 0.465928\n",
      "Epoch: [18/20] Iter:[10/192], Time: 2.10, lr: [0.0012293805561511607], Loss: 2.464825, Lambda: 0.19, Acc:0.405683, Semantic loss: 0.638294, BCE loss: 1.429724, SB loss: 0.396807\n",
      "Epoch: [18/20] Iter:[20/192], Time: 1.84, lr: [0.0011997565879500753], Loss: 2.294110, Lambda: 0.19, Acc:0.413683, Semantic loss: 0.618312, BCE loss: 1.312730, SB loss: 0.363068\n",
      "Epoch: [18/20] Iter:[30/192], Time: 1.75, lr: [0.0011700511125444005], Loss: 2.291385, Lambda: 0.19, Acc:0.393759, Semantic loss: 0.579466, BCE loss: 1.365649, SB loss: 0.346270\n",
      "Epoch: [18/20] Iter:[40/192], Time: 1.70, lr: [0.0011402615929770753], Loss: 2.300772, Lambda: 0.19, Acc:0.383823, Semantic loss: 0.560042, BCE loss: 1.407068, SB loss: 0.333663\n",
      "Epoch: [18/20] Iter:[50/192], Time: 1.67, lr: [0.0011103853371305413], Loss: 2.316548, Lambda: 0.19, Acc:0.387621, Semantic loss: 0.564345, BCE loss: 1.413918, SB loss: 0.338285\n",
      "Epoch: [18/20] Iter:[60/192], Time: 1.65, lr: [0.001080419483295973], Loss: 2.301463, Lambda: 0.19, Acc:0.385111, Semantic loss: 0.559472, BCE loss: 1.410979, SB loss: 0.331012\n",
      "Epoch: [18/20] Iter:[70/192], Time: 1.63, lr: [0.0010503609839122385], Loss: 2.306427, Lambda: 0.19, Acc:0.388267, Semantic loss: 0.544270, BCE loss: 1.436897, SB loss: 0.325260\n",
      "Epoch: [18/20] Iter:[80/192], Time: 1.62, lr: [0.0010202065871765603], Loss: 2.296979, Lambda: 0.19, Acc:0.387200, Semantic loss: 0.541326, BCE loss: 1.434965, SB loss: 0.320689\n",
      "Epoch: [18/20] Iter:[90/192], Time: 1.62, lr: [0.000989952816168914], Loss: 2.285492, Lambda: 0.19, Acc:0.386171, Semantic loss: 0.537989, BCE loss: 1.424934, SB loss: 0.322568\n",
      "Epoch: [18/20] Iter:[100/192], Time: 1.61, lr: [0.0009595959450576828], Loss: 2.294987, Lambda: 0.19, Acc:0.385090, Semantic loss: 0.535743, BCE loss: 1.436666, SB loss: 0.322578\n",
      "Epoch: [18/20] Iter:[110/192], Time: 1.61, lr: [0.000929131971860904], Loss: 2.299681, Lambda: 0.19, Acc:0.384817, Semantic loss: 0.535353, BCE loss: 1.439619, SB loss: 0.324709\n",
      "Epoch: [18/20] Iter:[120/192], Time: 1.60, lr: [0.0008985565871200918], Loss: 2.297675, Lambda: 0.19, Acc:0.387572, Semantic loss: 0.532517, BCE loss: 1.442559, SB loss: 0.322599\n",
      "Epoch: [18/20] Iter:[130/192], Time: 1.60, lr: [0.0008678651376944955], Loss: 2.325653, Lambda: 0.19, Acc:0.386433, Semantic loss: 0.540059, BCE loss: 1.462513, SB loss: 0.323081\n",
      "Epoch: [18/20] Iter:[140/192], Time: 1.60, lr: [0.000837052584692747], Loss: 2.322845, Lambda: 0.19, Acc:0.385032, Semantic loss: 0.535579, BCE loss: 1.465505, SB loss: 0.321762\n",
      "Epoch: [18/20] Iter:[150/192], Time: 1.60, lr: [0.000806113454312208], Loss: 2.333575, Lambda: 0.19, Acc:0.385967, Semantic loss: 0.533145, BCE loss: 1.478045, SB loss: 0.322385\n",
      "Epoch: [18/20] Iter:[160/192], Time: 1.59, lr: [0.0007750417800344363], Loss: 2.330756, Lambda: 0.19, Acc:0.385987, Semantic loss: 0.532125, BCE loss: 1.476978, SB loss: 0.321652\n",
      "Epoch: [18/20] Iter:[170/192], Time: 1.59, lr: [0.0007438310342008949], Loss: 2.325893, Lambda: 0.19, Acc:0.385759, Semantic loss: 0.532589, BCE loss: 1.472953, SB loss: 0.320351\n",
      "Epoch: [18/20] Iter:[180/192], Time: 1.59, lr: [0.0007124740464272778], Loss: 2.327359, Lambda: 0.19, Acc:0.386645, Semantic loss: 0.535663, BCE loss: 1.470044, SB loss: 0.321652\n",
      "Epoch: [18/20] Iter:[190/192], Time: 1.58, lr: [0.0006809629055511224], Loss: 2.324780, Lambda: 0.19, Acc:0.386063, Semantic loss: 0.537038, BCE loss: 1.466097, SB loss: 0.321645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.34421464 0.26025476 0.13409474 0.33693124 0.13154024\n",
      " 0.09946991 0.26026929] 0.19584685200681665\n",
      "1 [0.         0.51328101 0.26571293 0.21617382 0.51426939 0.134201\n",
      " 0.08561513 0.33478273] 0.25800450330770214\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: building (class 2), barren (class 5), forest (class 6)\n",
      "Loss: 6.613, MeanIU:  0.2580, Best_mIoU:  0.2868\n",
      "Per-class IoUs:\n",
      "  - building (class 2): IoU = 0.2657\n",
      "  - barren (class 5): IoU = 0.1342\n",
      "  - forest (class 6): IoU = 0.0856\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.51328101 0.26571293 0.21617382 0.51426939 0.134201\n",
      " 0.08561513 0.33478273]\n",
      "Epoch: [19/20] Iter:[0/192], Time: 7.03, lr: [0.0006746414238367822], Loss: 2.436591, Lambda: 0.20, Acc:0.416902, Semantic loss: 0.420930, BCE loss: 1.748613, SB loss: 0.267048\n",
      "Epoch: [19/20] Iter:[10/192], Time: 2.14, lr: [0.0006429336362339898], Loss: 2.542535, Lambda: 0.20, Acc:0.379051, Semantic loss: 0.543587, BCE loss: 1.670017, SB loss: 0.328931\n",
      "Epoch: [19/20] Iter:[20/192], Time: 1.86, lr: [0.0006110510578510947], Loss: 2.422327, Lambda: 0.20, Acc:0.390279, Semantic loss: 0.564989, BCE loss: 1.516960, SB loss: 0.340378\n",
      "Epoch: [19/20] Iter:[30/192], Time: 1.77, lr: [0.0005789824653018995], Loss: 2.320034, Lambda: 0.20, Acc:0.387404, Semantic loss: 0.550137, BCE loss: 1.433842, SB loss: 0.336055\n",
      "Epoch: [19/20] Iter:[40/192], Time: 1.73, lr: [0.0005467151732202777], Loss: 2.298051, Lambda: 0.20, Acc:0.387616, Semantic loss: 0.533159, BCE loss: 1.436701, SB loss: 0.328192\n",
      "Epoch: [19/20] Iter:[50/192], Time: 1.70, lr: [0.0005142347343351296], Loss: 2.319591, Lambda: 0.20, Acc:0.386267, Semantic loss: 0.541680, BCE loss: 1.440736, SB loss: 0.337175\n",
      "Epoch: [19/20] Iter:[60/192], Time: 1.66, lr: [0.0004815245523312483], Loss: 2.333530, Lambda: 0.20, Acc:0.386040, Semantic loss: 0.539614, BCE loss: 1.461534, SB loss: 0.332382\n",
      "Epoch: [19/20] Iter:[70/192], Time: 1.64, lr: [0.000448565373510549], Loss: 2.333439, Lambda: 0.20, Acc:0.386653, Semantic loss: 0.542496, BCE loss: 1.459362, SB loss: 0.331581\n",
      "Epoch: [19/20] Iter:[80/192], Time: 1.63, lr: [0.00041533460609889997], Loss: 2.322799, Lambda: 0.20, Acc:0.389990, Semantic loss: 0.538460, BCE loss: 1.455577, SB loss: 0.328762\n",
      "Epoch: [19/20] Iter:[90/192], Time: 1.62, lr: [0.00038180538785330436], Loss: 2.319300, Lambda: 0.20, Acc:0.394100, Semantic loss: 0.533354, BCE loss: 1.460764, SB loss: 0.325182\n",
      "Epoch: [19/20] Iter:[100/192], Time: 1.61, lr: [0.00034794527452517863], Loss: 2.310843, Lambda: 0.20, Acc:0.395270, Semantic loss: 0.527055, BCE loss: 1.461957, SB loss: 0.321831\n",
      "Epoch: [19/20] Iter:[110/192], Time: 1.61, lr: [0.00031371433588231993], Loss: 2.318126, Lambda: 0.20, Acc:0.396768, Semantic loss: 0.532990, BCE loss: 1.460416, SB loss: 0.324719\n",
      "Epoch: [19/20] Iter:[120/192], Time: 1.61, lr: [0.0002790622842837163], Loss: 2.312078, Lambda: 0.20, Acc:0.396447, Semantic loss: 0.535664, BCE loss: 1.450115, SB loss: 0.326300\n",
      "Epoch: [19/20] Iter:[130/192], Time: 1.60, lr: [0.0002439239356353784], Loss: 2.330792, Lambda: 0.20, Acc:0.393816, Semantic loss: 0.538733, BCE loss: 1.461184, SB loss: 0.330875\n",
      "Epoch: [19/20] Iter:[140/192], Time: 1.60, lr: [0.00020821159321002047], Loss: 2.335996, Lambda: 0.20, Acc:0.392536, Semantic loss: 0.539856, BCE loss: 1.463950, SB loss: 0.332190\n",
      "Epoch: [19/20] Iter:[150/192], Time: 1.59, lr: [0.00017180122628828942], Loss: 2.332987, Lambda: 0.20, Acc:0.392030, Semantic loss: 0.538346, BCE loss: 1.463454, SB loss: 0.331187\n",
      "Epoch: [19/20] Iter:[160/192], Time: 1.59, lr: [0.00013450451987183818], Loss: 2.337472, Lambda: 0.20, Acc:0.393353, Semantic loss: 0.536909, BCE loss: 1.469659, SB loss: 0.330904\n",
      "Epoch: [19/20] Iter:[170/192], Time: 1.59, lr: [9.600244875192536e-05], Loss: 2.329086, Lambda: 0.20, Acc:0.392388, Semantic loss: 0.538375, BCE loss: 1.460390, SB loss: 0.330321\n",
      "Epoch: [19/20] Iter:[180/192], Time: 1.59, lr: [5.563716848048335e-05], Loss: 2.329450, Lambda: 0.20, Acc:0.392661, Semantic loss: 0.537772, BCE loss: 1.460833, SB loss: 0.330845\n",
      "Epoch: [19/20] Iter:[190/192], Time: 1.58, lr: [1.1092486125349496e-05], Loss: 2.339659, Lambda: 0.20, Acc:0.392870, Semantic loss: 0.539184, BCE loss: 1.468793, SB loss: 0.331682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 [0.         0.29536014 0.28987004 0.1533631  0.33360732 0.12721472\n",
      " 0.09507358 0.29290855] 0.19842468285757875\n",
      "1 [0.         0.51210403 0.33708384 0.26060936 0.53183386 0.10815034\n",
      " 0.0913041  0.35792933] 0.27487685681386986\n",
      "=> saving checkpoint to output/loveda/pidnet_small_loveda/dacscheckpoint.pth.tar\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Number of selected classes: 3\n",
      "Selected classes: agriculture (class 7), road (class 3), background (class 1)\n",
      "Loss: 6.653, MeanIU:  0.2749, Best_mIoU:  0.2868\n",
      "Per-class IoUs:\n",
      "  - agriculture (class 7): IoU = 0.3579\n",
      "  - road (class 3): IoU = 0.2606\n",
      "  - background (class 1): IoU = 0.5121\n",
      "-----------------------------------------------------------------------------------------------\n",
      "[0.         0.51210403 0.33708384 0.26060936 0.53183386 0.10815034\n",
      " 0.0913041  0.35792933]\n",
      "Hours: 2\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c49716f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T00:44:41.417456Z",
     "iopub.status.busy": "2025-05-21T00:44:41.417160Z",
     "iopub.status.idle": "2025-05-21T00:44:41.424168Z",
     "shell.execute_reply": "2025-05-21T00:44:41.423605Z"
    },
    "papermill": {
     "duration": 0.049328,
     "end_time": "2025-05-21T00:44:41.425187",
     "exception": false,
     "start_time": "2025-05-21T00:44:41.375859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/Adaptive_DACS.zip'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Set the path of the folder you want to zip\n",
    "folder_to_zip = '/kaggle/working/log'  # <-- replace this with your folder path\n",
    "\n",
    "# Set the name of the output zip file (without extension)\n",
    "zip_filename = 'Adaptive_DACS'\n",
    "\n",
    "# Create the zip archive\n",
    "shutil.make_archive(zip_filename, 'zip', folder_to_zip)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7160037,
     "sourceId": 11431888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7160755,
     "sourceId": 11432925,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7356120,
     "sourceId": 11782133,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7408952,
     "sourceId": 11798251,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10580.350925,
   "end_time": "2025-05-21T00:44:44.673096",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T21:48:24.322171",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
