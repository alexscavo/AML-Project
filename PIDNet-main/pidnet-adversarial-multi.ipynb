{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:51:22.741729Z",
     "iopub.status.busy": "2025-05-25T18:51:22.741388Z",
     "iopub.status.idle": "2025-05-25T18:51:27.698654Z",
     "shell.execute_reply": "2025-05-25T18:51:27.697723Z",
     "shell.execute_reply.started": "2025-05-25T18:51:22.741705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q albumentations==1.4.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:51:27.700345Z",
     "iopub.status.busy": "2025-05-25T18:51:27.700120Z",
     "iopub.status.idle": "2025-05-25T18:51:33.845551Z",
     "shell.execute_reply": "2025-05-25T18:51:33.844845Z",
     "shell.execute_reply.started": "2025-05-25T18:51:27.700312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install yacs\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copytree('/kaggle/input/pidnet-pretrained/', '/kaggle/working/pretrained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:21.664750Z",
     "iopub.status.busy": "2025-05-25T16:00:21.664582Z",
     "iopub.status.idle": "2025-05-25T16:00:21.700971Z",
     "shell.execute_reply": "2025-05-25T16:00:21.700267Z",
     "shell.execute_reply.started": "2025-05-25T16:00:21.664731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_lst_file(image_dir, label_dir, output_lst):\n",
    "    # List and sort files numerically\n",
    "    images = sorted(os.listdir(image_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    labels = sorted(os.listdir(label_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_lst), exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    with open(output_lst, 'w') as f:\n",
    "        for img, lbl in zip(images, labels):\n",
    "            # Generate full paths and normalize to use forward slashes\n",
    "            img_path = os.path.join(image_dir, img).replace(\"\\\\\", \"/\")\n",
    "            lbl_path = os.path.join(label_dir, lbl).replace(\"\\\\\", \"/\")\n",
    "            # Write formatted line with consistent spacing\n",
    "            f.write(f\"{img_path} {lbl_path}\\n\")\n",
    "\n",
    "# Paths to the LoveDA dataset directories\n",
    "train_image_dir = \"/kaggle/input/loveda-splits/Train/Train/Urban/images_png\"\n",
    "train_label_dir = \"/kaggle/input/loveda-splits/Train/Train/Urban/masks_png\"\n",
    "\n",
    "\n",
    "target_image_dir = \"/kaggle/input/loveda-splits/Train/Train/Rural/images_png\"\n",
    "target_label_dir = \"/kaggle/input/loveda-splits/Train/Train/Rural/masks_png\"\n",
    "\n",
    "val_image_dir = \"/kaggle/input/loveda-splits/Val/Val/Rural/images_png\"\n",
    "val_label_dir = \"/kaggle/input/loveda-splits/Val/Val/Rural/masks_png\"\n",
    "\n",
    "\n",
    "train_lst_path = \"list/urban/train.lst\"\n",
    "target_lst_path = \"list/rural/train.lst\"\n",
    "val_lst_path = \"list/rural/val.lst\"\n",
    "\n",
    "# Create .lst files\n",
    "create_lst_file(train_image_dir, train_label_dir, train_lst_path)\n",
    "create_lst_file(target_image_dir, target_label_dir, target_lst_path)\n",
    "create_lst_file(val_image_dir, val_label_dir, val_lst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:21.701945Z",
     "iopub.status.busy": "2025-05-25T16:00:21.701666Z",
     "iopub.status.idle": "2025-05-25T16:00:21.706233Z",
     "shell.execute_reply": "2025-05-25T16:00:21.705694Z",
     "shell.execute_reply.started": "2025-05-25T16:00:21.701924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft\n",
    "# Licensed under the MIT License.\n",
    "# Written by Ke Sun (sunk@mail.ustc.edu.cn)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "\n",
    "def add_path(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:21.708763Z",
     "iopub.status.busy": "2025-05-25T16:00:21.708530Z",
     "iopub.status.idle": "2025-05-25T16:00:23.358585Z",
     "shell.execute_reply": "2025-05-25T16:00:23.357797Z",
     "shell.execute_reply.started": "2025-05-25T16:00:21.708746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "        else:\n",
    "            return self.relu(out)\n",
    "\n",
    "class segmenthead(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
    "        super(segmenthead, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
    "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(self.relu(self.bn1(x)))\n",
    "        out = self.conv2(self.relu(self.bn2(x)))\n",
    "\n",
    "        if self.scale_factor is not None:\n",
    "            height = x.shape[-2] * self.scale_factor\n",
    "            width = x.shape[-1] * self.scale_factor\n",
    "            out = F.interpolate(out,\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.process1 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process2 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process3 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.process4 = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
    "                                    )\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        x_list = []\n",
    "\n",
    "        x_list.append(self.scale0(x))\n",
    "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
    "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
    "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
    "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
    "                        size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
    "\n",
    "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "class PAPPM(nn.Module):\n",
    "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PAPPM, self).__init__()\n",
    "        bn_mom = 0.1\n",
    "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale0 = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.scale_process = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "        self.compression = nn.Sequential(\n",
    "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
    "                                    )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "        scale_list = []\n",
    "\n",
    "        x_ = self.scale0(x)\n",
    "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
    "                        mode='bilinear', align_corners=algc)+x_)\n",
    "\n",
    "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
    "\n",
    "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PagFM(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
    "        super(PagFM, self).__init__()\n",
    "        self.with_channel = with_channel\n",
    "        self.after_relu = after_relu\n",
    "        self.f_x = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        self.f_y = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, mid_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(mid_channels)\n",
    "                                )\n",
    "        if with_channel:\n",
    "            self.up = nn.Sequential(\n",
    "                                    nn.Conv2d(mid_channels, in_channels,\n",
    "                                              kernel_size=1, bias=False),\n",
    "                                    BatchNorm(in_channels)\n",
    "                                   )\n",
    "        if after_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        input_size = x.size()\n",
    "        if self.after_relu:\n",
    "            y = self.relu(y)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        y_q = self.f_y(y)\n",
    "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x_k = self.f_x(x)\n",
    "\n",
    "        if self.with_channel:\n",
    "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
    "        else:\n",
    "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
    "\n",
    "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
    "                            mode='bilinear', align_corners=False)\n",
    "        x = (1-sim_map)*x + sim_map*y\n",
    "\n",
    "        return x\n",
    "\n",
    "class Light_Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Light_Bag, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "\n",
    "class DDFMv2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(DDFMv2, self).__init__()\n",
    "        self.conv_p = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "        self.conv_i = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False),\n",
    "                                BatchNorm(out_channels)\n",
    "                                )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1-edge_att)*i + p)\n",
    "        i_add = self.conv_i(i + edge_att*p)\n",
    "\n",
    "        return p_add + i_add\n",
    "\n",
    "class Bag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
    "        super(Bag, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                                BatchNorm(in_channels),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=3, padding=1, bias=False)\n",
    "                                )\n",
    "\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "        return self.conv(edge_att*p + (1-edge_att)*i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:23.359970Z",
     "iopub.status.busy": "2025-05-25T16:00:23.359539Z",
     "iopub.status.idle": "2025-05-25T16:00:23.384139Z",
     "shell.execute_reply": "2025-05-25T16:00:23.383252Z",
     "shell.execute_reply.started": "2025-05-25T16:00:23.359940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import logging\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "bn_mom = 0.1\n",
    "algc = False\n",
    "\n",
    "class PIDNet(nn.Module):\n",
    "\n",
    "    def __init__(self, m=2, n=3, num_classes=19, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
    "        super(PIDNet, self).__init__()\n",
    "        self.augment = augment\n",
    "\n",
    "        # I Branch\n",
    "        self.conv1 =  nn.Sequential(\n",
    "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
    "                          BatchNorm2d(planes, momentum=bn_mom),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                      )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
    "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
    "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
    "\n",
    "        # P Branch\n",
    "        self.compression3 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "\n",
    "        self.compression4 = nn.Sequential(\n",
    "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
    "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                          )\n",
    "        self.pag3 = PagFM(planes * 2, planes)\n",
    "        self.pag4 = PagFM(planes * 2, planes)\n",
    "\n",
    "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
    "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # D Branch\n",
    "        if m == 2:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
    "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
    "        else:\n",
    "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
    "            self.diff3 = nn.Sequential(\n",
    "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                        )\n",
    "            self.diff4 = nn.Sequential(\n",
    "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
    "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
    "                                     )\n",
    "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
    "            self.dfm = Bag(planes * 4, planes * 4)\n",
    "\n",
    "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
    "\n",
    "        # Prediction Head\n",
    "        if self.augment:\n",
    "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
    "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
    "\n",
    "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            if i == (blocks-1):\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
    "            else:\n",
    "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
    "            )\n",
    "\n",
    "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        width_output = x.shape[-1] // 8\n",
    "        height_output = x.shape[-2] // 8\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(self.layer2(self.relu(x)))\n",
    "        x_ = self.layer3_(x)\n",
    "        x_d = self.layer3_d(x)\n",
    "\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x_ = self.pag3(x_, self.compression3(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff3(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_p = x_\n",
    "\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x_ = self.layer4_(self.relu(x_))\n",
    "        x_d = self.layer4_d(self.relu(x_d))\n",
    "\n",
    "        x_ = self.pag4(x_, self.compression4(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "                        self.diff4(x),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "        if self.augment:\n",
    "            temp_d = x_d\n",
    "\n",
    "        x_ = self.layer5_(self.relu(x_))\n",
    "        x_d = self.layer5_d(self.relu(x_d))\n",
    "        x = F.interpolate(\n",
    "                        self.spp(self.layer5(x)),\n",
    "                        size=[height_output, width_output],\n",
    "                        mode='bilinear', align_corners=algc)\n",
    "\n",
    "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
    "\n",
    "        if self.augment:\n",
    "            x_extra_p = self.seghead_p(temp_p)\n",
    "            x_extra_d = self.seghead_d(temp_d)\n",
    "            return [x_extra_p, x_, x_extra_d]\n",
    "        else:\n",
    "            return x_\n",
    "\n",
    "def get_seg_model():\n",
    "\n",
    "    model = PIDNet(m=2, n=3, num_classes=8, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
    "    \n",
    "    \n",
    "    pretrained_state = torch.load('/kaggle/working/pretrained_model/PIDNet_S_ImageNet.pth.tar', map_location='cpu')['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
    "    model_dict.update(pretrained_state)\n",
    "    msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
    "    logging.info('Attention!!!')\n",
    "    logging.info(msg)\n",
    "    logging.info('Over!!!')\n",
    "    model.load_state_dict(model_dict, strict = False)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_pred_model(name, num_classes):\n",
    "\n",
    "    if 's' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
    "    elif 'm' in name:\n",
    "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
    "    else:\n",
    "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:23.385251Z",
     "iopub.status.busy": "2025-05-25T16:00:23.385017Z",
     "iopub.status.idle": "2025-05-25T16:00:24.305301Z",
     "shell.execute_reply": "2025-05-25T16:00:24.304541Z",
     "shell.execute_reply.started": "2025-05-25T16:00:23.385232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "y_k_size = 6\n",
    "x_k_size = 6\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 ignore_label=255,\n",
    "                 base_size=2048,\n",
    "                 crop_size=(512, 512),\n",
    "                 scale_factor=16,\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]):\n",
    "\n",
    "        self.base_size = base_size\n",
    "        self.crop_size = crop_size\n",
    "        self.ignore_label = ignore_label\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        self.files = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def input_transform(self, image, city=False):\n",
    "        if city:\n",
    "            image = image.astype(np.float32)[:, :, ::-1]\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        image = image / 255.0\n",
    "        image -= self.mean\n",
    "        image /= self.std\n",
    "        return image\n",
    "\n",
    "    def label_transform(self, label):\n",
    "        return np.array(label).astype(np.uint8)\n",
    "\n",
    "    def pad_image(self, image, h, w, size, padvalue):\n",
    "        pad_h = max(size[0] - h, 0)\n",
    "        pad_w = max(size[1] - w, 0)\n",
    "\n",
    "        # Se non è necessario il padding, restituisci l'immagine originale\n",
    "        if pad_h == 0 and pad_w == 0:\n",
    "            return image\n",
    "\n",
    "        # Verifica il formato dell'immagine (deve essere H, W, C)\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        # Aggiungi il padding\n",
    "        pad_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=padvalue)\n",
    "\n",
    "        # Ripristina il formato originale (C, H, W) se necessario\n",
    "        if len(image.shape) == 3 and image.shape[2] <= 3:  # Se era in formato (C, H, W)\n",
    "            pad_image = np.transpose(pad_image, (2, 0, 1))  # Converti di nuovo in (C, H, W)\n",
    "\n",
    "        return pad_image\n",
    "\n",
    "    def rand_crop(self, image, label, edge):\n",
    "        # Verifica il formato dell'immagine\n",
    "        if len(image.shape) == 3 and image.shape[0] <= 3:  # Se è in formato (C, H, W)\n",
    "            image = np.transpose(image, (1, 2, 0))  # Converti in (H, W, C)\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Aggiungi padding se necessario\n",
    "        if h < self.crop_size[0] or w < self.crop_size[1]:\n",
    "            image = self.pad_image(image, h, w, self.crop_size, (0.0, 0.0, 0.0))\n",
    "            label = self.pad_image(label, h, w, self.crop_size, (self.ignore_label,))\n",
    "            edge = self.pad_image(edge, h, w, self.crop_size, (0.0,))\n",
    "\n",
    "        # Aggiorna le dimensioni dopo il padding\n",
    "        new_h, new_w = label.shape\n",
    "        if new_h < self.crop_size[0] or new_w < self.crop_size[1]:\n",
    "            raise ValueError(f\"Dimensioni insufficienti per il ritaglio: label={label.shape}, crop_size={self.crop_size}\")\n",
    "\n",
    "        # Calcola le coordinate per il ritaglio casuale\n",
    "        x = random.randint(0, new_w - self.crop_size[1])\n",
    "        y = random.randint(0, new_h - self.crop_size[0])\n",
    "\n",
    "        # Esegui il ritaglio\n",
    "        image = image[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        label = label[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "        edge = edge[y:y+self.crop_size[0], x:x+self.crop_size[1]]\n",
    "\n",
    "        #in questo modo l'iimagine è 512x512x3\n",
    "        #se volessi croppare quella regione\n",
    "        '''\n",
    "        # Estrai la regione da sfocare\n",
    "        cropped_region = image[y:y+crop_size[0], x:x+crop_size[1]]\n",
    "\n",
    "        # Applica il Gaussian Blur alla regione\n",
    "        blurred_region = cv2.GaussianBlur(cropped_region, (15, 15), 0)\n",
    "\n",
    "        # Sostituisci la regione originale con quella sfocata\n",
    "        augmented_image = image.copy()\n",
    "        augmented_image[y:y+crop_size[0], x:x+crop_size[1]] = blurred_region\n",
    "        '''\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "    def multi_scale_aug(self, image, label=None, edge=None,\n",
    "                        rand_scale=1, rand_crop=True):\n",
    "        long_size = int(self.base_size * rand_scale + 0.5)\n",
    "        h, w = image.shape[:2]\n",
    "        if h > w:\n",
    "            new_h = long_size\n",
    "            new_w = int(w * long_size / h + 0.5)\n",
    "        else:\n",
    "            new_w = long_size\n",
    "            new_h = int(h * long_size / w + 0.5)\n",
    "\n",
    "        image = cv2.resize(image, (new_w, new_h),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (new_w, new_h),\n",
    "                               interpolation=cv2.INTER_NEAREST)\n",
    "            if edge is not None:\n",
    "                edge = cv2.resize(edge, (new_w, new_h),\n",
    "                                   interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "        if rand_crop:\n",
    "            image, label, edge = self.rand_crop(image, label, edge)\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def gen_sample(self, image, label, edge_pad=True, edge_size=4, city=False, transform=None, show=False):\n",
    "\n",
    "\n",
    "        if transform is not None:\n",
    "            # Pass both image and mask\n",
    "            augmented = transform(image=image, mask=label)\n",
    "\n",
    "            if show:\n",
    "                show_images(image, augmented[\"image\"])\n",
    "\n",
    "            # Extract results\n",
    "            image = augmented['image']\n",
    "            label = augmented['mask']\n",
    "\n",
    "\n",
    "\n",
    "        #It' important keeping the edge generation after the data augmentation\n",
    "        edge = cv2.Canny(label, 0.1, 0.2)\n",
    "        kernel = np.ones((edge_size, edge_size), np.uint8)\n",
    "        if edge_pad:\n",
    "            edge = edge[y_k_size:-y_k_size, x_k_size:-x_k_size]\n",
    "            edge = np.pad(edge, ((y_k_size,y_k_size),(x_k_size,x_k_size)), mode='constant')\n",
    "        edge = (cv2.dilate(edge, kernel, iterations=1)>50)*1.0\n",
    "\n",
    "\n",
    "        #trasformazioni di input\n",
    "        image = self.input_transform(image, city=city) #Se city=True, converte l'immagine da RGB in BGR per opencv\n",
    "        label = self.label_transform(label) #converte la label in un array di interi\n",
    "        image = image.transpose((2, 0, 1)) #H,W,C -> C,H,W\n",
    "\n",
    "        return image, label, edge\n",
    "\n",
    "\n",
    "    def inference(self, model, image):\n",
    "        size = image.size()\n",
    "        pred = model(image)\n",
    "\n",
    "        \n",
    "        pred = pred[1]\n",
    "\n",
    "\n",
    "        pred = F.interpolate(\n",
    "            input=pred, size=size[-2:],\n",
    "            mode='bilinear', align_corners=True\n",
    "        )\n",
    "\n",
    "\n",
    "        return pred.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:24.306434Z",
     "iopub.status.busy": "2025-05-25T16:00:24.306062Z",
     "iopub.status.idle": "2025-05-25T16:00:26.032819Z",
     "shell.execute_reply": "2025-05-25T16:00:26.032149Z",
     "shell.execute_reply.started": "2025-05-25T16:00:24.306401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "from PIL import Image\n",
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(x_original, x_augmented, unnormalize = False):\n",
    "\n",
    "    if unnormalize:\n",
    "        # ImageNet mean and std\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])[:, None, None]\n",
    "\n",
    "        # Denormalize using NumPy broadcasting\n",
    "        x_original = x_original * imagenet_std + imagenet_mean\n",
    "        x_augmented = x_augmented * imagenet_std + imagenet_mean\n",
    "\n",
    "        # Clip to [0, 1] in case of overflows\n",
    "        x_original = np.clip(x_original, 0, 1)\n",
    "        x_augmented = np.clip(x_augmented, 0, 1)\n",
    "\n",
    "        # Transpose to HWC for matplotlib\n",
    "        x_original = np.transpose(x_original, (1, 2, 0))\n",
    "        x_augmented = np.transpose(x_augmented, (1, 2, 0))\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(x_original)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    axs[1].imshow(x_augmented)\n",
    "    axs[1].set_title(\"Augmented Image\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class LoveDA(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 list_path,\n",
    "                 num_classes=7,\n",
    "                 flip=False,\n",
    "                 ignore_label=0,\n",
    "                 crop_size=(512, 512),\n",
    "                 scale_factor=16, #multi scale usato come data augmentation alredy provided\n",
    "                 mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225],\n",
    "                 bd_dilate_size=4,\n",
    "                 weighted=True,\n",
    "                 transform=None):\n",
    "\n",
    "        # estende il base_dataset\n",
    "        super(LoveDA, self).__init__(ignore_label, crop_size, scale_factor, mean, std)\n",
    "\n",
    "        self.root = root\n",
    "        self.list_path = list_path\n",
    "        self.num_classes = num_classes\n",
    "        self.flip = flip\n",
    "        self.ignore_label = ignore_label\n",
    "        self.scale_factor = scale_factor\n",
    "        self.bd_dilate_size = bd_dilate_size\n",
    "\n",
    "        self.img_list = [line.strip().split() for line in open(root + list_path)]\n",
    "        self.files = self.read_files()\n",
    "        self.color_list = [[0, 0, 0], [1, 1, 1], [2, 2, 2],\n",
    "                            [3, 3, 3], [4, 4, 4], [5, 5, 5], [6, 6, 6], [7, 7, 7]]\n",
    "        self.class_weights = None\n",
    "        if weighted:\n",
    "            self.class_weights = torch.tensor([0.000000, 0.116411, 0.266041, 0.607794, 1.511413, 0.745507, 0.712438, 3.040396])\n",
    "        \n",
    "        self.transform=transform\n",
    "\n",
    "    def read_files(self):\n",
    "        files = []\n",
    "\n",
    "        for item in self.img_list:\n",
    "            image_path, label_path = item\n",
    "            name = os.path.splitext(os.path.basename(label_path))[0]\n",
    "            files.append({\n",
    "                \"img\": image_path,\n",
    "                \"label\": label_path,\n",
    "                \"name\": name\n",
    "            })\n",
    "\n",
    "        return files\n",
    "\n",
    "    # da immagine a label\n",
    "    def color2label(self, color_map):\n",
    "        label = np.ones(color_map.shape[:2]) * self.ignore_label\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            label[(color_map == v).sum(2) == 3] = i\n",
    "\n",
    "        return label.astype(np.uint8)\n",
    "\n",
    "    def convert_label(self, label, inverse=False):\n",
    "        temp = label.copy()\n",
    "        if inverse:\n",
    "            for v, k in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        else:\n",
    "            for k, v in self.label_mapping.items():\n",
    "                label[temp == k] = v\n",
    "        return label\n",
    "\n",
    "    # da label a immagine\n",
    "    def label2color(self, label):\n",
    "        color_map = np.zeros(label.shape + (3,))\n",
    "        for i, v in enumerate(self.color_list):\n",
    "            color_map[label == i] = self.color_list[i]\n",
    "\n",
    "        return color_map.astype(np.uint8)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.files[index]\n",
    "        name = item[\"name\"]\n",
    "        image = cv2.imread(item[\"img\"], cv2.IMREAD_COLOR)\n",
    "\n",
    "        size = image.shape\n",
    "\n",
    "        label = cv2.imread(item[\"label\"], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "        #edge (H,W)\n",
    "        image, label, edge = self.gen_sample(image, label, edge_pad=False,\n",
    "                                             edge_size=self.bd_dilate_size, city=False, transform=self.transform, show=False) #image diventa (C,H,W)\n",
    "\n",
    "        return image.copy(), label.copy(), edge.copy(), np.array(size), name\n",
    "\n",
    "    def single_scale_inference(self, model, image):\n",
    "        pred = self.inference(model, image)\n",
    "        return pred\n",
    "\n",
    "    def save_pred(self, preds, sv_path, name):\n",
    "        preds = np.asarray(np.argmax(preds.cpu(), axis=1), dtype=np.uint8)\n",
    "        for i in range(preds.shape[0]):\n",
    "            pred = self.label2color(preds[i])\n",
    "            save_img = Image.fromarray(pred)\n",
    "            save_img.save(os.path.join(sv_path, name[i] + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:26.033852Z",
     "iopub.status.busy": "2025-05-25T16:00:26.033502Z",
     "iopub.status.idle": "2025-05-25T16:00:26.049347Z",
     "shell.execute_reply": "2025-05-25T16:00:26.048523Z",
     "shell.execute_reply.started": "2025-05-25T16:00:26.033833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "class CrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, weight=None):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label\n",
    "        )\n",
    "\n",
    "    def _forward(self, score, target):\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        balance_weights = [0.4, 1.0]\n",
    "        sb_weights = 1.0\n",
    "        if len(balance_weights) == len(score):\n",
    "            return sum([w * self._forward(x, target) for (w, x) in zip(balance_weights, score)])\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class OhemCrossEntropy(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, thres=0.7,\n",
    "                 min_kept=100000, weight=None):\n",
    "        super(OhemCrossEntropy, self).__init__()\n",
    "        self.thresh = thres\n",
    "        self.min_kept = max(1, min_kept)\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label,\n",
    "            reduction='none'\n",
    "        )\n",
    "\n",
    "    def _ce_forward(self, score, target):\n",
    "\n",
    "\n",
    "        loss = self.criterion(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _ohem_forward(self, score, target, **kwargs):\n",
    "\n",
    "        pred = F.softmax(score, dim=1)\n",
    "        pixel_losses = self.criterion(score, target).contiguous().view(-1)\n",
    "        mask = target.contiguous().view(-1) != self.ignore_label\n",
    "\n",
    "        tmp_target = target.clone()\n",
    "        tmp_target[tmp_target == self.ignore_label] = 0\n",
    "        pred = pred.gather(1, tmp_target.unsqueeze(1))\n",
    "        pred, ind = pred.contiguous().view(-1,)[mask].contiguous().sort()\n",
    "        min_value = pred[min(self.min_kept, pred.numel() - 1)]\n",
    "        threshold = max(min_value, self.thresh)\n",
    "\n",
    "        pixel_losses = pixel_losses[mask][ind]\n",
    "        pixel_losses = pixel_losses[pred < threshold]\n",
    "        return pixel_losses.mean()\n",
    "\n",
    "    def forward(self, score, target):\n",
    "\n",
    "        if not (isinstance(score, list) or isinstance(score, tuple)):\n",
    "            score = [score]\n",
    "\n",
    "        balance_weights = [0.4, 1.0]\n",
    "        sb_weights = 1.0\n",
    "        if len(balance_weights) == len(score):\n",
    "            functions = [self._ce_forward] * \\\n",
    "                (len(balance_weights) - 1) + [self._ohem_forward]\n",
    "            return sum([\n",
    "                w * func(x, target)\n",
    "                for (w, x, func) in zip(balance_weights, score, functions)\n",
    "            ])\n",
    "\n",
    "        elif len(score) == 1:\n",
    "            return sb_weights * self._ohem_forward(score[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
    "\n",
    "\n",
    "def weighted_bce(bd_pre, target):\n",
    "    n, c, h, w = bd_pre.size()\n",
    "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
    "    target_t = target.view(1, -1)\n",
    "\n",
    "    pos_index = (target_t == 1)\n",
    "    neg_index = (target_t == 0)\n",
    "\n",
    "    weight = torch.zeros_like(log_p)\n",
    "    pos_num = pos_index.sum()\n",
    "    neg_num = neg_index.sum()\n",
    "    sum_num = pos_num + neg_num\n",
    "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
    "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "class BondaryLoss(nn.Module):\n",
    "    def __init__(self, coeff_bce = 20.0):\n",
    "        super(BondaryLoss, self).__init__()\n",
    "        self.coeff_bce = coeff_bce\n",
    "\n",
    "    def forward(self, bd_pre, bd_gt):\n",
    "\n",
    "        bce_loss = self.coeff_bce * weighted_bce(bd_pre, bd_gt)\n",
    "        loss = bce_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:26.050463Z",
     "iopub.status.busy": "2025-05-25T16:00:26.050198Z",
     "iopub.status.idle": "2025-05-25T16:00:26.069903Z",
     "shell.execute_reply": "2025-05-25T16:00:26.069219Z",
     "shell.execute_reply.started": "2025-05-25T16:00:26.050440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "\n",
    "  def __init__(self, model, sem_loss, bd_loss):\n",
    "    super(FullModel, self).__init__()\n",
    "    self.model = model\n",
    "    self.sem_loss = sem_loss\n",
    "    self.bd_loss = bd_loss\n",
    "\n",
    "  def pixel_acc(self, pred, label):\n",
    "    _, preds = torch.max(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc\n",
    "      \n",
    "  \n",
    "\n",
    "\n",
    "  def forward(self, inputs, labels, bd_gt, *args, **kwargs):\n",
    "    \n",
    "    outputs = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "    h, w = labels.size(1), labels.size(2)\n",
    "    ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
    "    if ph != h or pw != w:\n",
    "        for i in range(len(outputs)):\n",
    "            outputs[i] = F.interpolate(outputs[i], size=(\n",
    "                h, w), mode='bilinear', align_corners=True)\n",
    "\n",
    "    acc  = self.pixel_acc(outputs[-2], labels)\n",
    "    loss_s = self.sem_loss(outputs[:-1], labels)\n",
    "    loss_b = self.bd_loss(outputs[-1], bd_gt)\n",
    "\n",
    "    filler = torch.ones_like(labels) * 0\n",
    "    try:\n",
    "        bd_label = torch.where(torch.sigmoid(outputs[-1][:, 0, :, :]) > 0.8, labels, filler) # 0.7\n",
    "        loss_sb = self.sem_loss([outputs[-2]], bd_label)\n",
    "    except:\n",
    "        print(\"Error in loss computation\")\n",
    "        loss_sb = self.sem_loss([outputs[-2]], labels)\n",
    "    loss = loss_s + loss_b + loss_sb\n",
    "\n",
    "    return torch.unsqueeze(loss,0), outputs[:-1], acc, [loss_s, loss_b] #outputs[:-1] è una lista di tensori\n",
    "\n",
    "'''def forward(self, inputs, labels, bd_gt, *args, **kwargs):\n",
    "    # ——— cast targets to the right dtype\n",
    "    labels = labels.long()\n",
    "    # for BCEWithLogitsLoss we need float targets with a channel dim\n",
    "    bd_gt = bd_gt.float().unsqueeze(1)  \n",
    "\n",
    "    outputs = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "    # ——— resize outputs to match labels\n",
    "    h, w = labels.size(1), labels.size(2)\n",
    "    if outputs[0].size(2)!=h or outputs[0].size(3)!=w:\n",
    "        for i in range(len(outputs)):\n",
    "            outputs[i] = F.interpolate(outputs[i],\n",
    "                                       size=(h, w),\n",
    "                                       mode='bilinear',\n",
    "                                       align_corners=True)\n",
    "\n",
    "    # ——— pixel accuracy on the penultimate head\n",
    "    acc = self.pixel_acc(outputs[-2], labels)\n",
    "\n",
    "    # ——— multi-level segmentation loss\n",
    "    loss_s = sum(self.sem_loss(out, labels) for out in outputs[:-1])\n",
    "\n",
    "    # ——— boundary loss (now shapes match: [B,1,H,W] vs [B,1,H,W])\n",
    "    loss_b = self.bd_loss(outputs[-1], bd_gt)\n",
    "\n",
    "    # ——— selective semantic loss over high-confidence boundary regions\n",
    "    filler = torch.zeros_like(labels)\n",
    "    try:\n",
    "        mask = torch.sigmoid(outputs[-1][:, 0, ...]) > 0.8\n",
    "        bd_label = torch.where(mask, labels, filler)\n",
    "        loss_sb = self.sem_loss(outputs[-2], bd_label)\n",
    "    except Exception as e:\n",
    "        loss_sb = self.sem_loss(outputs[-2], labels)\n",
    "\n",
    "    total_loss = loss_s + loss_b + loss_sb\n",
    "\n",
    "    return (\n",
    "        total_loss.unsqueeze(0),\n",
    "        outputs[:-1],\n",
    "        acc,\n",
    "        [loss_s, loss_b, loss_sb]\n",
    "    )'''\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.val = None\n",
    "        self.avg = None\n",
    "        self.sum = None\n",
    "        self.count = None\n",
    "\n",
    "    def initialize(self, val, weight):\n",
    "        self.val = val\n",
    "        self.avg = val\n",
    "        self.sum = val * weight\n",
    "        self.count = weight\n",
    "        self.initialized = True\n",
    "\n",
    "    def update(self, val, weight=1):\n",
    "        if not self.initialized:\n",
    "            self.initialize(val, weight)\n",
    "        else:\n",
    "            self.add(val, weight)\n",
    "\n",
    "    def add(self, val, weight):\n",
    "        self.val = val\n",
    "        self.sum += val * weight\n",
    "        self.count += weight\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def value(self):\n",
    "        return self.val\n",
    "\n",
    "    def average(self):\n",
    "        return self.avg\n",
    "\n",
    "def create_logger(cfg, cfg_name, phase='train'):\n",
    "    root_output_dir = Path('/kaggle/working/output')\n",
    "\n",
    "    \n",
    "    folder_name = \"gan\"\n",
    "\n",
    "    # set up logger\n",
    "    if not root_output_dir.exists():\n",
    "        print('=> creating {}'.format(root_output_dir))\n",
    "        root_output_dir.mkdir()\n",
    "\n",
    "    dataset = 'loveda'\n",
    "    model = 'pidnet_small'\n",
    "    cfg_name = os.path.basename('log').split('.')[0]\n",
    "\n",
    "    final_output_dir = root_output_dir / dataset / cfg_name / folder_name\n",
    "\n",
    "    print('=> creating {}'.format(final_output_dir))\n",
    "    final_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    time_str = time.strftime('%Y-%m-%d-%H-%M')\n",
    "    log_file = '{}_{}_{}.log'.format('log', time_str, phase)\n",
    "    final_log_file = final_output_dir / log_file\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=str(final_log_file),\n",
    "                        format=head)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    console = logging.StreamHandler()\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    tensorboard_log_dir = Path('log') / dataset / model / \\\n",
    "            ('log' + '_' + time_str)\n",
    "    print('=> creating {}'.format(tensorboard_log_dir))\n",
    "    tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return logger, str(final_output_dir), str(tensorboard_log_dir)\n",
    "\n",
    "def get_confusion_matrix(label, pred, size, num_class, ignore=-1):\n",
    "    \"\"\"\n",
    "    Calcute the confusion matrix by given label and pred\n",
    "    \"\"\"\n",
    "    output = pred.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    seg_pred = np.asarray(np.argmax(output, axis=3), dtype=np.uint8)\n",
    "    seg_gt = np.asarray(\n",
    "    label.cpu().numpy()[:, :size[-2], :size[-1]], dtype=int)\n",
    "\n",
    "    ignore_index = seg_gt != ignore\n",
    "    seg_gt = seg_gt[ignore_index]\n",
    "    seg_pred = seg_pred[ignore_index]\n",
    "\n",
    "    index = (seg_gt * num_class + seg_pred).astype('int32')\n",
    "    label_count = np.bincount(index)\n",
    "    confusion_matrix = np.zeros((num_class, num_class))\n",
    "\n",
    "    for i_label in range(num_class):\n",
    "        for i_pred in range(num_class):\n",
    "            cur_index = i_label * num_class + i_pred\n",
    "            if cur_index < len(label_count):\n",
    "                confusion_matrix[i_label,\n",
    "                                 i_pred] = label_count[cur_index]\n",
    "    return confusion_matrix\n",
    "\n",
    "def adjust_learning_rate(optimizer, base_lr, max_iters,\n",
    "        cur_iters, power=0.9, nbb_mult=10):\n",
    "    lr = base_lr*((1-float(cur_iters)/max_iters)**(power))\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    if len(optimizer.param_groups) == 2:\n",
    "        optimizer.param_groups[1]['lr'] = lr * nbb_mult\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:26.070894Z",
     "iopub.status.busy": "2025-05-25T16:00:26.070698Z",
     "iopub.status.idle": "2025-05-25T16:00:26.087303Z",
     "shell.execute_reply": "2025-05-25T16:00:26.086694Z",
     "shell.execute_reply.started": "2025-05-25T16:00:26.070870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate(testloader, model, num_classes=8, ignore_label=0, align_corners=False):\n",
    "    model.eval()\n",
    "    # we're going to collect two sets of preds\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes, 2), dtype=np.float64)\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testloader):\n",
    "            image, label, bd_gts, _, _ = batch\n",
    "            size = label.size()\n",
    "            image  = image.cuda()\n",
    "            label  = label.long().cuda()\n",
    "            bd_gts = bd_gts.float().cuda()\n",
    "\n",
    "            losses, preds, _, _ = model(image, label, bd_gts)\n",
    "            if not isinstance(preds, (list, tuple)):\n",
    "                preds = [preds]\n",
    "\n",
    "            for i, x in enumerate(preds):\n",
    "                x = F.interpolate(\n",
    "                    x,\n",
    "                    size=size[-2:],\n",
    "                    mode='bilinear',\n",
    "                    align_corners=align_corners\n",
    "                )\n",
    "                cm = get_confusion_matrix(\n",
    "                    label,\n",
    "                    x,\n",
    "                    size,\n",
    "                    num_classes,\n",
    "                    ignore=ignore_label\n",
    "                )\n",
    "                confusion_matrix[..., i] += cm\n",
    "\n",
    "    # compute IoUs for each head\n",
    "    mean_ious = []\n",
    "    for i in range(confusion_matrix.shape[-1]):\n",
    "        cm = confusion_matrix[..., i]\n",
    "        pos = cm.sum(1)\n",
    "        res = cm.sum(0)\n",
    "        tp  = np.diag(cm)\n",
    "        ious = tp / np.maximum(1.0, pos + res - tp)\n",
    "        # drop class 0\n",
    "        mean_ious.append(ious[1:].mean())\n",
    "\n",
    "    # return the *second* head's mIoU by default (you can adjust)\n",
    "    return mean_ious[1], ious[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T16:00:26.088463Z",
     "iopub.status.busy": "2025-05-25T16:00:26.088199Z",
     "iopub.status.idle": "2025-05-25T18:20:20.263594Z",
     "shell.execute_reply": "2025-05-25T18:20:20.262837Z",
     "shell.execute_reply.started": "2025-05-25T16:00:26.088438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "import gc\n",
    "import albumentations as A\n",
    "# evita fork: usa spawn (più sicuro per DataLoader)\n",
    "# --- Discriminator definition for multi-level adaptation ---\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        if in_channels == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(1, 1, kernel_size=4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(1, 1, kernel_size=4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(1, 1, kernel_size=4, stride=2, padding=1),\n",
    "            )\n",
    "        else: \n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels // 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(in_channels // 2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(in_channels // 2, in_channels // 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(in_channels // 4),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(in_channels // 4, 1, kernel_size=4, stride=2, padding=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# --- Utility: compute IoU from confusion matrix ---\n",
    "def compute_iou(conf_matrix, ignore_index=0):\n",
    "    \"\"\"\n",
    "    Compute per-class IoU for *all* classes, but set the ignored one to NaN.\n",
    "    Returns a list of length N; IoU[ignore_index] == np.nan.\n",
    "    \"\"\"\n",
    "    num_classes = conf_matrix.shape[0]\n",
    "    ious = [float('nan')] * num_classes\n",
    "    for cls in range(num_classes):\n",
    "        if cls == ignore_index:\n",
    "            continue\n",
    "        tp = conf_matrix[cls, cls]\n",
    "        fp = conf_matrix[:, cls].sum() - tp\n",
    "        fn = conf_matrix[cls, :].sum() - tp\n",
    "        denom = tp + fp + fn\n",
    "        ious[cls] = tp / denom if denom > 0 else float('nan')\n",
    "    return ious\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Main training loop ---\n",
    "def train_domain_adaptation(\n",
    "    root, list_src, list_tgt, list_val,\n",
    "    num_classes=8, ignore_label=0,\n",
    "    batch_size=2, num_epochs=20,\n",
    "    base_lr=1e-2, \n",
    "    device='cuda'\n",
    "):\n",
    "    train_trasform = A.Compose([A.ColorJitter(p=0.5)])\n",
    "    # Datasets and loaders\n",
    "    src_dataset = LoveDA(root, list_src, num_classes=num_classes, ignore_label=ignore_label, transform=train_trasform)\n",
    "    tgt_dataset = LoveDA(root, list_tgt, num_classes=num_classes, ignore_label=ignore_label, transform=train_trasform)\n",
    "    val_dataset = LoveDA(root, list_val, num_classes=num_classes, ignore_label=ignore_label)\n",
    "\n",
    "    src_loader = DataLoader(src_dataset, batch_size=batch_size, pin_memory=False, shuffle=True, num_workers=4, drop_last=True)\n",
    "    tgt_loader = DataLoader(tgt_dataset, batch_size=batch_size, pin_memory=False, shuffle=True, num_workers=4, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=False, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "    target_iter = iter(tgt_loader)\n",
    "    # Models\n",
    "    seg_model = get_seg_model()\n",
    "    seg_model = seg_model.cuda()\n",
    "\n",
    "    ouput_branches = ['P', 'I']\n",
    "    \n",
    "    # FullModel wraps semantic and boundary losses\n",
    "    # Assuming sem_loss and bd_loss are defined elsewhere \n",
    "    class_weights_loveda = torch.tensor([0.000000, 0.116411, 0.266041, 0.607794, 1.511413, 0.745507, 0.712438, 3.040396])\n",
    "    \n",
    "    # sem_loss = nn.CrossEntropyLoss(ignore_index=ignore_label, weight=class_weights_loveda)\n",
    "    sem_loss = OhemCrossEntropy(ignore_label=ignore_label, thres=0.9, min_kept=131072, weight=class_weights_loveda)\n",
    "    bd_loss = BondaryLoss()\n",
    "    full_model = FullModel(seg_model, sem_loss, bd_loss).cuda()\n",
    "\n",
    "    n_discriminators = 3\n",
    "    \n",
    "    # Discriminators for two adaptation levels\n",
    "    # Level 1: intermediate head output channels (P branch)\n",
    "    if 'P' in ouput_branches:\n",
    "        d1 = Discriminator(in_channels=num_classes).cuda()\n",
    "\n",
    "    if 'I' in ouput_branches: \n",
    "        # Level 2: main output (I branch combined with P and D)\n",
    "        d2 = Discriminator(in_channels=num_classes).cuda()\n",
    "    if 'D' in ouput_branches:\n",
    "        # Level 3: intermediate head output channels (D branch)\n",
    "        d3 = Discriminator(in_channels=1).cuda()\n",
    "        \n",
    "\n",
    "    # Optimizers\n",
    "    params_dict = dict(full_model.named_parameters())\n",
    "    params = [{'params': list(params_dict.values()), 'lr': base_lr}]\n",
    "    optimizer_seg = torch.optim.SGD(params,\n",
    "                                lr=base_lr,\n",
    "                                momentum=0.7,\n",
    "                                weight_decay=0.0005,\n",
    "                                )\n",
    "    if 'P' in ouput_branches:\n",
    "        optimizer_d1 = optim.Adam(d1.parameters(), lr=1e-4, betas=(0.9, 0.99))\n",
    "        base_lr_d1 = optimizer_d1.param_groups[0]['lr']\n",
    "    if 'I' in ouput_branches:\n",
    "        optimizer_d2 = optim.Adam(d2.parameters(), lr=1e-4, betas=(0.9, 0.99))\n",
    "        base_lr_d2 = optimizer_d2.param_groups[0]['lr']\n",
    "        \n",
    "    if 'D' in ouput_branches:\n",
    "        optimizer_d3 = optim.Adam(d3.parameters(), lr=1e-4, betas=(0.9, 0.99))\n",
    "        base_lr_d3 = optimizer_d3.param_groups[0]['lr']\n",
    "        \n",
    "\n",
    "    # Adversarial labels\n",
    "    src_label = 1.0\n",
    "    tgt_label = 0.0\n",
    "\n",
    "    \n",
    "    lambda_adv1=0.0002\n",
    "    lambda_adv2=0.001\n",
    "    lambda_adv3=0.00002\n",
    "    # Training\n",
    "    max_iters = num_epochs * len(src_loader) # corresponds to num_epoch * num_batches\n",
    "    cur_iter = 0 # incremented by 1 at each iteration, by the end of the training it will be equal to max_iters\n",
    "    best_mIoU = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        seg_model.train()\n",
    "        if 'P' in ouput_branches:\n",
    "            d1.train()\n",
    "            meter_loss_d1 = AverageMeter()\n",
    "            meter_adv1  = AverageMeter()\n",
    "            \n",
    "        if 'I' in ouput_branches:\n",
    "            d2.train()\n",
    "            meter_adv2  = AverageMeter()\n",
    "            meter_loss_d2 = AverageMeter()\n",
    "        \n",
    "        if 'D' in ouput_branches:    \n",
    "            d3.train()\n",
    "            meter_adv3  = AverageMeter()\n",
    "            meter_loss_d3 = AverageMeter()\n",
    "            \n",
    "        meter_seg   = AverageMeter()\n",
    "        meter_bd    = AverageMeter()\n",
    "        meter_acc   = AverageMeter()\n",
    "        pbar = tqdm(src_loader, total=len(src_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for imgs_s, labels_s, edges_s, _, _ in pbar:\n",
    "            imgs_s = imgs_s.cuda(); labels_s = labels_s.long().cuda(); edges_s = edges_s.float().cuda()\n",
    "            try:\n",
    "                imgs_t, _, _, _, _ = next(target_iter)\n",
    "            except StopIteration:\n",
    "                target_iter = iter(tgt_loader)\n",
    "                imgs_t, _, _, _, _ = next(target_iter)\n",
    "            imgs_t = imgs_t.cuda()\n",
    "\n",
    "            # ----- Train Discriminators -----\n",
    "            with torch.no_grad():\n",
    "                out_s1, out_s2, out_s3 = seg_model(imgs_s)\n",
    "                out_t1, out_t2, out_t3 = seg_model(imgs_t)\n",
    "            if 'P' in ouput_branches:\n",
    "                prob_s1 = F.softmax(out_s1.detach(), dim=1)\n",
    "                prob_t1 = F.softmax(out_t1.detach(), dim=1)\n",
    "            if 'I' in ouput_branches:\n",
    "                prob_s2 = F.softmax(out_s2.detach(), dim=1)\n",
    "                prob_t2 = F.softmax(out_t2.detach(), dim=1)\n",
    "            if 'D' in ouput_branches:\n",
    "                prob_s3 = torch.sigmoid(out_s3.detach())\n",
    "                prob_t3 = torch.sigmoid(out_t3.detach())\n",
    "\n",
    "            # D1\n",
    "            if 'P' in ouput_branches:\n",
    "                optimizer_d1.zero_grad()\n",
    "                pred_d_s1 = d1(prob_s1)\n",
    "                pred_d_t1 = d1(prob_t1)\n",
    "                loss_d1 = 0.5 * (F.binary_cross_entropy_with_logits(pred_d_s1, torch.full_like(pred_d_s1, src_label)) +\n",
    "                                  F.binary_cross_entropy_with_logits(pred_d_t1, torch.full_like(pred_d_t1, tgt_label)))\n",
    "                loss_d1.backward()\n",
    "                optimizer_d1.step()\n",
    "                meter_loss_d1.update(loss_d1.item())\n",
    "\n",
    "            # D2\n",
    "            if 'I' in ouput_branches:\n",
    "                optimizer_d2.zero_grad()\n",
    "                pred_d_s2 = d2(prob_s2)\n",
    "                pred_d_t2 = d2(prob_t2)\n",
    "                loss_d2 = 0.5 * (F.binary_cross_entropy_with_logits(pred_d_s2, torch.full_like(pred_d_s2, src_label)) +\n",
    "                                  F.binary_cross_entropy_with_logits(pred_d_t2, torch.full_like(pred_d_t2, tgt_label)))\n",
    "                loss_d2.backward()\n",
    "                optimizer_d2.step()\n",
    "                meter_loss_d2.update(loss_d2.item())\n",
    "                \n",
    "               \n",
    "            # D3\n",
    "            if 'D' in ouput_branches:\n",
    "                optimizer_d3.zero_grad()\n",
    "                pred_d_s3 = d3(prob_s3)\n",
    "                pred_d_t3 = d3(prob_t3)\n",
    "                loss_d3 = 0.5 * (F.binary_cross_entropy_with_logits(pred_d_s3, torch.full_like(pred_d_s3, src_label)) +\n",
    "                                  F.binary_cross_entropy_with_logits(pred_d_t3, torch.full_like(pred_d_t3, tgt_label)))\n",
    "                loss_d3.backward()\n",
    "                optimizer_d3.step()\n",
    "                meter_loss_d3.update(loss_d3.item())\n",
    "                \n",
    "            # ----- Train Segmentation Network -----\n",
    "            optimizer_seg.zero_grad()\n",
    "            loss_seg, seg_outputs, acc, loss_components = full_model(imgs_s, labels_s, edges_s)\n",
    "            \n",
    "            # Adversarial on target\n",
    "            ot1, ot2, ot3 = seg_model(imgs_t)\n",
    "\n",
    "            if 'P' in ouput_branches:\n",
    "                prob_t1 = F.softmax(ot1, dim=1)\n",
    "                pred_d_t1_for_seg = d1(prob_t1)\n",
    "                loss_adv1 = F.binary_cross_entropy_with_logits(pred_d_t1_for_seg, torch.full_like(pred_d_t1_for_seg, src_label)) # predictions from target, but source ground truth\n",
    "                \n",
    "            if 'I' in ouput_branches:\n",
    "                prob_t2 = F.softmax(ot2, dim=1)\n",
    "                pred_d_t2_for_seg = d2(prob_t2)\n",
    "                loss_adv2 = F.binary_cross_entropy_with_logits(pred_d_t2_for_seg, torch.full_like(pred_d_t2_for_seg, src_label)) # predictions from target, but source ground truth\n",
    "                \n",
    "            if 'D' in ouput_branches:\n",
    "                prob_t3 = torch.sigmoid(ot3)\n",
    "                pred_d_t3_for_seg = d3(prob_t3)\n",
    "                loss_adv3 = F.binary_cross_entropy_with_logits(pred_d_t3_for_seg, torch.full_like(pred_d_t3_for_seg, src_label)) # predictions from target, but source ground truth\n",
    "\n",
    "            loss_total = loss_seg.mean()\n",
    "            \n",
    "            if 'P' in ouput_branches:\n",
    "                loss_total += lambda_adv1 * loss_adv1 \n",
    "            if 'I' in ouput_branches:\n",
    "                loss_total += lambda_adv2 * loss_adv2\n",
    "            if 'D' in ouput_branches:\n",
    "                loss_total += lambda_adv3 * loss_adv3\n",
    "            \n",
    "            loss_total.backward()\n",
    "            optimizer_seg.step()\n",
    "\n",
    "            meter_seg.update( loss_components[0].mean().item() )\n",
    "            meter_bd .update( loss_components[1].mean().item() )\n",
    "\n",
    "            if 'P' in ouput_branches:\n",
    "                meter_adv1.update( loss_adv1.item() )\n",
    "            if 'I' in ouput_branches:\n",
    "                meter_adv2.update( loss_adv2.item() )\n",
    "            if 'D' in ouput_branches:\n",
    "                meter_adv3.update( loss_adv3.item() )\n",
    "            \n",
    "            meter_acc.update( acc.item() )\n",
    "\n",
    "            # Update learning rate\n",
    "            cur_iter += 1\n",
    "            adjust_learning_rate(optimizer_seg, base_lr, max_iters, cur_iter)\n",
    "            if 'P' in ouput_branches:\n",
    "                adjust_learning_rate(optimizer_d1, base_lr_d1, max_iters, cur_iter)\n",
    "            if 'I' in ouput_branches:\n",
    "                adjust_learning_rate(optimizer_d2, base_lr_d2, max_iters, cur_iter)\n",
    "            if 'D' in ouput_branches:\n",
    "                adjust_learning_rate(optimizer_d3, base_lr_d3, max_iters, cur_iter)\n",
    "\n",
    "            display_dict = {\n",
    "                    'seg_loss': loss_components[0].mean().item(),\n",
    "                    'bd_loss': loss_components[1].mean().item(),\n",
    "                    'acc': acc.item()\n",
    "            }\n",
    "            if 'P' in ouput_branches:\n",
    "                display_dict['adv1'] = loss_adv1.item()\n",
    "                display_dict['loss_d1'] = loss_d1.item()\n",
    "                \n",
    "            if 'I' in ouput_branches:\n",
    "                display_dict['adv2'] = loss_adv2.item()\n",
    "                display_dict['loss_d2'] = loss_d2.item()\n",
    "                \n",
    "            if 'D' in ouput_branches:\n",
    "                display_dict['adv3'] = loss_adv3.item()\n",
    "                display_dict['loss_d3'] = loss_d3.item()\n",
    "\n",
    "            # Display losses\n",
    "            pbar.set_postfix(display_dict)\n",
    "\n",
    "        log_str = (\n",
    "            f\"Epoch {epoch+1} Train Avg — \"\n",
    "            f\"seg_loss: {meter_seg.average():.4f}, \"\n",
    "            f\"bd_loss: {meter_bd.average():.4f}, \"\n",
    "            f\"acc: {meter_acc.average():.4f}, \"\n",
    "        )\n",
    "        \n",
    "        if 'P' in ouput_branches:\n",
    "            log_str += f\"adv1: {meter_adv1.average():.4f}, \"\n",
    "            log_str += f\"loss_d1: {meter_loss_d1.average():.4f}, \"    \n",
    "        \n",
    "        if 'I' in ouput_branches:\n",
    "            log_str += f\"adv2: {meter_adv2.average():.4f}, \"\n",
    "            log_str += f\"loss_d2: {meter_loss_d2.average():.4f}, \"      \n",
    "        \n",
    "        if 'D' in ouput_branches:\n",
    "            log_str += f\"adv3: {meter_adv3.average():.4f}, \" \n",
    "            log_str += f\"loss_d3: {meter_loss_d3.average():.4f}, \" \n",
    "        \n",
    "        print(log_str)\n",
    "        \n",
    "        torch.cuda.empty_cache()       # se usi GPU\n",
    "        gc.collect()                   # raccogli il garbage Python\n",
    "\n",
    "\n",
    "       # ——— (3) Validation on the FULL model ———\n",
    "        print(f\"\\nEpoch {epoch+1} Validation (full_model):\")\n",
    "        mIoU, cls_ious = validate(\n",
    "            val_loader,\n",
    "            full_model,\n",
    "            num_classes=num_classes,\n",
    "            ignore_label=ignore_label,\n",
    "            align_corners=True \n",
    "        )\n",
    "        print(f\"  ==> full_model mIoU: {mIoU:.4f}\")\n",
    "        for idx, iou in enumerate(cls_ious, start=1):\n",
    "            print(f\"    Class {idx:2d}: IoU = {iou:.4f}\")\n",
    "\n",
    "        final_output_dir = os.path.join('/kaggle/working', 'best')\n",
    "        os.makedirs(final_output_dir, exist_ok=True)\n",
    "        \n",
    "        if mIoU > best_mIoU:\n",
    "            best_mIoU = mIoU\n",
    "            torch.save(full_model.state_dict(), os.path.join(final_output_dir, 'best_full_model.pt'))\n",
    "\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage\n",
    "    train_domain_adaptation(\n",
    "        root='/kaggle/working/list/',\n",
    "        list_src='urban/train.lst',\n",
    "        list_tgt='rural/train.lst',\n",
    "        list_val='rural/val.lst',\n",
    "        num_classes=8,\n",
    "        ignore_label=0,\n",
    "        batch_size=6,\n",
    "        num_epochs=20,\n",
    "        base_lr=1e-2,\n",
    "        device='cuda'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:45:08.436291Z",
     "iopub.status.busy": "2025-05-25T18:45:08.436025Z",
     "iopub.status.idle": "2025-05-25T18:45:12.569045Z",
     "shell.execute_reply": "2025-05-25T18:45:12.567827Z",
     "shell.execute_reply.started": "2025-05-25T18:45:08.436267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# ---------- 1.  Paths & basic config ----------\n",
    "root      = '/kaggle/working/list/'\n",
    "list_val  = 'rural/val.lst'\n",
    "ckpt_path = '/kaggle/working/best/best_full_model.pt'\n",
    "batch_sz  = 6\n",
    "num_cls   = 8\n",
    "ignore_lb = 0\n",
    "device    = 'cuda'\n",
    "\n",
    "# ---------- 2.  Rebuild the model wrapper ----------\n",
    "seg_model = get_seg_model()                    \n",
    "seg_model = seg_model.to(device)\n",
    "\n",
    "class_weights_loveda = torch.tensor(\n",
    "    [0.000000, 0.116411, 0.266041, 0.607794,\n",
    "     1.511413, 0.745507, 0.712438, 3.040396],\n",
    "    device=device\n",
    ")\n",
    "sem_loss = OhemCrossEntropy(\n",
    "    ignore_label=ignore_lb, thres=0.9, min_kept=131072,\n",
    "    weight=class_weights_loveda\n",
    ")\n",
    "bd_loss  = BondaryLoss()\n",
    "\n",
    "full_model = FullModel(seg_model, sem_loss, bd_loss).to(device)\n",
    "\n",
    "# ---------- 3.  Load the checkpoint ----------\n",
    "state_dict = torch.load(ckpt_path, map_location='cpu')\n",
    "full_model.load_state_dict(state_dict, strict=True)\n",
    "full_model.eval()                               # important!\n",
    "\n",
    "# ---------- 4.  Validation dataset & loader ----------\n",
    "val_dataset = LoveDA(\n",
    "    root, list_val,\n",
    "    num_classes=num_cls,\n",
    "    ignore_label=ignore_lb,\n",
    "    transform=None\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_sz,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:35:02.278248Z",
     "iopub.status.busy": "2025-05-25T18:35:02.277677Z",
     "iopub.status.idle": "2025-05-25T18:35:02.283407Z",
     "shell.execute_reply": "2025-05-25T18:35:02.282417Z",
     "shell.execute_reply.started": "2025-05-25T18:35:02.278225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- 5.  Run the evaluation of the best model----------\n",
    "mIoU, cls_ious = validate(\n",
    "    val_loader,\n",
    "    full_model,\n",
    "    num_classes=num_cls,\n",
    "    ignore_label=ignore_lb,\n",
    "    align_corners=True       \n",
    ")\n",
    "\n",
    "print(f'\\nBest-checkpoint mIoU: {mIoU:0.4f}')\n",
    "for idx, iou in enumerate(cls_ious, start=1):\n",
    "    print(f'   class {idx:2d}: IoU = {iou:0.4f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack\n",
    "According to the authors of \"Learning to Adapt Structured Output Space for Semantic Segmentation\", the model should have learned to structure the output, whether the model comes from the source or the target domain. We test whether the model actually learned to force some segmentation map structure by using the Fast Gradient Descent method and looking the drop in performance. If the model actually forces a segmentation map desoite the input, the drop in performance should be lower with respect to the other models trained using data augmentation alone and data augmentation + color jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T18:42:44.507679Z",
     "iopub.status.busy": "2025-05-25T18:42:44.507327Z",
     "iopub.status.idle": "2025-05-25T18:42:55.392541Z",
     "shell.execute_reply": "2025-05-25T18:42:55.391420Z",
     "shell.execute_reply.started": "2025-05-25T18:42:44.507652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ------------------ 1. Setup ------------------\n",
    "import torch, random, numpy as np, matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "CKPT_PATH = '/kaggle/working/best/best_full_model.pt'   # <- your saved model\n",
    "NUM_CLASSES = 8\n",
    "IGNORE_LABEL = 0\n",
    "\n",
    "# class weights used during training\n",
    "CLASS_WEIGHTS = torch.tensor(\n",
    "    [0.000000, 0.116411, 0.266041, 0.607794,\n",
    "     1.511413, 0.745507, 0.712438, 3.040396],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ------------------ 2. Rebuild + load ------------------\n",
    "seg_model   = get_seg_model().to(device)\n",
    "sem_loss    = OhemCrossEntropy(ignore_label=IGNORE_LABEL,\n",
    "                               thres=0.9, min_kept=131072,\n",
    "                               weight=CLASS_WEIGHTS).to(device)\n",
    "bd_loss     = BondaryLoss().to(device)\n",
    "\n",
    "full_model  = FullModel(seg_model, sem_loss, bd_loss).to(device)\n",
    "full_model.load_state_dict(torch.load(CKPT_PATH, map_location='cpu'), strict=True)\n",
    "full_model.eval()\n",
    "\n",
    "print('✓ checkpoint loaded')\n",
    "\n",
    "# ------------------ 4. FGSM attack helpers ------------------\n",
    "def fgsm_attack(model, dataloader, epsilon=0.03,\n",
    "                ignore_index=0, max_samples=200):\n",
    "    \"\"\"Return a batch of adversarially-perturbed images + labels.\"\"\"\n",
    "    model.eval()\n",
    "    adv_imgs, adv_lbls = [], []\n",
    "    collected = 0\n",
    "\n",
    "    for imgs, lbls, *_ in tqdm(dataloader, desc='FGSM'):\n",
    "        imgs, lbls = imgs.to(device).float(), lbls.to(device).long()\n",
    "        imgs.requires_grad = True\n",
    "\n",
    "        logits = model.model(imgs)[-2]              # underlying PIDNet output\n",
    "        logits = F.interpolate(logits, size=lbls.shape[1:],\n",
    "                               mode='bilinear', align_corners=True)\n",
    "        loss = F.cross_entropy(logits, lbls,\n",
    "                               weight=CLASS_WEIGHTS,\n",
    "                               ignore_index=ignore_index)\n",
    "        model.zero_grad(); loss.backward()\n",
    "\n",
    "        # un-normalise, add perturbation, re-normalise\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406],\n",
    "                            device=device).view(1,3,1,1)\n",
    "        std  = torch.tensor([0.229, 0.224, 0.225],\n",
    "                            device=device).view(1,3,1,1)\n",
    "        img_unnorm = imgs * std + mean\n",
    "        adv_unnorm = (img_unnorm + epsilon * imgs.grad.sign()).clamp(0,1)\n",
    "        adv_imgs_b = (adv_unnorm - mean) / std\n",
    "\n",
    "        for ai, lb in zip(adv_imgs_b.cpu(), lbls.cpu()):\n",
    "            adv_imgs.append(ai); adv_lbls.append(lb)\n",
    "            collected += 1\n",
    "            if collected >= max_samples:\n",
    "                return torch.stack(adv_imgs), torch.stack(adv_lbls)\n",
    "\n",
    "    return torch.stack(adv_imgs), torch.stack(adv_lbls)\n",
    "\n",
    "def evaluate_on_adv(model, adv_imgs, lbls, num_classes):\n",
    "    \"\"\"Mean IoU on a batch of adversarial samples (ignoring class-0).\"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(adv_imgs), 4):\n",
    "            x = adv_imgs[i:i+4].to(device)\n",
    "            logits = model.model(x)[-2]\n",
    "            logits = F.interpolate(logits, size=lbls.shape[1:],\n",
    "                                   mode='bilinear', align_corners=True)\n",
    "            preds.append(logits.argmax(1).cpu())\n",
    "    preds = torch.cat(preds)\n",
    "\n",
    "    ious = []\n",
    "    for cls in range(1, num_classes):\n",
    "        pred_i = preds == cls; lbl_i = lbls[:len(preds)] == cls\n",
    "        inter  = (pred_i & lbl_i).sum().item()\n",
    "        union  = (pred_i | lbl_i).sum().item()\n",
    "        if union > 0: ious.append(inter / union)\n",
    "    print(f'\\nFGSM mIoU (ε={epsilon}): {np.mean(ious):.4f}')\n",
    "\n",
    "def decode_segmap(segmentation):\n",
    "    cmap = np.array([\n",
    "        [0,0,0], [128,64,128], [70,70,70], [128,0,0],\n",
    "        [0,0,255], [153,153,153], [0,128,0], [255,255,0]\n",
    "    ], dtype=np.uint8)\n",
    "    rgb = cmap[segmentation]\n",
    "    return rgb\n",
    "\n",
    "def visualise_examples(model, dataloader, adv_imgs, adv_lbls, k=4):\n",
    "    import matplotlib.pyplot as plt\n",
    "    idxs = random.sample(range(len(adv_imgs)), k)\n",
    "    for idx in idxs:\n",
    "        # original sample from loader\n",
    "        img_np, gt_lbl, *_ = dataloader.dataset[idx]\n",
    "        img_t = torch.from_numpy(img_np).unsqueeze(0).float().to(device)\n",
    "        gt_np = gt_lbl\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_clean = model.model(img_t)[-2]\n",
    "            logits_clean = F.interpolate(logits_clean, size=gt_np.shape,\n",
    "                                         mode='bilinear', align_corners=True)\n",
    "            pred_clean = logits_clean.argmax(1).squeeze(0).cpu().numpy()\n",
    "\n",
    "            logits_adv = model.model(adv_imgs[idx:idx+1].to(device))[-2]\n",
    "            logits_adv = F.interpolate(logits_adv, size=gt_np.shape,\n",
    "                                       mode='bilinear', align_corners=True)\n",
    "            pred_adv = logits_adv.argmax(1).squeeze(0).cpu().numpy()\n",
    "\n",
    "        # un-normalise RGB\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std  = np.array([0.229, 0.224, 0.225])\n",
    "        rgb_img = (img_np.transpose(1,2,0) * std + mean).clip(0,1)\n",
    "\n",
    "        fig, ax = plt.subplots(1,4, figsize=(18,6))\n",
    "        for a,title,data in zip(ax,\n",
    "            ['RGB', 'Prediction', 'FGSM Prediction', 'GT'],\n",
    "            [rgb_img, decode_segmap(pred_clean),\n",
    "             decode_segmap(pred_adv), decode_segmap(gt_np)]):\n",
    "            a.imshow(data); a.set_title(title); a.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# ------------------ 5. FGSM run ------------------\n",
    "epsilon = 0.04            # set your ε here\n",
    "adv_imgs, adv_lbls = fgsm_attack(\n",
    "    full_model, val_loader,\n",
    "    epsilon=epsilon,\n",
    "    ignore_index=IGNORE_LABEL,\n",
    "    max_samples=200\n",
    ")\n",
    "evaluate_on_adv(full_model, adv_imgs, adv_lbls, NUM_CLASSES)\n",
    "visualise_examples(full_model, val_loader, adv_imgs, adv_lbls, k=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('/kaggle/working/checkpoints', 'zip', '/kaggle/working/') \n",
    "shutil.make_archive('/kaggle/working/best', 'zip', '/kaggle/working/') "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7153698,
     "sourceId": 11422827,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7154101,
     "sourceId": 11423306,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
