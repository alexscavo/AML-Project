{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montiamo il drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per evitare di occupare troppa memoria, eliminiamo il dataset presente nella cartella di pidnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r \"/content/drive/MyDrive/GitHub/PIDNet-main/data/loveda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il codice seguente serve per scaricare lo zip del dataset LoveDA. Non usarlo se lo hai già scaricato. In ogni caso ho inserito un check che verifica la presenza o meno del file /content/drive/MyDrive/Datasets/LoveDA/train.zip. Se questo non è presente, allora parte il download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"/content/drive/MyDrive/Datasets/LoveDA/train.zip\"\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_path = '/content/drive/MyDrive/Datasets/LoveDA'\n",
    "train_zip = os.path.join(dataset_path, 'train.zip')\n",
    "val_zip = os.path.join(dataset_path, 'val.zip')\n",
    "\n",
    "# Function to unzip with a progress bar\n",
    "def unzip_with_progress(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        with tqdm(total=total_files, desc=f\"Extracting {os.path.basename(zip_path)}\") as pbar:\n",
    "            for file in zip_ref.infolist():\n",
    "                zip_ref.extract(file, extract_to)\n",
    "                pbar.update(1)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    url_train = \"https://zenodo.org/records/5706578/files/Train.zip?download=1\"\n",
    "    output_train = \"/content/drive/MyDrive/Datasets/LoveDA/train.zip\"  # Specify the path in your Google Drive\n",
    "\n",
    "    url_val = \"https://zenodo.org/records/5706578/files/Val.zip?download=1\"\n",
    "    output_val = \"/content/drive/MyDrive/Datasets/LoveDA/val.zip\"  # Specify the path in your Google Drive\n",
    "\n",
    "\n",
    "    response = requests.get(url_train, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "\n",
    "    with open(output_train, \"wb\") as file, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=\"Downloading\"\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            file.write(data)\n",
    "            progress_bar.update(len(data))\n",
    "\n",
    "    print(\"Download train completed!\")\n",
    "\n",
    "    response = requests.get(url_val, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "\n",
    "    with open(output_val, \"wb\") as file, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=\"Downloading\"\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            file.write(data)\n",
    "            progress_bar.update(len(data))\n",
    "\n",
    "    print(\"Download val completed!\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una cartella in cui mettere il clone repository di github, qualora non sia già presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = \"/content/drive/MyDrive/GitHub/\"\n",
    "os.makedirs(destination_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poiché il repository è privato, è necessario fare il clone usando il tuo account github. Per farlo crea un token da github con i seguenti passaggi:\n",
    "\n",
    "\n",
    "1. Vai sul tuo account GitHub.\n",
    "2. Vai a **Settings** > **Developer settings** > **Personal access tokens** > Tokens (classic).\n",
    "3. Clicca **Generate new token**\n",
    "4. Imposta una data di scadenza del token e fisci tutte le autorizzazioni (spunta tutte le caselle proposte).\n",
    "5. Genera il token e salvalo da qualche parte, perché puoi vederlo solo una volta.\n",
    "\n",
    "Adesso inserisci il tuo username e il token nella casella di codice seguente per fare il clone\n",
    "\n",
    "Nota: anche qui viene fatto un check per cui il clone non viene eseguito il repository è già stato clonato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/content/drive/MyDrive/GitHub/PIDNet-main\"\n",
    "if not os.path.exists(folder_path):\n",
    "  github_username = \"MontanaVincenzo\"  # Replace with your GitHub username\n",
    "  github_token = \"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\"  # Replace with your personal access token\n",
    "\n",
    "  # Repository URL and folder\n",
    "  repo_url = f\"https://{github_username}:{github_token}@github.com/alexscavo/AML-Project.git\"\n",
    "\n",
    "  !git clone {repo_url} {destination_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamo un pull per aggiornare il repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/GitHub/PIDNet-main\n",
    "!git pull origin main  # Replace 'main' with your branch name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzippiamo il dataset sulla corretta cartella del repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/content/drive/MyDrive/GitHub/DeepLab/project_datasets/LoveDA/Train\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    new_folder = \"/content/drive/MyDrive/GitHub/DeepLab/project_datasets/LoveDA\"\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    \n",
    "    # Unzip train and validation datasets\n",
    "    unzip_with_progress(train_zip, '/content/drive/MyDrive/GitHub/DeepLab/project_datasets/LoveDA')\n",
    "    unzip_with_progress(val_zip, '/content/drive/MyDrive/GitHub/DeepLab/project_datasets/LoveDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo il file di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/GitHub/DeepLab/training\n",
    "%run train_loveDA.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RobotLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
